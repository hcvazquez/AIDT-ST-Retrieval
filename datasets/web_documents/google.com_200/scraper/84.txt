<!doctype html>
<html>
 <head> 
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
    new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
    j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
    'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
    })(window,document,'script','dataLayer','GTM-TLK8PF');</script> 
  <meta http-equiv="Content-Type" content="text/html" charset="UTF-8"> 
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"> 
  <link rel="shortcut icon" href="/assets/favicon.ico"> 
  <title>Introduction to Web Scraping for Marketers</title> 
  <meta name="description" content=""> 
  <script src="https://code.jquery.com/jquery-2.1.4.min.js"></script> 
  <link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/css/bootstrap.min.css" rel="stylesheet"> 
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script> 
  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css"> 
  <link href="https://fonts.googleapis.com/css?family=Raleway:700,400,300" rel="stylesheet" type="text/css"> 
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/styles/monokai-sublime.min.css"> 
  <link rel="stylesheet" type="text/css" href="/assets/css/style.css"> 
  <meta name="HandheldFriendly" content="True"> 
  <meta name="MobileOptimized" content="320"> 
  <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
  <link rel="canonical" href="https://www.connordphillips.com/2016/02/22/introduction-to-web-scraping-for-marketers/"> 
  <meta name="referrer" content="no-referrer-when-downgrade"> 
  <link rel="amphtml" href="https://www.connordphillips.com/2016/02/22/introduction-to-web-scraping-for-marketers/amp/"> 
  <meta property="og:site_name" content="Connor Phillips - Marketing, Analytics, Programming and Entrepreneurship"> 
  <meta property="og:type" content="article"> 
  <meta property="og:title" content="Introduction to Web Scraping for Marketers"> 
  <meta property="og:description" content="Over the span of just a few years the digital marketing landscape has evolved into a data-crazed world filled with programmatic marketing products that are aimed at mining data and making bid adjustments based on real time cost-benefit analysis. With the advent of this type of software, businesses have flocked"> 
  <meta property="og:url" content="https://www.connordphillips.com/2016/02/22/introduction-to-web-scraping-for-marketers/"> 
  <meta property="og:image" content="//s3.amazonaws.com/ghost-blogpost-images/2016/Feb/marketers_web_scraping-1456097087068.png"> 
  <meta property="article:published_time" content="2016-02-22T19:00:46.000Z"> 
  <meta property="article:modified_time" content="2016-02-24T02:02:21.000Z"> 
  <meta property="article:tag" content="marketing"> 
  <meta property="article:tag" content="programming"> 
  <meta property="article:tag" content="nodejs"> 
  <meta property="article:tag" content="web scraping"> 
  <meta property="article:tag" content="web scraper"> 
  <meta name="twitter:card" content="summary_large_image"> 
  <meta name="twitter:title" content="Introduction to Web Scraping for Marketers"> 
  <meta name="twitter:description" content="Over the span of just a few years the digital marketing landscape has evolved into a data-crazed world filled with programmatic marketing products that are aimed at mining data and making bid adjustments based on real time cost-benefit analysis. With the advent of this type of software, businesses have flocked"> 
  <meta name="twitter:url" content="https://www.connordphillips.com/2016/02/22/introduction-to-web-scraping-for-marketers/"> 
  <meta name="twitter:image" content="//s3.amazonaws.com/ghost-blogpost-images/2016/Feb/marketers_web_scraping-1456097087068.png"> 
  <meta name="twitter:label1" content="Written by"> 
  <meta name="twitter:data1" content="Connor Phillips"> 
  <meta name="twitter:label2" content="Filed under"> 
  <meta name="twitter:data2" content="marketing, programming, nodejs, web scraping, web scraper"> 
  <meta property="og:image:width" content="622"> 
  <meta property="og:image:height" content="280"> 
  <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Connor Phillips - Marketing, Analytics, Programming and Entrepreneurship",
        "logo": "https://www.connordphillips.com/ghost/img/ghosticon.jpg"
    },
    "author": {
        "@type": "Person",
        "name": "Connor Phillips",
        "image": {
            "@type": "ImageObject",
            "url": "//www.gravatar.com/avatar/f1422f7f9450dfc4ece083de8978bbda?s=250&d=mm&r=x",
            "width": 250,
            "height": 250
        },
        "url": "https://www.connordphillips.com/author/connor/",
        "sameAs": []
    },
    "headline": "Introduction to Web Scraping for Marketers",
    "url": "https://www.connordphillips.com/2016/02/22/introduction-to-web-scraping-for-marketers/",
    "datePublished": "2016-02-22T19:00:46.000Z",
    "dateModified": "2016-02-24T02:02:21.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "//s3.amazonaws.com/ghost-blogpost-images/2016/Feb/marketers_web_scraping-1456097087068.png",
        "width": 622,
        "height": 280
    },
    "keywords": "marketing, programming, nodejs, web scraping, web scraper",
    "description": "Over the span of just a few years the digital marketing landscape has evolved into a data-crazed world filled with programmatic marketing products that are aimed at mining data and making bid adjustments based on real time cost-benefit analysis. With the advent of this type of software, businesses have flocked",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://www.connordphillips.com"
    }
}
    </script> 
  <meta name="generator" content="Ghost 0.11"> 
  <link rel="alternate" type="application/rss+xml" title="Connor Phillips - Marketing, Analytics, Programming and Entrepreneurship" href="https://www.connordphillips.com/rss/"> 
 </head> 
 <body class="post-template tag-marketing tag-programming tag-nodejs tag-web-scraping tag-web-scraper"> 
  <!-- Google Tag Manager (noscript) --> 
  <noscript>
   <iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TLK8PF" height="0" width="0" style="display:none;visibility:hidden"></iframe>
  </noscript> 
  <!-- End Google Tag Manager (noscript) --> 
  <!-- Navigation --> 
  <nav class="navbar" role="navigation"> 
   <div class="container"> 
    <!-- Brand and toggle get grouped for better mobile display --> 
    <div class="navbar-header"> 
     <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar"></span> <span class="icon-bar"></span> <span class="icon-bar"></span> </button> 
     <div class="navigation-site-logo"> 
      <a class="navbar-brand" href="/">CONNOR PHILLIPS</a> 
     </div> 
    </div> 
    <!-- Collect the nav links, forms, and other content for toggling --> 
    <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1"> 
     <ul class="nav navbar-nav"> 
      <li> <a href="/about">About</a> </li> 
      <li> <a href="/portfolio">Portfolio</a> </li> 
     </ul> 
    </div> 
    <!-- /.navbar-collapse --> 
   </div> 
   <!-- /.container --> 
  </nav> 
  <div class="container"> 
   <main class="main_uber" role="main"> 
    <div class="row"> 
     <div class="col-md-12"> 
      <article class="article-content-wrapper" role="article" itemscope itemtype="http://schema.org/Article"> 
       <header class="article-header-information"> 
        <h1 class="article-title" itemprop="headline">Introduction to Web Scraping for Marketers</h1> 
        <time class="article-post-time" datetime="2016-02-22" itemprop="datePublished">Monday 22 Feb 2016</time> 
       </header> 
       <div class="article-content-body" itemprop="articleBody"> 
        <img src="//s3.amazonaws.com/ghost-blogpost-images/2016/Feb/marketers_web_scraping-1456097087068.png" class="img-responsive article-post-image"> 
        <p>Over the span of just a few years the digital marketing landscape has evolved into a data-crazed world filled with programmatic marketing products that are aimed at mining data and making bid adjustments based on real time cost-benefit analysis. With the advent of this type of software, businesses have flocked to purchase these solutions in order to reap the exponential lifts that the platforms promise. In some instances these decisions turn out to be a slam dunk, while in other instances the results have zero impact on marketing performance and the marketing teams are forced to develop an in-house solution.</p> 
        <p>Regardless of the case that occurs, there is an inherent need for marketers to be trained on various programming languages like JavaScript and Python in order to implement 3rd party platform pixels or create a homegrown solution. This type of skill set is not typically found with the present day marketer, but will definitely be found in the skill set of the next generation marketer.</p> 
        <p>As a result, it is good to read up on basic programming languages and know enough to help reduce the need for development team resources for common marketing team requests. I am a major advocate of marketers following this path and will try to introduce such topics in blog posts like this one on web scraping.</p> 
        <p><strong>Web Scraping</strong></p> 
        <p>Web scraping for the purpose marketing can occur varies case to case, but almost always has an element of collecting information or cleaning data. From keeping tabs on competitor rankings or product pricing to cleaning up and categorizing internal data, the possibilities with web scraping are endless. </p> 
        <p>In the accompanying guide I will walk you through a quick tutorial on how your can build a web scraper with NodeJS.</p> 
        <p><strong>Prerequisites:</strong></p> 
        <p>-You must have Nodejs and NPM installed on your machine -Node.js &amp; npm (npm is bundled with node) - Install here: <a href="http://nodejs.org">https://nodejs.org/en/</a></p> 
        <p>-Basic understanding of JavaScript and Node.js</p> 
        <p>-Text editor program - Doesn’t matter which you use. Two popular programs are <a href="https://www.sublimetext.com/">Sublime Text</a> &amp; <a href="https://atom.io/">Atom.io</a></p> 
        <p>-Command Line Interface</p> 
        <p><em>Note: This tutorial was created with a Mac. The only difference that the operating system makes for this tutorial is the command line interface or CLI that is used. If you are using a Mac, your default CLI will be terminal. If you are using Windows, your default CLI will be command prompt.</em></p> 
        <p><strong>Let’s get to it!</strong></p> 
        <p><strong>Step 1)</strong> Create a file named package.json. This file contains all of the modules that are required for our web scraper to work as well and the javascript file that is the primary entry point to the program. Set your file up like so.</p> 
        <p><strong>package.json:</strong></p> 
        <pre><code>{
  "name": "marketing-web-scraper",
  "version": "1.0.0",
  "description": "Web scraper for marketers",
  "main": "app.js",
  "author": "Your Name",
  "dependencies": {
    "cheerio": "^0.19.0",
    "express": "^4.13.3",
    "fs": "0.0.2",
    "request": "^2.67.0"
  }
}</code></pre> 
        <p>After you save the file, go to your CLI and change directories to your app folder like so </p> 
        <pre><code>cd /path/to/application-folder</code></pre> 
        <p>and run</p> 
        <pre><code>npm install</code></pre> 
        <p>This will run a series of commands to install the packages from npm. If your install was successful, you will notice that a node_modules folder was created with folders created for each of the dependencies listed. These folders contain code, which will interact with our program when we require the modules within our app.</p> 
        <b>Step 2)</b> Create a javascript file titled “app.js”, require each of the modules located in the dependencies section of the package.json and then set our URL that we want scraped with a port for the server to be accessed from. In my example I decided to scrape the headlines from one of my favorite web development sites, asiteapart.com (var url = ‘
        <a href="http://alistapart.com/’">http://alistapart.com/’</a>) Look for the commented section to the right of the code for an explanation of what the modules provide. 
        <p><i>Please note that all URL’s have to contain http:// or https://. If an application protocol type is not included in the URL then you will receive the following error message [Error: Invalid URI "alistapart.com"]</i></p> 
        <pre><code>
var express = require("express"); // NodeJS framework
var fs = require("fs"); // Simple server request
var request = require("request"); // Access to the file system
var cheerio = require("cheerio"); // Server-side jQuery
var app = express();

var url = 'http://alistapart.com/' //Website for the web scrape

var port = '8080'; // Server port for the listen function
</code></pre> 
        <p><strong>Step 3)</strong> Set up an empty array that will be used to store the scraped data and create a route with a GET request that contains a require function. When we access this route at localhost:8080/ the web scraping function will be triggered</p> 
        <pre><code>var titles = []; //Empty array for storing scraped data

//Web Scraping Logic accessed at localhost:8080/
app.get('/', function(req, res){
)};</code></pre> 
        <p><strong>Step 4)</strong> Add the request function which will access our url. The if(err) clause is used to send us an error message if the request fails.</p> 
        <pre><code>//1) Request a URL, Then check to see if there is an error accessing the website. If there is no error accessing the website, then log the HTML body of the page
  request(url, function(err, res, body){
    if(err){
      console.log(err);
    } else {
     //Step 5 code
    }</code></pre> 
        <p><strong>Step 5)</strong> Load the body of the page with the cheerio “load” method and set it to the ‘$’. Then traverse the body content for the specific HTML elements that you are looking to scrape. For my example I am looking to scrape the headlines of the articles listed. When looking at the source code of my URL I notice a common naming convention trend of ‘h4.summary-title’. This looks like the exact information I was looking for so I pass this to the cheerio variable and set a loop to capture all of the text on that page that fit this criteria, which will then be stored in the empty variable we set earlier in the code.</p> 
        <pre><code>//Provide Cheerio with access to the URL's HTML
var $ = cheerio.load(body);

//Traverse the HTML for the h4 tags used for the article titles

$('h4.summary-title').each(function(i, elem){
  titles[i] = $(this).text();
});


console.log(titles);</code></pre> 
        <p><strong>Step 6)</strong> Write the scraped information to a .csv file that will be found within our application folder and log success text to our terminal and to our localhost page. </p> 
        <pre><code>fs.writeFile('web-scrape-results.csv', JSON.stringify(titles, null, " "), function(err){
        if(err){
          console.log(err);
        } else {
          console.log("Data written successfully!");
        }
      });</code></pre> 
        <p><strong>Step 7)</strong> Go back to your CLI, run </p> 
        <pre><code>node app.js</code></pre>, and then go to 
        <pre><code>localhost:8080/</code></pre> If you followed all of the steps correctly then you should have a newly created csv file called ‘web-scrape-results.csv’ with the scraped information. If you don’t see that file then you missed some parts of code along the way and should refollow the steps or tweet at me/send me an email and I will be more than happy to help! 
        <img src="https://s3.amazonaws.com/ghost-blogpost-images/2016/Feb/web_scrape_console-1456167516830.png" class="img-responsive"> 
        <img src="https://s3.amazonaws.com/ghost-blogpost-images/2016/Feb/results_csv-1456167600838.png" class="img-responsive"> 
        <p><b><u>Full Code:</u></b></p> ***package.json*** 
        <pre><code>
{
  "name": "marketing-web-scraper",
  "version": "1.0.0",
  "description": "Web scraper for marketers",
  "main": "app.js",
  "author": "Connor Phillips",
  "dependencies": {
    "cheerio": "^0.19.0",
    "express": "^4.13.3",
    "fs": "0.0.2",
    "request": "^2.67.0",
    "x-ray": "^2.0.3"
  }
}
</code></pre> 
        <b><i>app.js</i></b> 
        <pre><code>//Step 2
var express = require("express"); // NodeJS framework
var fs = require("fs"); // Simple server request
var request = require("request"); // Access to the file system
var cheerio = require("cheerio"); // Server-side jQuery
var app = express();

var url = 'http://alistapart.com/' //Website for the web scrape

var port = '8080'; // Server port for the listen function

//Step 3
var titles = []; //Empty array for storing scraped data


//Web Scraping Logic accessed at localhost:8080/
app.get('/', function(req, res){

//Step 4 

  //Request a URL, Then check to see if there is an error accessing the website. If there is no error accessing the website, then log the HTML body of the page
  request(url, function(err, res, body){
    if(err){
      console.log(err);
    } else {

//Step 5

      //Provide Cheerio with access to the URL's HTML
      var $ = cheerio.load(body);

      //Traverse the HTML for the h4 tags used for the article titles
      $('h4.summary-title').each(function(i, elem){
        titles[i] = $(this).text();
      });

      console.log(titles);

//Step 6

      fs.writeFile('web-scrape-results.csv', JSON.stringify(titles, null, " "), function(err){
        if(err){
          console.log(err);
        } else {
          console.log("Data written successfully!");
        }
      });

    }
  })
  res.send(url + " was successfully scraped!");


});

app.listen(port);

console.log('Listening on port' + port);</code></pre> 
       </div> 
       <div class="article-tags">
         Tags: 
        <a href="/tag/marketing/">marketing</a> | 
        <a href="/tag/programming/">programming</a> | 
        <a href="/tag/nodejs/">nodejs</a> | 
        <a href="/tag/web-scraping/">web scraping</a> | 
        <a href="/tag/web-scraper/">web scraper</a> 
       </div> 
       <div class="article-social-share-wrapper"> 
        <h4 class="social-share-links">Enjoy this post? Please Share: &nbsp;</h4> 
        <div class="article-social-share-icons"> 
         <a class="social-share-links icon-twitter" target="_blank" href="http://twitter.com/share?text=Introduction to Web Scraping for Marketers&amp;url=https://www.connordphillips.com/2016/02/22/introduction-to-web-scraping-for-marketers/" onclick="dataLayer.push({'event': 'twitterShare'});"><span class="hidethis_uber"><i class="fa fa-twitter"></i> Twitter</span></a> 
         <a class="social-share-links icon-facebook" target="_blank" href="http://www.facebook.com/sharer.php?u=https://www.connordphillips.com/2016/02/22/introduction-to-web-scraping-for-marketers/"><span class="hidethis_uber" onclick="dataLayer.push({'event': 'facebookShare'});"><i class="fa fa-facebook"></i> Facebook</span></a> 
         <a class="social-share-links icon-gplus" target="_blank" href="https://plus.google.com/share?url=https://www.connordphillips.com/2016/02/22/introduction-to-web-scraping-for-marketers/"><span class="hidethis_uber" onclick="dataLayer.push({'event': 'googlePlusShare'});"><i class="fa fa-google-plus"></i> Google+</span></a> 
         <a class="social-share-links icon-linkedin" target="_blank" href="https://www.linkedin.com/shareArticle?mini=true&amp;url=https://www.connordphillips.com/2016/02/22/introduction-to-web-scraping-for-marketers/&amp;title=Introduction to Web Scraping for Marketers"><span class="hidethis_uber" onclick="dataLayer.push({'event': 'linkedInShare'});"><i class="fa fa-linkedin"></i> LinkedIn</span></a> 
        </div> 
       </div> 
       <div class="article-newsletter-signup"> 
        <h3>Want to read more content like this?</h3> 
        <p>Sign up for my monthly newsletter so you never miss a post</p> 
        <div class="mc-field-group"> 
         <form action="//connordphillips.us10.list-manage.com/subscribe/post?u=46d4ca194e984dd223cf8f4b0&amp;id=07980a6312" method="post" id="mc-embedded-subscribe-form" name="mc-embedded-subscribe-form" class="validate" target="_blank" novalidate> 
          <label for="mce-EMAIL">Email Address</label> 
          <input type="email" value="" name="EMAIL" class="article-newsletter-signup-email" id="mce-EMAIL" placeholder="johndoe@gmail.com"> 
         </form>
        </div> 
        <div id="mce-responses" class="clear"> 
         <div class="response" id="mce-error-response" style="display:none"></div> 
         <div class="response" id="mce-success-response" style="display:none"></div> 
        </div> 
        <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups--> 
        <div style="position: absolute; left: -5000px;" aria-hidden="true">
         <input type="text" name="b_46d4ca194e984dd223cf8f4b0_07980a6312" tabindex="-1" value="">
        </div> 
        <div class="clear">
         <input type="submit" value="Subscribe" name="subscribe" id="mc-embedded-subscribe" class="article-newsletter-signup-button">
        </div> 
       </div>  
      </article>
     </div>  
    </div> 
    <!-- Go to www.addthis.com/dashboard to customize your tools --> 
    <script type="text/javascript" src="//s7.addthis.com/js/300/addthis_widget.js#pubid=ra-558ae6a6402d29ac" async></script> 
   </main>
  </div>   
  <!-- You can safely delete this line if your theme does not require jQuery --> 
  <script type="text/javascript" src="https://code.jquery.com/jquery-1.11.3.min.js"></script> 
  <script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.1.0/highlight.min.js"></script> 
  <script>hljs.initHighlightingOnLoad();</script>  
 </body>
</html>