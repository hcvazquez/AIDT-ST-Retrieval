<!doctype html>
<html>
 <head> 
  <meta charset="utf-8"> 
  <meta http-equiv="X-UA-Compatible" content="IE=edge"> 
  <title></title> 
  <meta name="description" content=""> 
  <meta name="viewport" content="width=device-width, initial-scale=1"> 
  <link rel="stylesheet" type="text/css" href="/css/main.css"> 
  <!-- Place favicon.ico and apple-touch-icon.png in the root directory --> 
  <script src="http://ajax.googleapis.com/ajax/libs/jquery/1/jquery.js"></script> 
  <script src="/js/main.js"></script> 
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script> 
  <script>
      (adsbygoogle = window.adsbygoogle || []).push({
        google_ad_client: "ca-pub-9064317682916014",
        enable_page_level_ads: true
      });
    </script> 
 </head> 
 <body> 
  <!--[if lt IE 7]>
    <p class="browsehappy">You are using an <strong>outdated</strong> browser. Please <a href="http://browsehappy.com/">upgrade your browser</a> to improve your experience.</p>
<![endif]--> 
  <nav> 
   <a href="/" class="nav-logo">DANIEL <br>SHIFFMAN</a> 
   <span class="line-charm"></span> 
   <ul class="nav-links"> 
    <li><a href="/books/">BOOKS</a></li> 
    <li><a href="/videos/">VIDEOS</a></li> 
    <li><a href="/learning/">LEARNING</a></li> 
    <li><a href="/about/">ABOUT</a></li> 
    <span class="line-charm"></span> 
    <li><a href="http://twitter.com/shiffman" target="_blank">TWITTER</a></li> 
    <li><a href="http://github.com/shiffman" target="_blank">GITHUB</a></li> 
    <li><a href="https://www.patreon.com/codingtrain?ty=h" target="_blank">PATREON</a></li> 
   </ul> 
  </nav> 
  <div class="logo"> 
   <span class="nav-btn"><img src="/images/nav-btn.svg"></span> 
   <!-- <div class="logo-set">
      <h2>DANIEL SHIFFMAN</h2>
      <span class="intro">Teacher of Code and Programming</span>
    </div> --> 
  </div> 
  <span class="mobile-quick-links">VIEW QUICK LINKS</span> 
  <link rel="stylesheet" type="text/css" href="/css/prism.css"> 
  <link rel="stylesheet" type="text/css" href="/css/highlight.css"> 
  <link rel="stylesheet" type="text/css" href="/css/a2z.css"> 
  <script src="/js/blog.js"></script> 
  <script src="/js/prism.js"></script> 
  <section class="left-container out a2z"> 
   <h1>Programming from A to Z</h1> 
   <p><br> <a href="/a2z/" class="body-link primary">about</a> <a href="https://github.com/shiffman/A2Z-F16/blob/gh-pages/README.md" class="body-link primary">syllabus</a> <a href="https://github.com/shiffman/A2Z-F16" class="body-link primary">All example source code</a> </p> 
   <span class="line-charm first"></span> 
   <div class="content-wrapper article a2z"> 
    <h1 id="word-counting-and-text-analysis">Word Counting and Text Analysis</h1> 
    <iframe width="525" height="300" src="https://www.youtube.com/embed/tE-ZYXU8A8U?list=PLRqwX-V7Uu6bZQkJcGM5S9fn9R9Yyd8iZ" frameborder="0" allowfullscreen></iframe> 
    <h2 id="examples">Examples</h2> 
    <ul> 
     <li><a href="https://shiffman.github.io/A2Z-F16/week5-analysis/01_concordance/">Word counting</a> — <a href="https://github.com/shiffman/A2Z-F16/tree/gh-pages/week5-analysis/01_concordance">source code</a></li> 
     <li><a href="https://shiffman.github.io/A2Z-F16/week5-analysis/02_pos_concordance/">Parts of Speech Concordance</a> — <a href="https://github.com/shiffman/A2Z-F16/tree/gh-pages/week5-analysis/02_pos_concordance">source code</a></li> 
     <li><a href="https://shiffman.github.io/A2Z-F16/week5-analysis/03_tf-idf/">Keyword extraction - TF-IDF</a> — <a href="https://github.com/shiffman/A2Z-F16/tree/gh-pages/week5-analysis/03_tf-idf">source code</a></li> 
     <li><a href="https://shiffman.github.io/A2Z-F16/week5-analysis/04_classification/">Text Classification - Naive Bayes</a> — <a href="https://github.com/shiffman/A2Z-F16/tree/gh-pages/week5-analysis/04_classification">source code</a></li> 
     <li><a href="https://github.com/shiffman/A2Z-F16/tree/gh-pages/week5-analysis/05_node_concordance">Node concordance</a></li> 
    </ul> 
    <h2 id="sample-datasets">Sample datasets:</h2> 
    <ul> 
     <li><a href="http://www.gutenberg.org/">Project Gutenberg</a></li> 
     <li><a href="http://www.aueb.gr/users/ion/data/enron-spam/">Enron e-mail corpus</a></li> 
    </ul> 
    <h2 id="related-references">Related references</h2> 
    <ul> 
     <li><a href="http://secretlifeofpronouns.com/">Secret Life of Pronouns</a>, <a href="https://www.youtube.com/watch?v=PGsQwAu3PzU">Pennebaker Ted Talk</a></li> 
     <li><a href="http://www.tfidf.com/">TF-IDF Single Page Tutorial</a></li> 
     <li><a href="http://www.paulgraham.com/spam.html">Paul Graham’s A Plan for Spam</a> and <a href="http://www.paulgraham.com/better.html">Better Bayesian Filtering</a></li> 
     <li><a href="http://www.bcc.bilkent.edu.tr/BayesianFiltering.pdf">Introduction to Bayesian Filtering</a></li> 
     <li><a href="http://sciencehouse.wordpress.com/2009/04/19/monty-hall-and-bayes/">Monty Hall and Bayes</a></li> 
     <li><a href="http://yudkowsky.net/rational/bayes">An Intuitive Explanation of Bayes’ Theorem by Eliezer S. Yudkowsky</a></li> 
    </ul> 
    <h2 id="related-projects">Related Projects</h2> 
    <ul> 
     <li><a href="http://www.runemadsen.com/work/speech-comparison/">SPEECH COMPARISON</a> by Rune Madsen</li> 
     <li><a href="http://www.sarahgp.com/index.html">Book-Book</a> by Sarah Groff-Palermo</li> 
     <li><a href="https://www.jasondavies.com/wordtree/">Word Tree</a> by Jason Davies</li> 
     <li><a href="http://www.wordle.net/">Wordle</a></li> 
     <li><a href="http://www.stefanieposavec.co.uk/-everything-in-between/#/ok-go-of-the-blue-colour-of-the-sky/">OK GO album covers</a> by Stefanie Posavec</li> 
     <li><a href="http://thecreatorsproject.vice.com/blog/craigslists-missed-connections-get-matched-by-an-algorithmic-cupid">Luke Dubois’ Missed Connections</a></li> 
     <li><a href="http://hindsightisalways2020.net/">Luke Dubois’ HindSight is always 20/20</a></li> 
     <li><a href="http://feltron.com/FAR13.html">Nicholas Felton’s 2013 Annual Report</a>, <a href="http://bits.blogs.nytimes.com/2014/08/19/a-life-in-data-nicholas-feltons-self-surveillance/?_php=true&amp;_type=blogs&amp;_r=0">NY Times Article</a></li> 
     <li><a href="http://style.org/lyrics/">Lyrical Indicators</a> and <a href="http://style.org/stateoftheunion/">Parsing the State of the Union</a> by Jonathan Corum</li> 
    </ul> 
    <h2 id="exercise-ideas">Exercise ideas</h2> 
    <ul> 
     <li>Visualize the results of a concordance using canvas (or some other means).</li> 
     <li>Expand the information the concordance holds so that it keeps track of word positions (i.e. not only how many times do the words appear in the source text, but where do they appear each time.)</li> 
     <li>Implement some of the ideas specific to spam filtering to the bayesian classification example.</li> 
     <li>In James W. Pennebaker’s book <a href="http://secretlifeofpronouns.com/">The Secret Life of Pronouns</a>, Pennebaker describes his research into how the frequency of words that have little to no meaning on their own (I, you, they, a, an, the, etc.) are a window into the emotional state or personality of an author or speaker. For example, heavy use of the pronoun “I” is an indicator of “depression, stress or insecurity”. Create a page sketch that analyzes the use of pronouns. For more, visit <a href="http://www.analyzewords.com/">analyzewords.com</a>.</li> 
     <li>Use the ideas to find similarities between people. For example, if you look at all the e-mails on the ITP student list, can you determine who is similar? Consider using properties in addition to word count, such as time of e-mails, length of e-mails, who writes to whom, etc.</li> 
    </ul> 
    <h2 id="associative-arrays-in-javascript">Associative Arrays in JavaScript?</h2> 
    <iframe width="525" height="300" src="https://www.youtube.com/embed/_5jdE6RKxVk?list=PLRqwX-V7Uu6bZQkJcGM5S9fn9R9Yyd8iZ" frameborder="0" allowfullscreen></iframe> 
    <p>You know that thing we call an array? Yes, that’s right, an ordered list of data. Each element of an array is numbered and accessed by its numeric index.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="kd">var</span> <span class="nx">nameList</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'Jane'</span><span class="p">,</span> <span class="s1">'Sue'</span><span class="p">,</span> <span class="s1">'Bob'</span><span class="p">];</span>
<span class="c1">// Is your name Sue?</span>
<span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="s1">'Is your name '</span> <span class="o">+</span> <span class="nx">nameList</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">+</span> <span class="s1">'?'</span><span class="p">);</span></code></pre>
    </figure> 
    <p>What if, however, instead of numbering the elements of an array we could name them? This element is named “Sue”, this one “Bob”, this one “Jane”, and so on and so forth. In programming, this kind of data structure is often referred to as an “associative array”, “map”, “hash” or “dictionary.” It’s a collection of <code class="highlighter-rouge">key/value</code> pairs. The key is <code class="highlighter-rouge">Sue</code>, the value is <code class="highlighter-rouge">24</code>. It’s just like having a dictionary of words and when you look up, say, <code class="highlighter-rouge">Sue</code> the definition is <code class="highlighter-rouge">24</code>.</p> 
    <p>Associative arrays can be incredibly convenient for various applications. For example, you could keep a list of student IDs (<code class="highlighter-rouge">student name/id</code>) or a list of prices (<code class="highlighter-rouge">product name/price</code>) in a dictionary. The fundamental building block of just about every text analysis application is a concordance, a list of all words in a document along with how many times each word occurred. A dictionary is the perfect data structure to hold this information. Each element of the dictionary consists of a String paired with a number.</p> 
    <p>Most programming languages and environments have specific classes or objects for a variety of data structures (a dictionary is just one example). JavaScript, however, does not. But all is not lost. Remember that thing called a JavaScript object?</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="kd">var</span> <span class="nx">obj</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">Sue</span><span class="p">:</span> <span class="mi">24</span><span class="p">,</span>
  <span class="na">Jane</span><span class="p">:</span> <span class="mi">991</span><span class="p">,</span>
  <span class="na">Bob</span><span class="p">:</span> <span class="mi">12</span>
<span class="p">};</span></code></pre>
    </figure> 
    <p>That’s right. A JavaScript object is a collection of name-value pairs. And so while it might be more convenient to have a custom-tailored dictionary object, we’re going to be able to get all the functionality we need out of just a plain old object itself.</p> 
    <p>To start writing a concordance all we need is an empty object.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="kd">var</span> <span class="nx">concordance</span> <span class="o">=</span> <span class="p">{};</span></code></pre>
    </figure> 
    <p>A value (in this case a count) can be paired with a word by naming the key as a String.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="nx">concordance</span><span class="p">[</span><span class="s1">'the'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">100</span><span class="p">;</span>
<span class="nx">concordance</span><span class="p">[</span><span class="s1">'a'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">10</span><span class="p">;</span>
<span class="nx">concordance</span><span class="p">[</span><span class="s1">'go'</span><span class="p">]</span> <span class="o">=</span> <span class="mi">50</span><span class="p">;</span></code></pre>
    </figure> 
    <p>The above is just another way of writing:</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="kd">var</span> <span class="nx">concordance</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">the</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
  <span class="na">a</span><span class="p">:</span> <span class="mi">10</span><span class="p">,</span>
  <span class="na">go</span><span class="p">:</span> <span class="mi">50</span>
<span class="p">};</span></code></pre>
    </figure> 
    <p>We’ll need this new way since we’ll be pulling the names for the object as strings from a source text.</p> 
    <h2 id="text-concordance">Text Concordance</h2> 
    <iframe width="525" height="300" src="https://www.youtube.com/embed/unm0BLor8aE?list=PLRqwX-V7Uu6bZQkJcGM5S9fn9R9Yyd8iZ" frameborder="0" allowfullscreen></iframe> 
    <p>In the case of our examples, we’re going to take a text document, split it into an array of Strings and increase the value associated with a particular key (i.e. word) each time we encounter the same String. Let’s assume we have some text in a variable named <code class="highlighter-rouge">data</code>. First, we’ll split into word “tokens”.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="c1">// Using any non letter or number character as delimiter</span>
<span class="kd">var</span> <span class="nx">tokens</span> <span class="o">=</span> <span class="nx">data</span><span class="p">.</span><span class="nx">split</span><span class="p">(</span><span class="sr">/</span><span class="se">\W</span><span class="sr">+/</span><span class="p">);</span></code></pre>
    </figure> 
    <p>Then we’ll go through each one a a time.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">tokens</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span></code></pre>
    </figure> 
    <p>The tricky thing here is we have to determine if each token (each element of the resulting array) is a new word or one we’ve already encountered. If it’s new, we need to set its initial count at 1. If it’s not, we need to increase its count by one.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">tokens</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx">word</span> <span class="o">=</span> <span class="nx">tokens</span><span class="p">[</span><span class="nx">i</span><span class="p">];</span>
  <span class="c1">// It's a new word!</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">concordance</span><span class="p">[</span><span class="nx">word</span><span class="p">]</span> <span class="o">===</span> <span class="kc">undefined</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">concordance</span><span class="p">[</span><span class="nx">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
  <span class="c1">// We've seen this word before!</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="nx">concordance</span><span class="p">[</span><span class="nx">word</span><span class="p">]</span><span class="o">++</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre>
    </figure> 
    <p>There, we now have a concordance object that stores all the words and their counts! The question, however, remains: what do we do with this thing?</p> 
    <p>The first thing you might want to do is simply examine the results. For example, let’s say we wanted to display the most frequent words (in sorted order). Unfortunately, the fields of a JavaScript object have no order to them and cannot be easily sorted. One solution to this problem is to keep a separate array of all the keys. This array can be sorted and used to iterate over all the name/value pairs in the concordance object.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="c1">// Add another array to track keys</span>
<span class="kd">var</span> <span class="nx">keys</span> <span class="o">=</span> <span class="p">[];</span>
<span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">tokens</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx">word</span> <span class="o">=</span> <span class="nx">tokens</span><span class="p">[</span><span class="nx">i</span><span class="p">];</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">concordance</span><span class="p">[</span><span class="nx">word</span><span class="p">]</span> <span class="o">===</span> <span class="kc">undefined</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">concordance</span><span class="p">[</span><span class="nx">word</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="c1">// When we have a new word, let's add to our keys array!</span>
    <span class="nx">keys</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">word</span><span class="p">);</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="nx">concordance</span><span class="p">[</span><span class="nx">word</span><span class="p">]</span><span class="o">++</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre>
    </figure> 
    <p>While we could write our own sorting algorithm in JavaScript to sort the array, we might as well make use of the <code class="highlighter-rouge">sort()</code> function available as part of the Array prototype. The tricky thing here is that the sort function expects as an argument which a function itself!</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="nx">keys</span><span class="p">.</span><span class="nx">sort</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">)</span> <span class="p">{</span>
  <span class="c1">// what goes here??</span>
<span class="p">});</span></code></pre>
    </figure> 
    <p>This is pretty typical of JavaScript and functional programming. Here we have an anonymous function that we pass into the <code class="highlighter-rouge">sort()</code> function itself. This function takes two arguments: <code class="highlighter-rouge">a</code> and <code class="highlighter-rouge">b</code>. The function is a <strong>comparison</strong> function and should return true if element <code class="highlighter-rouge">b</code> should appear before <code class="highlighter-rouge">a</code> in the sorted result.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="nx">keys</span><span class="p">.</span><span class="nx">sort</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">concordance</span><span class="p">[</span><span class="nx">b</span><span class="p">]</span> <span class="o">&gt;</span> <span class="nx">concordance</span><span class="p">[</span><span class="nx">a</span><span class="p">])</span> <span class="p">{</span>
    <span class="k">return</span> <span class="kc">true</span><span class="p">;</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="k">return</span> <span class="kc">false</span><span class="p">;</span>
  <span class="p">}</span>
<span class="p">});</span></code></pre>
    </figure> 
    <p>This can be condensed since a positive number is evaluated as <code class="highlighter-rouge">true</code> and a negative one as <code class="highlighter-rouge">false</code>.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="nx">keys</span><span class="p">.</span><span class="nx">sort</span><span class="p">(</span><span class="kd">function</span><span class="p">(</span><span class="nx">a</span><span class="p">,</span> <span class="nx">b</span><span class="p">)</span> <span class="p">{</span>
  <span class="k">return</span> <span class="p">(</span><span class="nx">concordance</span><span class="p">[</span><span class="nx">b</span><span class="p">]</span> <span class="o">-</span> <span class="nx">concordance</span><span class="p">[</span><span class="nx">a</span><span class="p">]);</span>
<span class="p">});</span></code></pre>
    </figure> 
    <p>Now that we have sorted keys, we can iterate over the concordance.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">keys</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="nx">keys</span><span class="p">[</span><span class="nx">i</span><span class="p">]</span> <span class="o">+</span> <span class="s1">': '</span> <span class="o">+</span> <span class="nx">concordance</span><span class="p">[</span><span class="nx">keys</span><span class="p">[</span><span class="nx">i</span><span class="p">]]);</span>
<span class="p">}</span></code></pre>
    </figure> 
    <p>Here is a <a href="http://shiffman.net/teaching/a2z/analysis/01_concordance/">text concordance example</a> and its <a href="https://github.com/shiffman/Programming-from-A-to-Z-F14/tree/master/week3_analysis/01_concordance">source code</a>.</p> 
    <h2 id="tf-idf">TF-IDF</h2> 
    <iframe width="525" height="300" src="https://www.youtube.com/embed/RPMYV-eb6lI?list=PLRqwX-V7Uu6bZQkJcGM5S9fn9R9Yyd8iZ" frameborder="0" allowfullscreen></iframe> 
    <p>One common application of a text concordance is <a href="http://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a> or term frequency–inverse document frequency. Let’s consider a corpus of wikipedia articles. Is there a way we could automatically generate keywords or tags for an article based on its word counts?</p> 
    <p>TF-IDF has two components. Term frequency is one that we are already quite familiar with. How frequent is a given term in a document? This is exactly what we calculated in the concordance. We could stop here and say that keyword generation is: “The words that appear most frequently are most important in a document.” While there is some merit to this idea, what we’ll see is that the most frequent words are just the words that appear frequently in all text: junk words like ‘to’, ‘a’, ‘and’, ‘you’, ‘me’, etc. <a href="http://secretlifeofpronouns.com/">Ironically, these junk words may hold the key to unlocking a world of information about a particular text</a>. Nevertheless, these are clearly not related to a document’s subject matter as keywords.</p> 
    <p>TF-IDF takes a different approach. Yes, a word that appears frequently in a document (TF) is one key indicator. But adding in another indicator such as inverse document frequency (is it a word that rarely appears in other documents?) takes the junk words out of the equation Let’s consider a wikipedia article about rainbows. Here are some of the counts:</p> 
    <figure class="highlight">
     <pre><code class="language-text" data-lang="text">the:      16
and:      6
rainbow:  5
droplets: 3</code></pre>
    </figure> 
    <p>Using this as a keyword score alone is not enough since the most important word is ‘the’. Now let’s say we looked at five other wikipedia articles. Let’s now count how many articles each of these words appear at least once in.</p> 
    <figure class="highlight">
     <pre><code class="language-text" data-lang="text">the:      6
and:      6
rainbow:  1
droplets: 1</code></pre>
    </figure> 
    <p>This is a somewhat obvious result: ‘the’ and ‘and’ appear in all the articles and ‘rainbow’ and ‘droplet’ appear in both. We could therefore compute a score for each of these as:</p> 
    <figure class="highlight">
     <pre><code class="language-text" data-lang="text">rainbow:   5 * (6/1)   30
droplets:  3 * (6/1)   18
the:      16 * (6/6)   16
and:       6 * (6/6)   6</code></pre>
    </figure> 
    <p>Now we’re getting somewhere!</p> 
    <p>TF-IDF is meant to be run on a much larger corpus and in order to dampen the effect of the IDF value, a common solution is to use the logarithm of IDF.</p> 
    <figure class="highlight">
     <pre><code class="language-text" data-lang="text">rainbow:   5 * log(6/1)   3.89
droplets:  3 * log(6/1)   2.33
the:      16 * log(6/6)   0.0
and:       6 * log(6/6)   0.0</code></pre>
    </figure> 
    <p>If <a href="http://en.wikipedia.org/wiki/Logarithmic_scale">logarithmic scale</a> is new to you, this Khan Academy video may help. (Note how if a term appears in every single document the tf-idf score is always zero.)</p> 
    <iframe width="525" height="300" src="//www.youtube.com/embed/sBhEi4L91Sg" frameborder="0" allowfullscreen></iframe> 
    <p>We can improve this one more step by using not just the raw count of how many times a term (such as “rainbow”) appears in a document, but the ratio of of its count to the total number of words in the document. This normalizes the score by document length. So if the total number of words in the article is 100, the score would now be:</p> 
    <figure class="highlight">
     <pre><code class="language-text" data-lang="text">rainbow:  (5/100) * log(6/1)   0.0389
droplets: (3/100) * log(6/1)   0.0233
the:     (16/100) * log(6/6)   0.0
and:      (6/100) * log(6/6)   0.0</code></pre>
    </figure> 
    <p>In the case of only examining this document it makes no difference, but if we were looking at the score for “rainbow” across multiple documents without this change the score would be biased towards longer documents.</p> 
    <p>For a wonderful example of TF-IDF out in the world, take a look at <a href="http://bits.blogs.nytimes.com/2014/08/19/a-life-in-data-nicholas-feltons-self-surveillance/">Nicholas Felton’s 2013 Annual Report</a>.</p> 
    <h2 id="naive-bayesian-text-classification">Naive Bayesian Text Classification</h2> 
    <h3 id="bayes-theorem">Bayes’ Theorem:</h3> 
    <figure class="highlight">
     <pre><code class="language-text" data-lang="text">p(A|B) = (p(B|A) * p(A)) / (p(B|A) * p(A) + p(B|~A) * p(~A) )</code></pre>
    </figure> 
    <p>Consider the following scenario:</p> 
    <ul> 
     <li>1% of all ITP students are afflicted with a rare disease known as ITPosis</li> 
     <li>There is a test you can take to determine if you have it, known as a TID (Test for Interactive Disease).</li> 
     <li>90% of all students with ITPosis will receive a positivie TID (i.e. 10% that have the disease will receive a false negative).</li> 
     <li>95% of students without ITPosis will receive a negative TID (i.e. 5% will receive false positives).</li> 
    </ul> 
    <p>You have received a positive TID, what is the likelihood you have ITPosis?</p> 
    <p>As you might expect, there is a very precise answer to this question but it’s probably not what you initially guess. Bayesian reasoning is counter-intuitive and takes quite a bit of getting used to. In fact, when <a href="http://yudkowsky.net/rational/bayes">given a similar question related to breast cancer and mammograms</a>&lt;/a&gt;, only 15% of doctors get the answer correct.</p> 
    <p>The answer — 15.3% — is calculated via Bayes’ Theorem. Let’s look at it again with this scenario:</p> 
    <ul> 
     <li>There are 1000 students.</li> 
     <li>10 of them have ITPosis.</li> 
     <li>9 of those 10 with the disease will receive a positive TID.</li> 
     <li>Out of the 990 w/o ITPosis, ~50 will receive positive TIDs.</li> 
     <li>Therefore, 59 total students receive positive TIDs, 9 of which actually have the disease, 50 do not.</li> 
     <li>The chance one has the disease if the test is positive is therefore 9 / 58 = 15.5% (off slightly from the exact result b/c of rounding).</li> 
    </ul> 
    <p>This video illustrates the problem quite nicely.</p> 
    <p><iframe width="525" height="300" src="//www.youtube.com/embed/D8VZqxcu0I0" frameborder="0" allowfullscreen></iframe></p> 
    <p>The problem our brains run into are those rascally 90% and 95% numbers. 90% of students who test positive have the disease and 95% who don’t test negative, if I test positive, I should probably have it, right?!! The important thing to remember is that only 1% of students actually have the disease. Sure testing positive increases the likelihood, but because 5% of students without the disease receive a false positive, it only increases the chances to 15%. All of this is explained in incredibly thorough and wonderful detail in <a href="http://yudkowsky.net/">Eliezer Yudkowsky’s</a> article <a href="http://yudkowsky.net/rational/bayes">An Intuitive Explanation of Bayesian Reasoning</a>. My explanation is simply adapted from his.</p> 
    <p>By the way, we could have calculated it as follows:</p> 
    <pre>
  P (ITPosis | Positive TID) = (90% * 1%) / (90% * 1% + 5% * 99%)
</pre> 
    <p>This reads as “the probability that a positive TID means you have ITPosis” equals:</p> 
    <p>So why do we care? This type of reasoning can be applied quite nicely to text analysis. A common example is spam filtering. If we know the probability that a spam e-mail contains a specific words, we can calculate the likelihood that an e-mail is spam based on its concordance.</p> 
    <p>A wonderful resource for this approach is <a href="http://www.paulgraham.com/spam.html">Paul Graham’s A Plan for Spam</a> as well as <a href="http://www.paulgraham.com/better.html">Better Bayesian Filtering</a>.</p> 
    <p>The example code that follows is not a perfect text classifier by any means. It’s a simple implementation of the idea that outlines the basic steps one might take to apply <a href="http://en.wikipedia.org/wiki/Bayesian_filtering">Bayesian Filtering</a> to text.</p> 
    <h3 id="a-word-object">A Word Object</h3> 
    <p>The first thing we need to do is expand on the concordance example that stores a single number associated with each word. For classification, we’ll need to know things like how many times that word appears in spam e-mails versus good (aka ‘ham’) e-mails. And then we’ll need to use these values to calculate the probability that each word would appear in a spam or ham e-mail.&lt;/p&gt;</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="kd">var</span> <span class="nx">word</span> <span class="o">=</span> <span class="p">{};</span>
<span class="nx">word</span><span class="p">.</span><span class="nx">countA</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>   <span class="c1">// category A count</span>
<span class="nx">word</span><span class="p">.</span><span class="nx">countB</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>   <span class="c1">// category B count</span>
<span class="nx">word</span><span class="p">.</span><span class="nx">probA</span> <span class="o">=</span> <span class="p">???;</span>  <span class="c1">// probability word appears in category A doc</span>
<span class="nx">word</span><span class="p">.</span><span class="nx">probB</span> <span class="o">=</span> <span class="p">???;</span>  <span class="c1">// probability word appears in category B doc</span>
<span class="c1">// etc. etc.</span></code></pre>
    </figure> 
    <p>Instead of storing a single number like <code class="highlighter-rouge">dictionary['the'] = 16;</code> we now need to associate an object with multiple data points with each key.The process of running the filter works as follows:</p> 
    <ol> 
     <li>Train the filter with known category A (for example: spam) e-mails and known category B (ham) e-mails.</li> 
     <li>For every word, check if it’s new. If it is add it, if not, simply increase the counter for “A” or “B” (depending on whether it’s found in A or B).</li> 
    </ol> 
    <p>Here’s how this might look:</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">tokens</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx">token</span> <span class="o">=</span> <span class="nx">tokens</span><span class="p">[</span><span class="nx">i</span><span class="p">].</span><span class="nx">toLowerCase</span><span class="p">();</span>
  <span class="k">if</span> <span class="p">(</span><span class="nx">dictionary</span><span class="p">[</span><span class="nx">token</span><span class="p">]</span> <span class="o">===</span> <span class="kc">undefined</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">dictionary</span><span class="p">[</span><span class="nx">token</span><span class="p">]</span> <span class="o">=</span> <span class="p">{};</span>
    <span class="nx">dictionary</span><span class="p">[</span><span class="nx">token</span><span class="p">].</span><span class="nx">countA</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="nx">dictionary</span><span class="p">[</span><span class="nx">token</span><span class="p">].</span><span class="nx">countB</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span>
    <span class="nx">dictionary</span><span class="p">[</span><span class="nx">token</span><span class="p">].</span><span class="nx">word</span> <span class="o">=</span> <span class="nx">token</span><span class="p">;</span>
  <span class="p">}</span> <span class="k">else</span> <span class="p">{</span>
    <span class="c1">// Which category are we training for?</span>
    <span class="k">if</span> <span class="p">(</span><span class="nx">category</span> <span class="o">===</span> <span class="s1">'A'</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">dict</span><span class="p">[</span><span class="nx">token</span><span class="p">].</span><span class="nx">countA</span><span class="o">++</span><span class="p">;</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">tokenCountA</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span> <span class="k">else</span> <span class="k">if</span> <span class="p">(</span><span class="nx">category</span> <span class="o">===</span> <span class="s1">'B'</span><span class="p">)</span> <span class="p">{</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">dict</span><span class="p">[</span><span class="nx">token</span><span class="p">].</span><span class="nx">countB</span><span class="o">++</span><span class="p">;</span>
      <span class="k">this</span><span class="p">.</span><span class="nx">tokenCountB</span><span class="o">++</span><span class="p">;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span></code></pre>
    </figure> 
    <p>The above steps are repeated over and over again for all training documents. Once all the “training” files are read, the probabilities can be calculated for every word.</p> 
    <p>Once we’ve gone through the process of counting the occurrences in each category (‘A’ or ‘B’, spam or ham, etc.), we can the calculate the probabilities according to Bayes rule.</p> 
    <figure class="highlight">
     <pre><code class="language-javascript" data-lang="javascript"><span class="c1">// Ok, assuming we have an array of keys</span>
<span class="k">for</span> <span class="p">(</span><span class="kd">var</span> <span class="nx">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="nx">i</span> <span class="o">&lt;</span> <span class="nx">keys</span><span class="p">.</span><span class="nx">length</span><span class="p">;</span> <span class="nx">i</span><span class="o">++</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nx">key</span> <span class="o">=</span> <span class="nx">keys</span><span class="p">[</span><span class="nx">i</span><span class="p">];</span>
  <span class="kd">var</span> <span class="nx">word</span> <span class="o">=</span> <span class="nx">dictionary</span><span class="p">[</span><span class="nx">key</span><span class="p">];</span>

  <span class="c1">// Average frequency per document</span>
  <span class="c1">// (this assumes we've counted total documents)</span>
  <span class="nx">word</span><span class="p">.</span><span class="nx">freqA</span> <span class="o">=</span> <span class="nx">word</span><span class="p">.</span><span class="nx">countA</span> <span class="o">/</span> <span class="nx">docCountA</span><span class="p">;</span>      
  <span class="nx">word</span><span class="p">.</span><span class="nx">freqB</span> <span class="o">=</span> <span class="nx">word</span><span class="p">.</span><span class="nx">countB</span> <span class="o">/</span> <span class="nx">docCountB</span><span class="p">;</span>      

  <span class="c1">// Probability via Bayes rule</span>
  <span class="nx">word</span><span class="p">.</span><span class="nx">probA</span> <span class="o">=</span> <span class="nx">word</span><span class="p">.</span><span class="nx">freqA</span> <span class="o">/</span> <span class="p">(</span><span class="nx">word</span><span class="p">.</span><span class="nx">freqA</span> <span class="o">+</span> <span class="nx">word</span><span class="p">.</span><span class="nx">freqB</span><span class="p">);</span>
  <span class="nx">word</span><span class="p">.</span><span class="nx">probB</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="nx">probA</span><span class="p">;</span>
<span class="p">}</span></code></pre>
    </figure> 
    <p>The above formula might look a little bit simpler to you than the original Bayes rule. This is because I am leaving out the “prior probability” and assuming that any document has a 50% chance of being category A or B.</p> 
    <p>Now, all that is left to do is take a new document, and compute the total probability for that document according to the formula specified in <a href="http://www.paulgraham.com/spam.html">Graham’s essay</a>. For this step, we need to calculate <a href="http://www.paulgraham.com/naivebayes.html">combined probability</a> as outlined by Graham. For more about combined probability, here’s <a href="http://www.mathpages.com/home/kmath267.htm">another resource</a>.</p> 
    <figure class="highlight">
     <pre><code class="language-java" data-lang="java"><span class="c1">// Combined probabilities</span>
<span class="c1">// http://www.paulgraham.com/naivebayes.html</span>
<span class="n">var</span> <span class="n">productA</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span>
<span class="n">var</span> <span class="n">productB</span> <span class="o">=</span> <span class="mi">1</span><span class="o">;</span>

<span class="c1">// Multiply probabilities together</span>
<span class="k">for</span> <span class="o">(</span><span class="n">var</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="o">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="n">words</span><span class="o">.</span><span class="na">length</span><span class="o">;</span> <span class="n">i</span><span class="o">++)</span> <span class="o">{</span>
  <span class="n">var</span> <span class="n">word</span> <span class="o">=</span> <span class="n">words</span><span class="o">[</span><span class="n">i</span><span class="o">];</span>
  <span class="n">productA</span> <span class="o">*=</span> <span class="n">word</span><span class="o">.</span><span class="na">probA</span><span class="o">;</span>
  <span class="n">productB</span> <span class="o">*=</span> <span class="n">word</span><span class="o">.</span><span class="na">probB</span><span class="o">;</span>
<span class="o">}</span>

<span class="c1">// Apply formula</span>
<span class="n">var</span> <span class="n">pA</span> <span class="o">=</span> <span class="n">productA</span> <span class="o">/</span> <span class="o">(</span><span class="n">productA</span> <span class="o">+</span> <span class="n">productB</span><span class="o">);</span></code></pre>
    </figure> 
    <p>Now we know the probability the document is in category A!</p> 
    <p>One important aspect of this analysis that I’ve left out is the “interesting-ness&amp;#8221 of any given word. An interesting rating is defined as how different, say, the spam probability is from 0.5 (i.e. 50/50 is as boring as it gets) or the absolute value of <code class="highlighter-rouge">probA - 0.5</code>. Graham’s spam filter, for example, only uses the probability of the top 15 most interesting words. If you are looking for an exercise, you might try adding this feature to the Bayesian classifier example.</p> 
    <iframe width="525" height="300" src="https://www.youtube.com/embed/6DoJob85jE0?list=PLRqwX-V7Uu6bZQkJcGM5S9fn9R9Yyd8iZ" frameborder="0" allowfullscreen></iframe> 
   </div> 
  </section> 
  <section class="right-container quick-links out"> 
   <div class="quick-link"> 
    <a href="/a2z/" class="secondary">About the course</a> 
   </div> 
   <h5>Tutorials</h5> 
   <div class="quick-link"> 
    <a href="/a2z/intro" class="secondary">Introduction - p5.js, JavaScript, and Strings</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/regex" class="secondary">Regular Expressions</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/closures" class="secondary">Closures</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/data-apis" class="secondary">Libraries, Data, and APIs</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/server-node" class="secondary">Server-side programming with node.js</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/twitter-bots" class="secondary">Twitter API and bots with node.js</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/bot-ec2" class="secondary">Deploy Bot to Amazon EC2</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/bot-heroku" class="secondary">Deploy Bot to Heroku</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/text-analysis" class="secondary">Text Analysis</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/markov" class="secondary">N-Grams and Markov Chains</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/cfg" class="secondary">Context-Free Grammar</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/node-api" class="secondary">Creating an API in Node</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/firebase" class="secondary">Database as Service: Firebase</a> 
   </div> 
   <div class="quick-link"> 
    <a href="/a2z/chrome-ext" class="secondary">Chrome Extensions</a> 
   </div> 
  </section> 
  <footer class="left-container about out"> 
   <div class="content-wrapper article"> 
    <p>Source code for this website can be found on <a href="https://github.com/shiffman/shiffman.net/" target="_blank">Github</a>.</p> 
   </div> 
  </footer> 
  <script>

  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-94163-1', 'auto');
  ga('send', 'pageview');

</script>   
 </body>
</html>