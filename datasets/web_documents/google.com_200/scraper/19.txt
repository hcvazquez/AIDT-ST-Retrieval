<!doctype html>
<html>
 <head> 
  <meta charset="utf-8"> 
  <meta http-equiv="X-UA-Compatible" content="IE=edge"> 
  <meta name="viewport" content="width=device-width, initial-scale=1"> 
  <title>Web Scraping in Node.js with Multiple Examples - Hack Programming</title> 
  <script src="/cdn-cgi/apps/head/vxUkfPS_keAudLGePOWPgYnhbB4.js"></script>
  <link href="/favicon.ico" rel="shortcut icon"> 
  <link href="/assets/css/main.min.css?v=a5e7cebcaf" rel="stylesheet"> 
  <link href="https://fonts.googleapis.com/css?family=Fira+Mono|Work+Sans" rel="preconnect stylesheet"> 
  <link href="/assets/icons/styles.css?v=a5e7cebcaf" rel="stylesheet"> 
  <link rel="shortcut icon" href="/favicon.ico" type="image/x-icon"> 
  <link rel="canonical" href="https://hackprogramming.com/web-scraping-in-node-js-with-multiple-examples/"> 
  <meta name="referrer" content="no-referrer-when-downgrade"> 
  <meta property="og:site_name" content="Hack Programming"> 
  <meta property="og:type" content="article"> 
  <meta property="og:title" content="Web Scraping in Node.js with Multiple Examples"> 
  <meta property="og:description" content="Web scraping which can be used for things like email collection, creating a news feed reader, comparing product price from multiple e-commerce sites, data mining from search engines is an alternate way to extract data from the websites which doesn't provide an api for access information. So, whenever possible make"> 
  <meta property="og:url" content="https://hackprogramming.com/web-scraping-in-node-js-with-multiple-examples/"> 
  <meta property="og:image" content="https://hackprogramming.com/content/images/2017/03/post11-poster.jpg"> 
  <meta property="article:published_time" content="2017-03-08T15:04:00.000Z"> 
  <meta property="article:modified_time" content="2017-04-14T13:30:05.000Z"> 
  <meta property="article:tag" content="nodejs"> 
  <meta property="article:tag" content="javascript"> 
  <meta property="article:publisher" content="https://www.facebook.com/hackprogramming"> 
  <meta name="twitter:card" content="summary_large_image"> 
  <meta name="twitter:title" content="Web Scraping in Node.js with Multiple Examples"> 
  <meta name="twitter:description" content="Web scraping which can be used for things like email collection, creating a news feed reader, comparing product price from multiple e-commerce sites, data mining from search engines is an alternate way to extract data from the websites which doesn't provide an api for access information. So, whenever possible make"> 
  <meta name="twitter:url" content="https://hackprogramming.com/web-scraping-in-node-js-with-multiple-examples/"> 
  <meta name="twitter:image" content="https://hackprogramming.com/content/images/2017/03/post11-poster.jpg"> 
  <meta name="twitter:label1" content="Written by"> 
  <meta name="twitter:data1" content="Ashish Rawat"> 
  <meta name="twitter:label2" content="Filed under"> 
  <meta name="twitter:data2" content="nodejs, javascript"> 
  <meta property="og:image:width" content="1000"> 
  <meta property="og:image:height" content="600"> 
  <script type="application/ld+json">
{
    "@context": "https://schema.org",
    "@type": "Article",
    "publisher": {
        "@type": "Organization",
        "name": "Hack Programming",
        "logo": {
            "@type": "ImageObject",
            "url": "https://hackprogramming.com/content/images/2017/04/new-logo.png",
            "width": 60,
            "height": 60
        }
    },
    "author": {
        "@type": "Person",
        "name": "Ashish Rawat",
        "url": "https://hackprogramming.com/author/eashish/",
        "sameAs": []
    },
    "headline": "Web Scraping in Node.js with Multiple Examples",
    "url": "https://hackprogramming.com/web-scraping-in-node-js-with-multiple-examples/",
    "datePublished": "2017-03-08T15:04:00.000Z",
    "dateModified": "2017-04-14T13:30:05.000Z",
    "image": {
        "@type": "ImageObject",
        "url": "https://hackprogramming.com/content/images/2017/03/post11-poster.jpg",
        "width": 1000,
        "height": 600
    },
    "keywords": "nodejs, javascript",
    "description": "Web scraping which can be used for things like email collection, creating a news feed reader, comparing product price from multiple e-commerce sites, data mining from search engines is an alternate way to extract data from the websites which doesn&#x27;t provide an api for access information. So, whenever possible make",
    "mainEntityOfPage": {
        "@type": "WebPage",
        "@id": "https://hackprogramming.com/"
    }
}
    </script> 
  <script type="text/javascript" src="/public/ghost-sdk.min.js?v=a5e7cebcaf"></script> 
  <script type="text/javascript">
ghost.init({
	clientId: "ghost-frontend",
	clientSecret: "779cc139ceb2"
});
</script> 
  <meta name="generator" content="Ghost 1.8"> 
  <link rel="alternate" type="application/rss+xml" title="Hack Programming" href="https://hackprogramming.com/rss/"> 
 </head> 
 <body class="post-template tag-nodejs tag-javascript"> 
  <div id="root"> 
   <header class="blog-head mb-5"> 
    <div class="container blog-head-inner"> 
     <a href="https://hackprogramming.com" class="h1 blog-logo"> 
      <svg width="56px" height="47px" viewbox="0 0 51 42" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink"> 
       <g id="Page-1" stroke="none" stroke-width="1" fill="none" fill-rule="evenodd"> 
        <g id="hackprogramming" transform="translate(-153.000000, -19.000000)"> 
         <g id="official-logo" transform="translate(153.000000, 19.000000)"> 
          <g id="h"> 
           <path d="M25.928,27.7650909 C25.608,24.3730909 24.264,21.6210909 21.768,19.3810909 C19.336,17.1410909 16.392,16.0530909 13,16.0530909 C9.288,16.0530909 6.152,17.3970909 3.592,20.1490909 L3.592,2.74109091 C3.592,1.58909091 3.016,1.01309091 1.864,1.01309091 C0.776,1.01309091 0.2,1.58909091 0.2,2.74109091 L0.2,40.1170909 C0.2,41.2690909 0.776,41.8450909 1.864,41.8450909 C3.016,41.8450909 3.592,41.2690909 3.592,40.1170909 L3.592,27.7650909 C4.168,22.9650909 8.136,19.4450909 13,19.4450909 C15.624,19.4450909 17.864,20.3410909 19.72,22.1330909 C21.576,23.8610909 22.536,26.1010909 22.536,28.7250909 L22.536,40.1170909 C22.536,41.2050909 23.112,41.7810909 24.264,41.7810909 C25.352,41.7810909 25.928,41.2050909 25.928,40.1170909 L25.928,27.7650909 Z" fill="#787878"></path> 
           <path d="M23.2890788,15.0413582 C23.9473641,13.9641642 24.7346764,13.1544106 25.6510395,12.6120733 C26.5674025,12.069736 27.4070777,11.7985714 28.1700901,11.7985714 C29.2472842,11.7985714 30.2141262,12.2623564 31.0706451,13.1899402 C31.927164,14.117524 32.3554171,15.5238396 32.3554171,17.4089292 C32.3554171,18.8975516 32.0711618,20.2271931 31.5026427,21.3978937 C30.9341236,22.5685942 30.1729926,23.4924239 29.219227,24.1694104 C28.2654614,24.846397 27.0891682,25.1848852 25.690312,25.1848852 C25.2863642,25.1848852 24.6729712,25.143743 23.8501146,25.0614573 C23.7229459,25.0464963 23.5359358,25.0277953 23.2890788,25.0053537 L23.2890788,29.9985722 L21.1571429,29.9985722 L21.1571429,12.1576343 L23.2890788,12.1576343 L23.2890788,15.0413582 Z M23.2890788,17.5884607 L23.2890788,23.0978321 C24.0670523,23.2923255 24.7814308,23.3895707 25.4322355,23.3895707 C26.7263645,23.3895707 27.8166332,22.8827734 28.7030741,21.8691637 C29.5895151,20.855554 30.0327289,19.4660693 30.0327289,17.7006679 C30.0327289,16.4214999 29.791486,15.4583981 29.3089928,14.8113336 C28.8264996,14.1642691 28.2785601,13.8407417 27.6651579,13.8407417 C26.9993921,13.8407417 26.2644426,14.1792299 25.4602873,14.8562164 C24.656132,15.533203 23.9324031,16.443942 23.2890788,17.5884607 Z M37.1298316,25.0053537 L37.1298316,12.1576343 L39.2729883,12.1576343 L39.2729883,14.9628132 C39.9387541,13.9005802 40.7036252,13.1076575 41.5676246,12.5840215 C42.431624,12.0603855 43.3909856,11.7985714 44.4457382,11.7985714 C45.2237117,11.7985714 46.0016735,11.9182579 46.779647,12.1576343 L46.779647,16.7917899 L44.7150354,16.7917899 L44.7150354,13.8519624 C44.3559707,13.7921183 44.0717154,13.7621967 43.862261,13.7621967 C43.0693264,13.7621967 42.2876244,14.0763736 41.5171314,14.7047368 C40.7466384,15.3331 39.9985982,16.2793709 39.2729883,17.5435778 L39.2729883,25.0053537 L37.1298316,25.0053537 Z M56.0647893,25.3644166 C54.2245827,25.3644166 52.7509434,24.721102 51.6438273,23.4344535 C50.5367111,22.1478051 49.9831614,20.528298 49.9831614,18.5758837 C49.9831614,16.6159889 50.5367111,14.9964818 51.6438273,13.7173138 C52.7509434,12.4381458 54.2245827,11.7985714 56.0647893,11.7985714 C57.8975153,11.7985714 59.3655442,12.4381458 60.4689201,13.7173138 C61.572296,14.9964818 62.1239757,16.6159889 62.1239757,18.5758837 C62.1239757,20.528298 61.572296,22.1478051 60.4689201,23.4344535 C59.3655442,24.721102 57.8975153,25.3644166 56.0647893,25.3644166 Z M56.0647893,23.5803228 C57.2018275,23.5803228 58.1088262,23.1352389 58.7858128,22.2450577 C59.4627994,21.3548765 59.8012876,20.1318307 59.8012876,18.5758837 C59.8012876,17.0274172 59.4627994,15.8081116 58.7858128,14.9179304 C58.1088262,14.0277492 57.2018275,13.5826652 56.0647893,13.5826652 C54.91279,13.5826652 53.9983108,14.0277492 53.3213243,14.9179304 C52.6443377,15.8081116 52.3058495,17.0274172 52.3058495,18.5758837 C52.3058495,20.1318307 52.6443377,21.3548765 53.3213243,22.2450577 C53.9983108,23.1352389 54.91279,23.5803228 56.0647893,23.5803228 Z" id="pro" fill="#FFFFFF" transform="translate(41.640559, 20.898572) rotate(270.000000) translate(-41.640559, -20.898572) "></path> 
          </g> 
         </g> 
        </g> 
       </g> 
      </svg> </a> 
     <nav class="blog-nav"> 
      <ul class="nav"> 
       <li class="nav-about" role="presentation"><a href="https://hackprogramming.com/about/">About</a></li> 
       <li class="nav-posts" role="presentation"><a href="https://hackprogramming.com/">Posts</a></li> 
      </ul> 
     </nav> 
    </div> 
   </header> 
   <main id="content" class="content container mb-5" role="main"> 
    <div id="tags-slug-recent" style="display: none">
     nodejs,javascript,
    </div> 
    <header class="post-header post text-center mb-4"> 
     <h1 class="post-title font-weight-bold mb-3">Web Scraping in Node.js with Multiple Examples</h1> 
     <div class="post-meta mb-2">
       &nbsp;By 
      <a href="/author/eashish/">Ashish Rawat</a>&nbsp; 
      <i class="ti-circle" style="font-size:6.5px; color: #616161"></i>&nbsp; posted on&nbsp;
      <time class="post-date" datetime="03-08-17">08 Mar 2017</time> &nbsp;
      <i class="ti-circle" style="font-size:6.5px; color: #616161"></i> &nbsp;
      <a href="/tag/nodejs/">nodejs</a>,&nbsp;
      <a href="/tag/javascript/">javascript</a> 
     </div> 
    </header> 
    <div class="row justify-content-center"> 
     <article class="col-md-10 post tag-nodejs tag-javascript"> 
      <div class="post-content mt-3 mb-5"> 
       <div class="kg-card-markdown">
        <p>Web scraping which can be used for things like email collection, creating a news feed reader, comparing product price from multiple e-commerce sites, data mining from search engines is an alternate way to extract data from the websites which doesn't provide an api for access information. So, whenever possible make sure you use the api from getting their data as it doesn't involve parsing the whole page and also less time-consuming. Also, don't perform any kind of illegal scraping which may harm the website owner.<br> Before I'll write some examples, I want to tell you how it works fundamentally. Basically what a simple scraper does is send a <em>GET</em> request to the page, receives the data in html/xml format and then using the parser to extract the data in whatever format you want. <strong>WGET</strong> is one such utility for doing that using the terminal and there are various free and paid tools available on the web.<br> In this post, I'll use the <a href="https://github.com/rchipka/node-osmosis">osmosis</a> package written in node.js which packed with css3/xpath selector and lightweight http wrapper. There are also other high level web automation frameworks available like <em><a href="http://webdriver.io">webdriver.io</a></em>, <em>casperjs</em>. But for most of the cases, it suits my need. This whole post gives you multiple examples to get started with web scraping.</p> 
        <h4 id="settinguptheproject">Setting up the project</h4> 
        <ol> 
         <li>Install <em>node.js</em> which comes with npm package manager</li> 
         <li>Create a new folder say <strong>webscrap</strong>. CD into it.</li> 
         <li>Run <code>npm init</code> from the terminal to create the <em>package.json</em> file.</li> 
         <li>Finally run <code>npm i osmosis --save</code> to install the web scraping package. It depends on lightweight http wrapper and xml parser so you don't need extra dependency other than this.</li> 
        </ol> 
        <p>Now open the <em>package.json</em> and create a new start script for <code>npm start</code> command. Final <em>package.json</em> will look something like this:</p> 
        <pre><code class="language-json">{   
      "name": "webscrap",
      "version": "1.0.0",
      "main": "index.js",
      "scripts": {
        "start": "node index"
      },
      "dependencies": {
        "osmosis": "^1.1.2"
      }
}
</code></pre> 
        <p>Also, create a new <em>index.js</em> file where we'll do all our work.</p> 
        <div class="small alert alert-warning">
          Note that at the time of writing, the selectors for selecting the block of data is in working condition, but in future these selector may get invalid response due to updated page but the logic remains the same unless library gets updated. 
        </div> 
        <h4 id="scrapinggoogletitletag">Scraping Google Title Tag</h4> 
        <p>This is the most basic example which will also introduce you to the <a href="https://github.com/rchipka/node-osmosis">osmosis</a> package and let the first node script up and running. Put the below code inside <em>index.js</em> file and do <code>npm start</code> from terminal. It will output the title of the webpage.</p> 
        <pre><code class="language-js">const osmosis = require('osmosis');
osmosis
    .get('www.google.com')
    .set({'Title': 'title'})   // or alternate: `.find('title').set('Title')`
    .data(console.log)  // will output {'Title': 'Google'}
</code></pre> 
        <p>Let's see what these methods do. First <code>get</code> method will fetch the webpage in compressed format. Next <code>set</code> method will<br> select the <strong>title</strong> element given as a css3 selector to the value of object property. And finally <code>data</code> method along with <code>console.log</code> print the output. The <code>set</code> method also accept string as an argument.<br> Although I'll cover most of the methods in this tutorial, you may better read the concise documenation from the <a href="https://github.com/rchipka/node-osmosis" target="_blank">official doc</a>.</p> 
        <h4 id="gettingrelatedsearchesfromgoogle">Getting Related Searches From Google</h4> 
        <p>Suppose we want to get the related searches of <em>analytics</em> keyword from google, we will do the following:</p> 
        <pre><code class="language-js">osmosis
    .get('https://www.google.co.in/search?q=analytics')
    .find('#botstuff')
    .set({'related': ['.card-section .brs_col p a']})
    .data(function(data) {
        console.log(data);
    })
</code></pre> 
        <p>That's it. Pretty simple. It will extract all the keywords from the first page of search, store in array and log them in the terminal. And the logic behind it is easy, we first analyse the web page through developer tools, check the block where it's is present, (in this case it is in the <code>#botstuff</code> div block) and store it in array through <code>.card-section .brs_col p a</code> selector which match every related keywords present on that page.</p> 
        <h4 id="combiningpaginationandrelatedsearches">Combining Pagination and Related Searches</h4> 
        <p>And that's is too easy with this library, we just have to add chain-able method to this by finding the href of anchor (<code>&lt;a&gt;</code>) tag.<br> We also limit the pagination to <code>5</code>, so that google doesn't detect me as a bot. If you need some time interval after every page scrap, you can attach <code>.delay(ms)</code> method after every <code>.paginate()</code>.</p> 
        <pre><code class="language-js">osmosis
   .get('https://www.google.co.in/search?q=analytics')
   .paginate('#navcnt table tr &gt; td a[href]', 5)
   .find('#botstuff')
   .set({'related': ['.card-section .brs_col p a']})
   .data(console.log)
   .log(console.log) // enable logging
   .error(console.error) // in case there is an error found.
</code></pre> 
        <h4 id="scrapingemailsfromtheshopify">Scraping emails from the shopify.</h4> 
        <p>This example will tell you how you can get the content of a single combining with multiple blocks of front page content. In this<br> case, we will collect emails and app name of all the apps, traversing one by one with a <code>.follow</code> method and then mark the appropriate selectors from developer console.<br> You can combine the below code with <code>.paginate</code> method also to wholly scrap all the content except they don't block you.</p> 
        <pre><code class="language-js">osmosis
   .get('http://apps.shopify.com/categories/sales')
   .find('.resourcescontent ul.app-card-grid')
   .follow('li a[href]')
   .find('.resourcescontent')
   .set({
       'appname': '.app-header__details h1',
       'email': '#AppInfo table tbody tr:nth-child(2) td &gt; a'
    })
   .log(console.log)   // enable logging to see what is does.
   .data(console.log)
</code></pre> 
        <p>Probably, you need to save this data in the a file or something which can be done like this. Example from above modified code (saved in json format).</p> 
        <pre><code class="language-js">const fs = require('fs');
let savedData = [];
osmosis
   .get(..).find(..).follow(..).find(..)
   .set(..)
   .log(console.log)
   .data(function(data) {
      console.log(data);
      savedData.push(data);
   })
   .done(function() {
      fs.writeFile('data.json', JSON.stringify( savedData, null, 4), function(err) {
        if(err) console.error(err);
        else console.log('Data Saved to data.json file');
      })
   });
</code></pre> 
        <p><em>Finally the tutorial is completed. Hope you like it. Feel free to write in the comments below if you're having any problems in the above snippets.</em></p> 
       </div> 
      </div> 
      <div class="related-posts"> 
       <h4 class="title mb-4"><span>You might also like:</span></h4> 
       <div class="lists"> 
       </div> 
      </div> 
      <div id="disqus_thread"></div> 
      <script>
                var disqus_config = function () {
                    this.page.url = 'https://hackprogramming.com/web-scraping-in-node-js-with-multiple-examples/'
                    this.page.identifier = 'ghost-22';
                };
                (function() { // DON'T EDIT BELOW THIS LINE
                    var d = document, s = d.createElement('script');
                    s.src = '//hackprogramming.disqus.com/embed.js';
                    s.setAttribute('data-timestamp', +new Date());
                    (d.head || d.body).appendChild(s);
                })();
            </script> 
      <noscript>
       Please enable JavaScript to view the 
       <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
      </noscript> 
     </article> 
    </div> 
   </main> 
   <footer class="blog-foot"> 
    <div class="container"> 
     <div class="row"> 
      <div class="info col-md-6"> 
       <p class="small">Copyright © 2017, Hackprogramming.com | All Rights Reserved.</p> 
       <ul class="social list-unstyled"> 
        <li><a href="https://www.facebook.com/hackprogramming" target="_blank"><i class="ti-facebook"></i></a></li> 
        <li><a href="https://plus.google.com/collection/cBHwmB" target="_blank"><i class="ti-google"></i></a></li> 
        <li><a href="https://github.com/eashish93" target="_blank"><i class="ti-github"></i></a></li> 
        <li><a href="https://hackprogramming.com/rss" target="_blank"><i class="ti-rss"></i></a></li> 
       </ul> 
      </div> 
      <div class="blog-tags col-md-6"> 
       <h4 class="h6 title"><span>Popular Tags</span></h4> 
       <a href="/tag/javascript/">javascript</a>&nbsp;
       <a href="/tag/nodejs/">nodejs</a>&nbsp;
       <a href="/tag/linux/">linux tricks</a>&nbsp;
       <a href="/tag/how-to/">how to's</a>&nbsp;
       <a href="/tag/nginx/">nginx</a>&nbsp;
       <a href="/tag/react/">react</a> 
      </div> 
     </div> 
    </div> 
   </footer> 
  </div> 
  <script type="text/javascript" src="/assets/js/build.min.js?v=a5e7cebcaf"></script>   
 </body>
</html>