<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>
 <head>
  <meta http-equiv="Content-Type" content="text/html; charset=ISO-8859-1">
  <meta content="Website XSL Stylesheet V2.6.0" name="generator">
  <link rel="home" href="index.html" title="Java Sound Resources">
  <link rel="up" href="faq.html" title="Java Sound Resources: Frequently Asked Questions">
  <link rel="previous" href="faq_general.html" title="Java Sound Resources: FAQ: General">
  <link rel="next" href="faq_midi.html" title="Java Sound Resources: FAQ: MIDI Programming">
  <link rel="first" href="faq_general.html" title="Java Sound Resources: FAQ: General">
  <link rel="last" href="faq_misc.html" title="Java Sound Resources: FAQ: Miscellaneous">
  <link href="style.css" rel="stylesheet" type="text/css"> 
  <title>Java Sound Resources: FAQ: Audio Programming</title> 
  <meta content="Java, Sound, Java Sound, JavaSound, Frequently Asked
      Questions, FAQ" name="keyword"> 
 </head>
 <body class="tabular" bgcolor="white" text="black" link="#0000FF" vlink="#840084" alink="#0000FF">
  <div class="webpage">
   <a name="faq_audio"></a>
   <table border="0" cellpadding="0" cellspacing="0" width="100%" summary="Navigation">
    <tbody>
     <tr>
      <td valign="top" align="left" bgcolor="#E0E0E0"><img height="1" width="1" alt=" " src="graphics/spacer.gif"></td>
      <td valign="top" align="left" bgcolor="white" rowspan="2"><h1>Java Sound Resources: FAQ: Audio Programming</h1><p>This page presents Questions and Answers related to the <a href="http://www.javasoft.com/products/java-media/sound/index.html" target="_top">Java Sound API</a>.</p>
       <div class="qandaset">
        <h2 class="title">Audio Programming</h2>
        <dl>
         <dt>
          1. 
          <a href="#sec_dataline">DataLines</a>
         </dt>
         <dd>
          <dl>
           <dt>
            1.1. 
            <a href="#sec_line_general">General</a>
           </dt>
           <dd>
            <dl>
             <dt>
              1.1.1. 
              <a href="#dataline_notification">How can I be notified when data is available for write/read in a SourceDataLine or TargetDataLine?</a>
             </dt>
             <dt>
              1.1.2. 
              <a href="#not_16k_line">Why does it fail to open any line with 16 kHz sample rate?</a>
             </dt>
             <dt>
              1.1.3. 
              <a href="#mulaw_line">How can I get a SourceDataLine or TargetDataLine in &#x3bc;-law format?</a>
             </dt>
             <dt>
              1.1.4. 
              <a href="#duplex_open_order">Why does simultaneous recording and playback only work when first opening the playback line (SourceDataLine)?</a>
             </dt>
             <dt>
              1.1.5. 
              <a href="#linux_duplex">Why doesn't simultaneous recording and playback work at all with the Sun JDK 1.3/1.4 on GNU/Linux?</a>
             </dt>
             <dt>
              1.1.6. 
              <a href="#select_mixer">How can I get a Line from a specific Mixer?</a>
             </dt>
             <dt>
              1.1.7. 
              <a href="#dad_mono_lines">Why are there no mono lines with the "Direct Audio Devices" mixers on Linux?</a>
             </dt>
             <dt>
              1.1.8. 
              <a href="#source_target">Why is a SourceDataLine called "source" and a TargetDataLine called "target" though it's actually the other way round?</a>
             </dt>
             <dt>
              1.1.9. 
              <a href="#dataline_getposition">Why are DataLine.getFramePosition() and DataLine.getMicrosecondPosition() so inaccurate?</a>
             </dt>
             <dt>
              1.1.10. 
              <a href="#dataline_getlevel">Why does DataLine.getLevel() always return -1?</a>
             </dt>
             <dt>
              1.1.11. 
              <a href="#active_vs_running">What is the difference between DataLine.isActive() and DataLine.isRunning()?</a>
             </dt>
             <dt>
              1.1.12. 
              <a href="#detect_underrun">How can I detect a buffer underrun or overrun?</a>
             </dt>
             <dt>
              1.1.13. 
              <a href="#underrun_event">Why is there no event for notifying applications of an underrun/overrun condition?</a>
             </dt>
             <dt>
              1.1.14. 
              <a href="#line_position">How can I find out the current playback or recording position?</a>
             </dt>
             <dt>
              1.1.15. 
              <a href="#looping_playback">How can I do looping in playback?</a>
             </dt>
            </dl>
           </dd>
           <dt>
            1.2. 
            <a href="#sec_sourcedataline">SourceDataLine</a>
           </dt>
           <dd>
            <dl>
             <dt>
              1.2.1. 
              <a href="#sdl_repeat">How can I avoid that the last bit of sound played on a SourceDataLine is repeated?</a>
             </dt>
             <dt>
              1.2.2. 
              <a href="#wrong_open">Why is playback distorted, too fast or too slow with the JDK 1.5.0 beta, but not with earlier versions of the JDK?</a>
             </dt>
            </dl>
           </dd>
           <dt>
            1.3. 
            <a href="#sec_targetdataline">TargetDataLine</a>
           </dt>
           <dd>
            <dl>
             <dt>
              1.3.1. 
              <a href="#capture_source">How can I capture from a specific source (microphone or line-in)?</a>
             </dt>
             <dt>
              1.3.2. 
              <a href="#multiple_tdl_per_card">How can I get more than one TargetDataLine?</a>
             </dt>
             <dt>
              1.3.3. 
              <a href="#multiple_tdl">Why is in not possible to open more than one TargetDataLine at the same time?</a>
             </dt>
             <dt>
              1.3.4. 
              <a href="#established_device_format">Why do I get a LineUnavailableException: "Requested format incompatible with already established device format"?</a>
             </dt>
             <dt>
              1.3.5. 
              <a href="#recording_volume">How can I control the volume when recording with a TargetDataLine?</a>
             </dt>
             <dt>
              1.3.6. 
              <a href="#stop_drain_tdl">How should I use stop() and drain() on a TargetDataLine?</a>
             </dt>
             <dt>
              1.3.7. 
              <a href="#read_blocking">Why is TargetDataLine.read() blocking for a long time?</a>
             </dt>
             <dt>
              1.3.8. 
              <a href="#recordings_cutoff">Why is the end of recordings cut off prematurely?</a>
             </dt>
            </dl>
           </dd>
           <dt>
            1.4. 
            <a href="#sec_clip">Clip</a>
           </dt>
           <dd>
            <dl>
             <dt>
              1.4.1. 
              <a href="#big_clip">Why do I get an out of memory exception when trying to use a Clip with a 5 MB audio file?</a>
             </dt>
             <dt>
              1.4.2. 
              <a href="#no_free_voices">Why do I get "LineUnavailableException: No Free Voices" when opening a Clip?</a>
             </dt>
             <dt>
              1.4.3. 
              <a href="#clip_rewind">How can I rewind a Clip?</a>
             </dt>
             <dt>
              1.4.4. 
              <a href="#clip_no_position_reset">Why does the frame/microsecond position not jump back to zero when a Clip is looped?</a>
             </dt>
             <dt>
              1.4.5. 
              <a href="#clip_play_multiple">Why are there failures, clicks and other random effects if a clip is played multiple times with 1.5?</a>
             </dt>
            </dl>
           </dd>
          </dl>
         </dd>
         <dt>
          2. 
          <a href="#sec_controls">Controls</a>
         </dt>
         <dd>
          <dl>
           <dt>
            2.1. 
            <a href="#controls_of_dad_line">Why does the SourceDataLine instances I get when using the "Direct Audio Device" (ALSA on Linux) have no controls?</a>
           </dt>
           <dt>
            2.2. 
            <a href="#balance_vs_pan">What is the difference between a BALANCE and a PAN control? Which one should I use?</a>
           </dt>
           <dt>
            2.3. 
            <a href="#controls_of_mono_line">Why do mono lines from a "Direct Audio Device" have no PAN control?</a>
           </dt>
           <dt>
            2.4. 
            <a href="#controls_after_open">Why does obtaining a gain control work with 1.4.2, but not with 1.5.0?</a>
           </dt>
           <dt>
            2.5. 
            <a href="#no_volume_control">Why do Clip and SourceDataLine instances have no VOLUME control?</a>
           </dt>
           <dt>
            2.6. 
            <a href="#no_sr_control">Why is there no sample rate control in 1.5.0?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          3. 
          <a href="#sec_buffers">DataLine buffers</a>
         </dt>
         <dd>
          <dl>
           <dt>
            3.1. 
            <a href="#min_buffersize">What is the minimum buffer size I can use?</a>
           </dt>
           <dt>
            3.2. 
            <a href="#default_buffersize">Why does a line have the default buffer size though a buffer size was specified in a DataLine.Info object when obtaining the line?</a>
           </dt>
           <dt>
            3.3. 
            <a href="#large_buffers">Why is it not possible to use large buffers for a DataLine with 1.5.0?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          4. 
          <a href="#sec_mixers">Mixers</a>
         </dt>
         <dd>
          <dl>
           <dt>
            4.1. 
            <a href="#mixers">What are all these mixers?</a>
           </dt>
           <dt>
            4.2. 
            <a href="#no_sdl_from_mixer">Why are there mixers from which I can't get a SourceDataLine?</a>
           </dt>
           <dt>
            4.3. 
            <a href="#phone_output">How can I redirect sound output to a phone / modem device?</a>
           </dt>
           <dt>
            4.4. 
            <a href="#multiple_soundcards">Can I use multiple soundcards at the same time?</a>
           </dt>
           <dt>
            4.5. 
            <a href="#only_jsae_playback">Why can I record from different soundcards, but not play back to them?</a>
           </dt>
           <dt>
            4.6. 
            <a href="#supported_formats">How can I obtain the formats supported by a mixer (or at all)?</a>
           </dt>
           <dt>
            4.7. 
            <a href="#dad_supported_formats">What formats are supported by "Direct Audio Device" mixers?</a>
           </dt>
           <dt>
            4.8. 
            <a href="#sr_unspecified">Why are there AudioFormat objects with frame rate/sample rate reported as -1 when I query a Mixer for its supported formats?</a>
           </dt>
           <dt>
            4.9. 
            <a href="#match_port_mixer">How can I detect which Port Mixer belongs to which soundcard?</a>
           </dt>
           <dt>
            4.10. 
            <a href="#which_mixer_used">How can I find out which Mixer implementation is used?</a>
           </dt>
           <dt>
            4.11. 
            <a href="#why_jsae_default">Why do I get lines from the "Java Sound Audio Engine" in the JDK 1.5.0 though the "Direct Audio Device" mixers are available, too?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          5. 
          <a href="#sec_drivers">Soundcard Drivers</a>
         </dt>
         <dd>
          <dl>
           <dt>
            5.1. 
            <a href="#which_driver_possible">Which soundcard drivers can be used by Java Sound?</a>
           </dt>
           <dt>
            5.2. 
            <a href="#which_driver_used">How can I find out which soundcard driver is used?</a>
           </dt>
           <dt>
            5.3. 
            <a href="#use_alsa">I've installed ALSA and the JDK 1.4.2 to take advantage of the ALSA support. Now, how do I use it?</a>
           </dt>
           <dt>
            5.4. 
            <a href="#alsa_default">Can I make ALSA the default in version 1.4.2?</a>
           </dt>
           <dt>
            5.5. 
            <a href="#alsa_mixing">How can I enable mixing with the "Direct Audio Device" mixers on Linux?</a>
           </dt>
           <dt>
            5.6. 
            <a href="#req_direct_audio">What are the requirements for using the direct audio devices?</a>
           </dt>
           <dt>
            5.7. 
            <a href="#which_linux_driver">How can I find out which soundcard driver is installed on my Linux system?</a>
           </dt>
           <dt>
            5.8. 
            <a href="#hardware_buffers">How does Java Sound deal with hardware buffers of the soundcard?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          6. 
          <a href="#sec_synchronization">Synchronization</a>
         </dt>
         <dd>
          <dl>
           <dt>
            6.1. 
            <a href="#sync_playback">How can I synchronize two or more playback lines?</a>
           </dt>
           <dt>
            6.2. 
            <a href="#sync_playback_recording">How can I synchronize playback (SourceDataLines) with recording (TargetDataLines)?</a>
           </dt>
           <dt>
            6.3. 
            <a href="#sync_playback_externally">How can I synchronize playback to an external clock?</a>
           </dt>
           <dt>
            6.4. 
            <a href="#sync_clip">Do multiple Clip instances that are looped stay in sync?</a>
           </dt>
           <dt>
            6.5. 
            <a href="#clock_drift">Why does recording or playing for a certain period of time results in audio data that is shorter or longer than the period I recorded / played?</a>
           </dt>
           <dt>
            6.6. 
            <a href="#mixer_synchronize">How can I use Mixer.synchronize()?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          7. 
          <a href="#sec_files">Audio Files</a>
         </dt>
         <dd>
          <dl>
           <dt>
            7.1. 
            <a href="#save_audio_data">How can I save audio data to a file, like .wav or .aiff?</a>
           </dt>
           <dt>
            7.2. 
            <a href="#add_chunks">How can I add special chunks to .wav or .aiff files (like for a descriptive text or copyright)?</a>
           </dt>
           <dt>
            7.3. 
            <a href="#read_looppoints">Is it possible to get information about loop points (e.g. from the 'smpl' chunk in .wav files) using the AudioFileFormat properties?</a>
           </dt>
           <dt>
            7.4. 
            <a href="#getframelength">Why does AudioFileFormat.getFrameLength() always return -1 for .wav files?</a>
           </dt>
           <dt>
            7.5. 
            <a href="#8bit_signed_wav">Why does a .wav file contain PCM_UNSIGNED data if I try to save 8 bit PCM_SIGNED data?</a>
           </dt>
           <dt>
            7.6. 
            <a href="#read_vox">How can I read in a .vox file and save it as .wav file?</a>
           </dt>
           <dt>
            7.7. 
            <a href="#read_headerless">How can I read from a headerless audio file?</a>
           </dt>
           <dt>
            7.8. 
            <a href="#file_length">How can I determine the length or the duration of an audio file?</a>
           </dt>
           <dt>
            7.9. 
            <a href="#write_parts">How can I write an audio file in smaller parts?</a>
           </dt>
           <dt>
            7.10. 
            <a href="#wav_not_recognized">Why are some .wav files not recognized by Java Sound?</a>
           </dt>
           <dt>
            7.11. 
            <a href="#big_endian_wav">Why is it not possible to write big-endian data using a WaveAudioOutputStream?</a>
           </dt>
           <dt>
            7.12. 
            <a href="#edit_file">How can I edit or modify audio files?</a>
           </dt>
           <dt>
            7.13. 
            <a href="#audio_data_cached">How can I play audio files where the data is cached in the RAM?</a>
           </dt>
           <dt>
            7.14. 
            <a href="#write_file_vs_outputstream">Why is there a difference between using AudioSystem.write(..., File) and using AudioSystem.write(..., OutputStream) with a FileOutputStream?</a>
           </dt>
           <dt>
            7.15. 
            <a href="#aos_docs">Where can I find documentation on the AudioOutputStream programming?</a>
           </dt>
           <dt>
            7.16. 
            <a href="#ais_skip">How can I start playback of a file at a certain position?</a>
           </dt>
           <dt>
            7.17. 
            <a href="#multichannel_files">Is it possible to read and write multichannel audio files?</a>
           </dt>
           <dt>
            7.18. 
            <a href="#compare_files">How can I compare two audio files?</a>
           </dt>
           <dt>
            7.19. 
            <a href="#overwrite_file">Is it possible to insert recorded audio data into an existing file?</a>
           </dt>
           <dt>
            7.20. 
            <a href="#file_in_bytearray">How can I store an audio file in a byte array?</a>
           </dt>
           <dt>
            7.21. 
            <a href="#aos_unknown_length">Which value should I use for the length of the file in AudioOutputStreams if the length is not known in advance?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          8. 
          <a href="#sec_audioformat">Sample Representation and AudioFormat</a>
         </dt>
         <dd>
          <dl>
           <dt>
            8.1. 
            <a href="#digital_audio_representation">How is audio represented digitally?</a>
           </dt>
           <dt>
            8.2. 
            <a href="#floating_point">In which cases should I use a floating point representation for audio data?</a>
           </dt>
           <dt>
            8.3. 
            <a href="#frame_rate">What is the meaning of frame rate in AudioFormat?</a>
           </dt>
           <dt>
            8.4. 
            <a href="#frame_size">What is the meaning of frame size in Audioformat?</a>
           </dt>
           <dt>
            8.5. 
            <a href="#signedness">What is signed / unsigned?</a>
           </dt>
           <dt>
            8.6. 
            <a href="#unsigned_in_byte">How can I use Java's signed byte type to store an 8 bit unsigned sample?</a>
           </dt>
           <dt>
            8.7. 
            <a href="#detect_signedness">How can I find out if an AudioFormat is signed or unsigned?</a>
           </dt>
           <dt>
            8.8. 
            <a href="#endianess">What is endianess / big endian / little endian?</a>
           </dt>
           <dt>
            8.9. 
            <a href="#samples_organized">How are samples organized in a byte array/stream?</a>
           </dt>
           <dt>
            8.10. 
            <a href="#unknown_sample_rate">What does "unknown sample rate" in an AudioFormat object mean?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          9. 
          <a href="#sec_conversion">Conversion between sample representations</a>
         </dt>
         <dd>
          <dl>
           <dt>
            9.1. 
            <a href="#convert_signedness">How can I convert 8 bit signed samples to 8 bit unsigned or vice versa?</a>
           </dt>
           <dt>
            9.2. 
            <a href="#short_to_byte">How do I convert short (16 bit) samples to bytes to store them in a byte array?</a>
           </dt>
           <dt>
            9.3. 
            <a href="#float_to_byte">How do I convert float or double samples to bytes to store them in a byte array?</a>
           </dt>
           <dt>
            9.4. 
            <a href="#reconstruct_samples">How can I reconstruct sample values from a byte array?</a>
           </dt>
           <dt>
            9.5. 
            <a href="#convert_channels">How can I convert between mono and stereo?</a>
           </dt>
           <dt>
            9.6. 
            <a href="#mono_mapping">How can I make a mono stream appear on one channel of a stereo stream?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          10. 
          <a href="#sec_audioinputstream">AudioInputStreams and Byte Arrays</a>
         </dt>
         <dd>
          <dl>
           <dt>
            10.1. 
            <a href="#file_bytearray">How can I read an audio file and store the audio data in a byte array?</a>
           </dt>
           <dt>
            10.2. 
            <a href="#bytearray_file">How can I write audio data from a byte array to an audio file?</a>
           </dt>
           <dt>
            10.3. 
            <a href="#calculate_skip">How can I calculate the number of bytes to skip from the length in seconds?</a>
           </dt>
           <dt>
            10.4. 
            <a href="#rewind_ais">How do I rewind an AudioInputStream?</a>
           </dt>
           <dt>
            10.5. 
            <a href="#skip_back_ais">How do I skip backwards on an AudioInputStream?</a>
           </dt>
           <dt>
            10.6. 
            <a href="#ais_length_unknown">How can I implement a real-time AudioInputStream, though I cannot give a length for it, as it is not known in advance?</a>
           </dt>
           <dt>
            10.7. 
            <a href="#mix_ais">How can I mix two (or more) AudioInputStream instances to a resulting AudioInputStream?</a>
           </dt>
           <dt>
            10.8. 
            <a href="#ais_section">How can I create an AudioInputStream that represents a portion of another AudioInputStream?</a>
           </dt>
           <dt>
            10.9. 
            <a href="#ais_unknown_length">Why does AudioInputStream.getFrameLength() return -1?</a>
           </dt>
           <dt>
            10.10. 
            <a href="#audiosystem_getAIS_vs_new_AIS">What is the difference between AudioSystem.getAudioInputStream(InputStream) and new AudioInputStream(InputStream, AudioFormat, long)?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          11. 
          <a href="#sec_processing">Data Processing (Amplifying, Mixing, Signal Processing)</a>
         </dt>
         <dd>
          <dl>
           <dt>
            11.1. 
            <a href="#processing_alaw">How can I do some processing on an A-law stream (like amplifing it)?</a>
           </dt>
           <dt>
            11.2. 
            <a href="#detect_level">How can I detect the level of sound while I am recording it?</a>
           </dt>
           <dt>
            11.3. 
            <a href="#convert_sample_rate">How can I do sample rate conversion?</a>
           </dt>
           <dt>
            11.4. 
            <a href="#detect_frequency">How can I detect the frequency (or pitch) of sound data?</a>
           </dt>
           <dt>
            11.5. 
            <a href="#fft1">How can I do equalizing / noise reduction / fft / echo cancellation / ...?</a>
           </dt>
           <dt>
            11.6. 
            <a href="#silence_supression">How can I do silence supression or silence detection?</a>
           </dt>
           <dt>
            11.7. 
            <a href="#mixing">How can I do mixing of audio streams?</a>
           </dt>
           <dt>
            11.8. 
            <a href="#float_vs_double">Should I use float or double for signal processing?</a>
           </dt>
           <dt>
            11.9. 
            <a href="#complex_numbers">How can I do computations with complex numbers in Java?</a>
           </dt>
           <dt>
            11.10. 
            <a href="#pitch_shifting">How can I change the pitch (frequency) of audio data without changing the duration?</a>
           </dt>
           <dt>
            11.11. 
            <a href="#time_streching">How can I change the duration of audio data without changing the pitch (frequency)?</a>
           </dt>
           <dt>
            11.12. 
            <a href="#reverb">How can I use reverbation?</a>
           </dt>
           <dt>
            11.13. 
            <a href="#max_volume">How can I find out the maximum volume of a sound file?</a>
           </dt>
           <dt>
            11.14. 
            <a href="#normalize_volume">How can I normalize the volume of sound?</a>
           </dt>
           <dt>
            11.15. 
            <a href="#calculate_power">How can I calculate the power of a signal?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          12. 
          <a href="#sec_compression">Compression and Encodings</a>
         </dt>
         <dd>
          <dl>
           <dt>
            12.1. 
            <a href="#sec_vorbis">Ogg Vorbis</a>
           </dt>
           <dd>
            <dl>
             <dt>
              12.1.1. 
              <a href="#what_is_vorbis">What is Ogg Vorbis?</a>
             </dt>
             <dt>
              12.1.2. 
              <a href="#decode_ogg">How can I play back Ogg Vorbis files?</a>
             </dt>
             <dt>
              12.1.3. 
              <a href="#encode_ogg">How can I encode Ogg Vorbis files?</a>
             </dt>
             <dt>
              12.1.4. 
              <a href="#vorbis_in_jdk">Who should we lobby to get Ogg Vorbis support in the Sun JRE?</a>
             </dt>
             <dt>
              12.1.5. 
              <a href="#vorbis_duration">How can I get the duration of an Ogg Vorbis file?</a>
             </dt>
            </dl>
           </dd>
           <dt>
            12.2. 
            <a href="#sec_mp3">mp3</a>
           </dt>
           <dd>
            <dl>
             <dt>
              12.2.1. 
              <a href="#decode_mp3">How can I play back mp3 files?</a>
             </dt>
             <dt>
              12.2.2. 
              <a href="#mp3_in_jre">Why is there no mp3 decoder in the Sun JRE/JDK?</a>
             </dt>
             <dt>
              12.2.3. 
              <a href="#mp3_legal">What is the legal state of the JLayer mp3 decoder?</a>
             </dt>
             <dt>
              12.2.4. 
              <a href="#decoder_differences">What are the differences between the JLayer mp3 decoder plug-in and the Sun mp3 decoder plug-in?</a>
             </dt>
             <dt>
              12.2.5. 
              <a href="#encode_mp3">How can I encode mp3 files?</a>
             </dt>
             <dt>
              12.2.6. 
              <a href="#pure_java_mp3_encoder">Is there a mp3 encoder implemented in pure java?</a>
             </dt>
             <dt>
              12.2.7. 
              <a href="#mp3_encoder_input_formats">Which input formats can I use for the mp3 encoder?</a>
             </dt>
             <dt>
              12.2.8. 
              <a href="#mp3_encoder_on_mac">Is mp3 encoding possible on Mac OS?</a>
             </dt>
             <dt>
              12.2.9. 
              <a href="#mp3_problems">Why do I get an UnsupportedAudioFileException when trying to play a mp3 file?</a>
             </dt>
             <dt>
              12.2.10. 
              <a href="#detect_mp3_length">How can I get the length of an mp3 stream?</a>
             </dt>
            </dl>
           </dd>
           <dt>
            12.3. 
            <a href="#sec_gsm">GSM 06.10</a>
           </dt>
           <dd>
            <dl>
             <dt>
              12.3.1. 
              <a href="#gsm">Is there support for GSM?</a>
             </dt>
             <dt>
              12.3.2. 
              <a href="#gsm_codec_formats">Why does the GSM codec refuses to encode from/decode to the format I want?</a>
             </dt>
             <dt>
              12.3.3. 
              <a href="#gsm_in_wav">How can I read a .wav file with GSM data or store GSM-encoded data in a .wav file?</a>
             </dt>
             <dt>
              12.3.4. 
              <a href="#gsm_with_byte_arrays">I want to convert to/from GSM using the Tritonus plug-in. However, I do not work with files or streams. Rather, I want to convert byte[] arrays.</a>
             </dt>
             <dt>
              12.3.5. 
              <a href="#gsm_from_bits">How can I decode GSM from frames of 260 bit?</a>
             </dt>
             <dt>
              12.3.6. 
              <a href="#calculate_gsm_duration">How can I calculate the duration of a GSM file?</a>
             </dt>
             <dt>
              12.3.7. 
              <a href="#native_gsm_codecs">Are there native implementations of codecs that are compatible with the framing format used by the Java Sound GSM codec?</a>
             </dt>
            </dl>
           </dd>
           <dt>
            12.4. 
            <a href="#sec_comp_xlaw">A-law and &#x3bc;-law</a>
           </dt>
           <dd>
            <dl>
             <dt>
              12.4.1. 
              <a href="#alaw_ulaw">What are A-law and &#x3bc;-law?</a>
             </dt>
             <dt>
              12.4.2. 
              <a href="#convert_to_ulaw">How can I convert a PCM encoded byte[] to a &#x3bc;-law byte[]?</a>
             </dt>
            </dl>
           </dd>
           <dt>
            12.5. 
            <a href="#sec_comp_speex">Speex</a>
           </dt>
           <dd>
            <dl>
             <dt>
              12.5.1. 
              <a href="#what_is_speex">What is Speex?</a>
             </dt>
             <dt>
              12.5.2. 
              <a href="#support_for_speex">Is there support for Speex?</a>
             </dt>
             <dt>
              12.5.3. 
              <a href="#jspeex_usage">How do I use JSpeex?</a>
             </dt>
             <dt>
              12.5.4. 
              <a href="#speex_duration">How can I get the duration of a Speex file?</a>
             </dt>
            </dl>
           </dd>
           <dt>
            12.6. 
            <a href="#sec_comp_misc">Miscellaneous</a>
           </dt>
           <dd>
            <dl>
             <dt>
              12.6.1. 
              <a href="#adpcm">Is there support for ADPCM (a.k.a. G723) in Java Sound?</a>
             </dt>
             <dt>
              12.6.2. 
              <a href="#wma">Is there support for WMA and ASF in Java Sound?</a>
             </dt>
             <dt>
              12.6.3. 
              <a href="#convert_encoded_to_encoded">How can I convert between two encoded formats directly (e.g. from mp3 to A-law)?</a>
             </dt>
             <dt>
              12.6.4. 
              <a href="#compression_schemas">What compression schemas can I use?</a>
             </dt>
             <dt>
              12.6.5. 
              <a href="#encoding_constr_workaround">How can I get Encoding instances for GSM and mp3 with JDKs older than 1.5.0?</a>
             </dt>
             <dt>
              12.6.6. 
              <a href="#realaudio">Is there support for RealAudio / RealMedia (.ra / .rm files)?</a>
             </dt>
             <dt>
              12.6.7. 
              <a href="#new_format_support">How can I get support for a new encoding?</a>
             </dt>
            </dl>
           </dd>
          </dl>
         </dd>
         <dt>
          13. 
          <a href="#sec_network">Audio data transfer over networks</a>
         </dt>
         <dd>
          <dl>
           <dt>
            13.1. 
            <a href="#streaming">How can I do streaming of audio data?</a>
           </dt>
           <dt>
            13.2. 
            <a href="#streaming_latency">Why do I get distorted sound in my streaming application if it is used on the internet, but works on a LAN?</a>
           </dt>
           <dt>
            13.3. 
            <a href="#upload">How can I upload recorded audio data to a server?</a>
           </dt>
           <dt>
            13.4. 
            <a href="#compression_network">What compression schema should I use to transfer audio data over a network?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          14. 
          <a href="#sec_ports">Ports</a>
         </dt>
         <dd>
          <dl>
           <dt>
            14.1. 
            <a href="#use_ports">How do I use the interface Port?</a>
           </dt>
           <dt>
            14.2. 
            <a href="#no_ports">Why is it not possible to retrieve Port instances?</a>
           </dt>
           <dt>
            14.3. 
            <a href="#no_port_controls">Why is it not possible to retrieve Control instances from Port lines?</a>
           </dt>
           <dt>
            14.4. 
            <a href="#port_open_close">What does opening and closing mean for Port lines?</a>
           </dt>
           <dt>
            14.5. 
            <a href="#port_vs_dataline">Why is it not possible to read data from a microphone Port line?</a>
           </dt>
           <dt>
            14.6. 
            <a href="#ports_jmf">Can I use Java Sound's Port interface to control volume and tone of sound played with an application using JMF?</a>
           </dt>
           <dt>
            14.7. 
            <a href="#no_predefined_ports">Why are there no Port instances of certain predefined types (like Port.Info.MICROPHONE or Port.Info.COMPACT_DISC) on Linux?</a>
           </dt>
          </dl>
         </dd>
         <dt>
          15. 
          <a href="#sec_misc">Miscellaneous</a>
         </dt>
         <dd>
          <dl>
           <dt>
            15.1. 
            <a href="#quieter_playback">Why is playback of audio data with Java Sound significantly quieter than with a similar player on the native OS?</a>
           </dt>
           <dt>
            15.2. 
            <a href="#multichannel">Can I use multi-channel sound?</a>
           </dt>
           <dt>
            15.3. 
            <a href="#multichannel_cards">Which multi-channel soundcards can I use with Java Sound?</a>
           </dt>
           <dt>
            15.4. 
            <a href="#rear_channels">Can I use the rear channels of a four-channel soundcard (like Soundblaster Life! and Soundblaster Audigy)?</a>
           </dt>
           <dt>
            15.5. 
            <a href="#cdda">How can I read audio data from a CD?</a>
           </dt>
           <dt>
            15.6. 
            <a href="#no_sound_on_linux">Why is there no sound at all when running my program on Linux, while on Windows it works as expected?</a>
           </dt>
           <dt>
            15.7. 
            <a href="#display_waveform">How can I display audio data as a waveform?</a>
           </dt>
           <dt>
            15.8. 
            <a href="#ais_vs_tdl">What is the difference between AudioInputStream and TargetDataLine?</a>
           </dt>
           <dt>
            15.9. 
            <a href="#24_96">Does Java Sound support 24 bit/96 kHz audio?</a>
           </dt>
          </dl>
         </dd>
        </dl>
        <table summary="Q and A Set" border="0">
         <colgroup>
          <col align="left" width="1%">
         </colgroup>
         <tbody>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_dataline"></a><h3 class="title"><a name="sec_dataline"></a>1. DataLines</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              1.1. 
              <a href="#sec_line_general">General</a>
             </dt>
             <dd>
              <dl>
               <dt>
                1.1.1. 
                <a href="#dataline_notification">How can I be notified when data is available for write/read in a SourceDataLine or TargetDataLine?</a>
               </dt>
               <dt>
                1.1.2. 
                <a href="#not_16k_line">Why does it fail to open any line with 16 kHz sample rate?</a>
               </dt>
               <dt>
                1.1.3. 
                <a href="#mulaw_line">How can I get a SourceDataLine or TargetDataLine in &#x3bc;-law format?</a>
               </dt>
               <dt>
                1.1.4. 
                <a href="#duplex_open_order">Why does simultaneous recording and playback only work when first opening the playback line (SourceDataLine)?</a>
               </dt>
               <dt>
                1.1.5. 
                <a href="#linux_duplex">Why doesn't simultaneous recording and playback work at all with the Sun JDK 1.3/1.4 on GNU/Linux?</a>
               </dt>
               <dt>
                1.1.6. 
                <a href="#select_mixer">How can I get a Line from a specific Mixer?</a>
               </dt>
               <dt>
                1.1.7. 
                <a href="#dad_mono_lines">Why are there no mono lines with the "Direct Audio Devices" mixers on Linux?</a>
               </dt>
               <dt>
                1.1.8. 
                <a href="#source_target">Why is a SourceDataLine called "source" and a TargetDataLine called "target" though it's actually the other way round?</a>
               </dt>
               <dt>
                1.1.9. 
                <a href="#dataline_getposition">Why are DataLine.getFramePosition() and DataLine.getMicrosecondPosition() so inaccurate?</a>
               </dt>
               <dt>
                1.1.10. 
                <a href="#dataline_getlevel">Why does DataLine.getLevel() always return -1?</a>
               </dt>
               <dt>
                1.1.11. 
                <a href="#active_vs_running">What is the difference between DataLine.isActive() and DataLine.isRunning()?</a>
               </dt>
               <dt>
                1.1.12. 
                <a href="#detect_underrun">How can I detect a buffer underrun or overrun?</a>
               </dt>
               <dt>
                1.1.13. 
                <a href="#underrun_event">Why is there no event for notifying applications of an underrun/overrun condition?</a>
               </dt>
               <dt>
                1.1.14. 
                <a href="#line_position">How can I find out the current playback or recording position?</a>
               </dt>
               <dt>
                1.1.15. 
                <a href="#looping_playback">How can I do looping in playback?</a>
               </dt>
              </dl>
             </dd>
             <dt>
              1.2. 
              <a href="#sec_sourcedataline">SourceDataLine</a>
             </dt>
             <dd>
              <dl>
               <dt>
                1.2.1. 
                <a href="#sdl_repeat">How can I avoid that the last bit of sound played on a SourceDataLine is repeated?</a>
               </dt>
               <dt>
                1.2.2. 
                <a href="#wrong_open">Why is playback distorted, too fast or too slow with the JDK 1.5.0 beta, but not with earlier versions of the JDK?</a>
               </dt>
              </dl>
             </dd>
             <dt>
              1.3. 
              <a href="#sec_targetdataline">TargetDataLine</a>
             </dt>
             <dd>
              <dl>
               <dt>
                1.3.1. 
                <a href="#capture_source">How can I capture from a specific source (microphone or line-in)?</a>
               </dt>
               <dt>
                1.3.2. 
                <a href="#multiple_tdl_per_card">How can I get more than one TargetDataLine?</a>
               </dt>
               <dt>
                1.3.3. 
                <a href="#multiple_tdl">Why is in not possible to open more than one TargetDataLine at the same time?</a>
               </dt>
               <dt>
                1.3.4. 
                <a href="#established_device_format">Why do I get a LineUnavailableException: "Requested format incompatible with already established device format"?</a>
               </dt>
               <dt>
                1.3.5. 
                <a href="#recording_volume">How can I control the volume when recording with a TargetDataLine?</a>
               </dt>
               <dt>
                1.3.6. 
                <a href="#stop_drain_tdl">How should I use stop() and drain() on a TargetDataLine?</a>
               </dt>
               <dt>
                1.3.7. 
                <a href="#read_blocking">Why is TargetDataLine.read() blocking for a long time?</a>
               </dt>
               <dt>
                1.3.8. 
                <a href="#recordings_cutoff">Why is the end of recordings cut off prematurely?</a>
               </dt>
              </dl>
             </dd>
             <dt>
              1.4. 
              <a href="#sec_clip">Clip</a>
             </dt>
             <dd>
              <dl>
               <dt>
                1.4.1. 
                <a href="#big_clip">Why do I get an out of memory exception when trying to use a Clip with a 5 MB audio file?</a>
               </dt>
               <dt>
                1.4.2. 
                <a href="#no_free_voices">Why do I get "LineUnavailableException: No Free Voices" when opening a Clip?</a>
               </dt>
               <dt>
                1.4.3. 
                <a href="#clip_rewind">How can I rewind a Clip?</a>
               </dt>
               <dt>
                1.4.4. 
                <a href="#clip_no_position_reset">Why does the frame/microsecond position not jump back to zero when a Clip is looped?</a>
               </dt>
               <dt>
                1.4.5. 
                <a href="#clip_play_multiple">Why are there failures, clicks and other random effects if a clip is played multiple times with 1.5?</a>
               </dt>
              </dl>
             </dd>
            </dl></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_line_general"></a><h4 class="title"><a name="sec_line_general"></a>1.1. General</h4></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              1.1.1. 
              <a href="#dataline_notification">How can I be notified when data is available for write/read in a SourceDataLine or TargetDataLine?</a>
             </dt>
             <dt>
              1.1.2. 
              <a href="#not_16k_line">Why does it fail to open any line with 16 kHz sample rate?</a>
             </dt>
             <dt>
              1.1.3. 
              <a href="#mulaw_line">How can I get a SourceDataLine or TargetDataLine in &#x3bc;-law format?</a>
             </dt>
             <dt>
              1.1.4. 
              <a href="#duplex_open_order">Why does simultaneous recording and playback only work when first opening the playback line (SourceDataLine)?</a>
             </dt>
             <dt>
              1.1.5. 
              <a href="#linux_duplex">Why doesn't simultaneous recording and playback work at all with the Sun JDK 1.3/1.4 on GNU/Linux?</a>
             </dt>
             <dt>
              1.1.6. 
              <a href="#select_mixer">How can I get a Line from a specific Mixer?</a>
             </dt>
             <dt>
              1.1.7. 
              <a href="#dad_mono_lines">Why are there no mono lines with the "Direct Audio Devices" mixers on Linux?</a>
             </dt>
             <dt>
              1.1.8. 
              <a href="#source_target">Why is a SourceDataLine called "source" and a TargetDataLine called "target" though it's actually the other way round?</a>
             </dt>
             <dt>
              1.1.9. 
              <a href="#dataline_getposition">Why are DataLine.getFramePosition() and DataLine.getMicrosecondPosition() so inaccurate?</a>
             </dt>
             <dt>
              1.1.10. 
              <a href="#dataline_getlevel">Why does DataLine.getLevel() always return -1?</a>
             </dt>
             <dt>
              1.1.11. 
              <a href="#active_vs_running">What is the difference between DataLine.isActive() and DataLine.isRunning()?</a>
             </dt>
             <dt>
              1.1.12. 
              <a href="#detect_underrun">How can I detect a buffer underrun or overrun?</a>
             </dt>
             <dt>
              1.1.13. 
              <a href="#underrun_event">Why is there no event for notifying applications of an underrun/overrun condition?</a>
             </dt>
             <dt>
              1.1.14. 
              <a href="#line_position">How can I find out the current playback or recording position?</a>
             </dt>
             <dt>
              1.1.15. 
              <a href="#looping_playback">How can I do looping in playback?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="dataline_notification"></a><a name="N10037"></a><b>1.1.1.</b></td>
           <td valign="top" align="left"><p>How can I be notified when data is available for write/read in a <tt class="classname">SourceDataLine</tt> or <tt class="classname">TargetDataLine</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You have to use <tt class="function">SourceDataLine/TargetDataLine.available()</tt>. The usual implementation for streaming audio (in Java Sound) is a dedicated thread for that - look at the Java Sound Demo which you can download from Sun or at the <a class="olink" href="examples/index.html">Java Sound Resources: Examples</a>. (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="not_16k_line"></a><a name="N1004D"></a><b>1.1.2.</b></td>
           <td valign="top" align="left"><p>Why does it fail to open any line with 16 kHz sample rate?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Apparently, most Java Sound implementations do not provide that, even if the soundcard supports it. Future implementations will support that. (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mulaw_line"></a><a name="N10055"></a><b>1.1.3.</b></td>
           <td valign="top" align="left"><p>How can I get a <tt class="classname">SourceDataLine</tt> or <tt class="classname">TargetDataLine</tt> in &#x3bc;-law format?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p><tt class="classname">TargetDataLines</tt> are supposed to act as a "direct" way to communicate with the audio hardware device, i.e. your soundcard. When your soundcard does not support &#x3bc;-law directly, the <tt class="classname">TargetDataLine</tt> won't either.</p><p>The way to go is to open a <tt class="classname">TargetDataLine</tt> in pcm format and route it through a format converter. See doc of <tt class="classname">AudioSystem</tt> to get converted Streams. The converted stream you get provides &#x3bc;-law samples then.</p><p>There is no drawback in this approach: all PC soundcards that I know of deliver only PCM, so it has to be rendered to &#x3bc;-law anyway in software. Whether in the soundcard's driver, the operating system layer or in the application (your java program) doesn't matter. You get maximum portability when only using pcm for <tt class="classname">TargetDataLines</tt>. (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="duplex_open_order"></a><a name="N10075"></a><b>1.1.4.</b></td>
           <td valign="top" align="left"><p>Why does simultaneous recording and playback only work when first opening the playback line (<tt class="classname">SourceDataLine</tt>)?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This depends on the soundcard and its driver to the native operating system. E.g. Soundblaster 16 or 64 do not provide real full duplex, only a kind of pseudo full duplex. I experienced under Windows that you can only use this pseudo full duplex when you have a certain order in opening record/playback lines. (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="linux_duplex"></a><a name="N10080"></a><b>1.1.5.</b></td>
           <td valign="top" align="left"><p>Why doesn't simultaneous recording and playback work at all with the Sun JDK 1.3/1.4 on GNU/Linux?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Due to problems with some OSS drivers, full-duplex is disabled by default in versions up to 1.4.1. There are several ways to get full-duplex:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Use the <a href="http://www.alsa-project.org/" target="_top">ALSA</a> support in JDK 1.4.2 or later. Note that in 1.4.2, the ALSA support is not used by default for playback. If you call <tt class="function">AudioSytem.getLine()</tt>, the default is used ("Java Sound Audio Engine"). To use the "Direct Audio Device" (which uses ALSA), obtain the respective mixer with <tt class="function">AudioSystem.getMixer()</tt> and call <tt class="function">getLine()</tt> on the mixer. To detect the "Direct Audio Device", look for a string "ALSA" in the vendor or description string of the Mixer.Info object. Although string comparison is not a nice way, it is higly likely that "ALSA" will appear in at least one of the string in future releases. For recording, the "Direct Audio Device" is the default. A way to make the is the default for playback, too, is to rename <tt class="filename">/dev/audio</tt> and <tt class="filename">/dev/dsp</tt>. However, this will disable sound support for all non-ALSA programs. In version 1.5, the "Direct Audio Device" are the default for playback, too, if the soundcard supports mixing in hardware.</p></li>
              <li><p>Use <a href="http://www.tritonus.org/" target="_top">Tritonus</a>. The Tritonus plug-ins work with Java versions that are older than 1.4.2, too. However, it is recommended to use 1.4.2 if possible. The ALSA support in 1.4.2 is more stable than the one in Tritonus.</p></li>
             </ul>
            </div><p>See also <a class="olink" href="faq_misc.html#check_duplex">Q:&nbsp;3.3</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="select_mixer"></a><a name="N100B3"></a><b>1.1.6.</b></td>
           <td valign="top" align="left"><p><a name="select_mixer.q"></a>How can I get a <tt class="classname">Line</tt> from a specific <tt class="classname">Mixer</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Obtain the list of available <tt class="classname">Mixer</tt> implementations with <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/AudioSystem.html#getMixerInfo()" target="_top"><tt class="function">AudioSystem.getMixerInfo()</tt></a>. Select one of the available and call <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/AudioSystem.html#getMixer(javax.sound.sampled.Mixer.Info)" target="_top"><tt class="function">AudioSystem.getMixer(Mixer.Info)</tt></a> to obtain the <tt class="classname">Mixer</tt>. With this object you can call <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/Mixer.html#getLine(javax.sound.sampled.Line.Info)" target="_top"><tt class="function">Mixer.getLine(Line.Info)</tt></a> instead of <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/AudioSystem.html#getLine(javax.sound.sampled.Line.Info)" target="_top"><tt class="function">AudioSystem.getLine(Line.Info)</tt></a>. In the JDK 1.5.0, you can also use the ease-of-use methods in <tt class="classname">AudioSystem</tt>:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p><a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/AudioSystem.html#getSourceDataLine(javax.sound.sampled.AudioFormat,      javax.sound.sampled.Mixer.Info)" target="_top"><tt class="function">getSourceDataLine(AudioFormat format, Mixer.Info info)</tt></a></p></li>
              <li><p><a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/AudioSystem.html#getTargetDataLine(javax.sound.sampled.AudioFormat,      javax.sound.sampled.Mixer.Info)" target="_top"><tt class="function">getTargetDataLine(AudioFormat format, Mixer.Info info)</tt></a></p></li>
              <li><p><a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/AudioSystem.html#getClip(javax.sound.sampled.Mixer.Info)" target="_top"><tt class="function">getClip(Mixer.Info info)</tt></a></p></li>
             </ul>
            </div><p>With the JDK 1.5.0, there is an additional possibility: The default provider properties can be used to select the default <tt class="classname">Mixer</tt> for each type of line (<tt class="classname">SourceDataLine</tt>, <tt class="classname">TargetDataLine</tt>, <tt class="classname">Clip</tt>, <tt class="classname">Port</tt>). The default <tt class="classname">Mixer</tt>, if available, is used in <tt class="function">AudioSystem.getLine()</tt>. For details, see the <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/AudioSystem.html" target="_top">specification</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="dad_mono_lines"></a><a name="N10115"></a><b>1.1.7.</b></td>
           <td valign="top" align="left"><p><a name="dad_mono_lines.q"></a>Why are there no mono lines with the "Direct Audio Devices" mixers on Linux?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The implementation of the "Direct Audio Device" queries the soundcard driver for the supported formats. Some ALSA drivers do not support mono lines, so they are not available in the "Direct Audio Device". The workaround is to open a stereo line and expand the mono data to stereo. See also <a href="#convert_channels">How can I convert between mono and stereo?</a> and <a href="#mono_mapping">How can I make a mono stream appear on one channel of a stereo stream?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="source_target"></a><a name="N10126"></a><b>1.1.8.</b></td>
           <td valign="top" align="left"><p>Why is a <tt class="classname">SourceDataLine</tt> called "source" and a <tt class="classname">TargetDataLine</tt> called "target" though it's actually the other way round?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Well, nobody really knows why this fancy naming was chosen. From the perspective of an application, it's counter-intuitive. To understand it, take the perspective of a <tt class="classname">Mixer</tt> object: It receives data from the application via a <tt class="classname">SourceDataLine</tt> object, this is its source of data. And it delivers data to the application via a <tt class="classname">TargetDataLine</tt>. So from the perspective of the <tt class="classname">Mixer</tt>, this is the target of its data. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="dataline_getposition"></a><a name="N10140"></a><b>1.1.9.</b></td>
           <td valign="top" align="left"><p>Why are <tt class="function">DataLine.getFramePosition()</tt> and <tt class="function">DataLine.getMicrosecondPosition()</tt> so inaccurate?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The implementation of these methods in the "Java Sound Audio Engine" is bad and will not be fixed. The "Direct Audio Device" has a much better implementation. See also <a href="#mixers">What are all these mixers?</a></p><p>But keep in mind that it is not possible to get a frame precise playback position with these methods. There is too much buffering in the data path (also in the audio hardware), so calculating the position is always only an estimation.</p><p>If you try to measure the precision of <tt class="function">DataLine.getMicrosecondPosition()</tt> with a real-time clock, you are also likely to see the effect of a clock drift. For details on this phenomenon see <a href="#clock_drift">Why does recording or playing for a certain period of time results in audio data that is shorter or longer than the period I recorded / played?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="dataline_getlevel"></a><a name="N1015F"></a><b>1.1.10.</b></td>
           <td valign="top" align="left"><p>Why does <tt class="function">DataLine.getLevel()</tt> always return <tt class="constant">-1</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p><tt class="function">DataLine.getLevel()</tt> is not implemented in current versions of the Sun JDK (1.4.1), nor in any other known Java Sound implementation. Here is a suggestion from Florian Bomers on how to implement this functionality yourself:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Read the data from the TargetDataLine in blocks.</p></li>
              <li><p>Convert each block to a common format, e.g. normalized floats [-1, +1], or 8 bit signed bytes. If your project can make use of LGPL'd code, have a look at class <a href="http://tritonus.cvs.sourceforge.net/tritonus/tritonus/src/org/tritonus/share/sampled/FloatSampleBuffer.java?view=markup" target="_top"><tt class="classname">FloatSampleBuffer</tt></a> (for floats) or <a href="http://tritonus.cvs.sourceforge.net/tritonus/tritonus/src/org/tritonus/share/sampled/TConversionTool.java?view=markup" target="_top"><tt class="classname">TConversionTool</tt></a> (for integer-based values) of the Tritonus project.</p></li>
              <li><p>Calculate the level of the block. This could be the average, RMS power, peak amplitude, or similar. Be sure to use the absolute values (or squaring the amplitudes for the power). See also <a href="#calculate_power">How can I calculate the power of a signal?</a></p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="active_vs_running"></a><a name="N1018A"></a><b>1.1.11.</b></td>
           <td valign="top" align="left"><p><a name="active_vs_running.q"></a>What is the difference between <tt class="function">DataLine.isActive()</tt> and <tt class="function">DataLine.isRunning()</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is an issue where even the Java Sound gurus do not know a satisfying answer. A useful definition would be the following:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p><tt class="function">isActive()</tt> returns true if the line is in started state, i.e. between calls to <tt class="function">start()</tt> and <tt class="function">stop()</tt>.</p></li>
              <li><p><tt class="function">isRunning()</tt> returns true if data is actually read from or written to the device. This would mean that <tt class="function">isRunning()</tt> returns false in case of buffer underruns or overruns.</p></li>
             </ul>
            </div><p>However, this is not the way it is implemented. For the "Direct Audio Device" mixers, <tt class="function">isActive()</tt> and <tt class="function">isRunning()</tt> always return the same value. In general, it is recommended to use <tt class="function">isActive()</tt>, since it is specified less ambigously and it is implemented consistently. See also <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4791152" target="_top">bug #4791152</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="detect_underrun"></a><a name="N101C6"></a><b>1.1.12.</b></td>
           <td valign="top" align="left"><p><a name="detect_underrun.q"></a>How can I detect a buffer underrun or overrun?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The following is working reliably at least with the "Direct Audio Device" mixers:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p><tt class="classname">SourceDataLine</tt>: underrun if (line.available() == line.getBufferSize())</p><p><tt class="function">SourceDataLine.available()</tt>: how much data can be written to the buffer. If the whole buffer can be written to, there is no data in the buffer to be rendered.</p></li>
              <li><p><tt class="classname">TargetDataLine</tt>: overrun if (line.available() == line.getBufferSize())</p><p><tt class="function">TargetDataLine.available()</tt>: how much data can be read from the buffer. If the whole buffer can be read, there is no space in the buffer for new data captured from the line.</p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="underrun_event"></a><a name="N101E6"></a><b>1.1.13.</b></td>
           <td valign="top" align="left"><p><a name="underrun_event.q"></a>Why is there no event for notifying applications of an underrun/overrun condition?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is Florian's (and my) opinion:</p>
            <div class="blockquote">
             <blockquote class="blockquote">
              <p>Java Sound is a low level audio API. We decided to give highest priority to performance and "bare" functionality, rather than adding many high-level features. And although this is not a reason to not add it, all low level audio API's that I have worked closely with do not provide underrun notification.</p>
             </blockquote>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="line_position"></a><a name="N101F4"></a><b>1.1.14.</b></td>
           <td valign="top" align="left"><p><a name="line_position.q"></a>How can I find out the current playback or recording position?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There are two possibilities:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Use <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/DataLine.html#getFramePosition()" target="_top"><tt class="function">DataLine.getFramePosition()</tt></a> or <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/DataLine.html#getMicrosecondPosition()" target="_top"><tt class="function">DataLine.getFramePosition()</tt></a>. These methods are supposed to return the current "hearing" position. However, they weren't implemented well prior to the JDK 1.5.0.</p></li>
              <li><p>Count the frames that you read from or write to the <tt class="classname">DataLine</tt> and add one full buffer size and 15 milliseconds (ballpark figure for hardware delay) to it. As reference point use the time when the write()/read() method returns. This allows amount correct extrapolation. This method works best if you call <tt class="function">read()</tt>/<tt class="function">write()</tt> with buffers that fit exactly into the line's buffer size.</p><p>This approach also works reasonably fine with 1.4.2 and before. It is implemented in the JAM program at J1 2003.</p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="looping_playback"></a><a name="N1021F"></a><b>1.1.15.</b></td>
           <td valign="top" align="left"><p><a name="looping_playback.q"></a>How can I do looping in playback?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There are two possibilities:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Load the data to loop into a <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/Clip.html" target="_top"><tt class="classname">Clip</tt></a> object and use its looping methods. This is convenient for short loops. There is a limitation on the size of the data, see <a href="#big_clip">Why do I get an out of memory exception when trying to use a <tt class="classname">Clip</tt> with a 5 MB audio file?</a></p></li>
              <li><p>Use a <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/SourceDataLine.html" target="_top"><tt class="classname">SourceDataLine</tt></a> and feed it the data you want to loop continuously. If you are reading the data from an <tt class="classname">AudioInputStream</tt>, rewinding the <tt class="classname">AudioInputStream</tt> in each loop may help to implement this. See <a href="#rewind_ais">How do I rewind an <tt class="classname">AudioInputStream</tt>?</a></p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_sourcedataline"></a><h4 class="title"><a name="sec_sourcedataline"></a>1.2. SourceDataLine</h4></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              1.2.1. 
              <a href="#sdl_repeat">How can I avoid that the last bit of sound played on a SourceDataLine is repeated?</a>
             </dt>
             <dt>
              1.2.2. 
              <a href="#wrong_open">Why is playback distorted, too fast or too slow with the JDK 1.5.0 beta, but not with earlier versions of the JDK?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="sdl_repeat"></a><a name="N1024D"></a><b>1.2.1.</b></td>
           <td valign="top" align="left"><p><a name="sdl_repeat.q"></a>How can I avoid that the last bit of sound played on a <tt class="classname">SourceDataLine</tt> is repeated?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This can be avoided easily: after writing all data to the <tt class="classname">SourceDataLine</tt> call <tt class="function">drain()</tt> and <tt class="function">stop()</tt>. If you want to reuse the line after this, call <tt class="function">start()</tt> again before writing more data to the line. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="wrong_open"></a><a name="N10268"></a><b>1.2.2.</b></td>
           <td valign="top" align="left"><p><a name="wrong_open.q"></a>Why is playback distorted, too fast or too slow with the JDK 1.5.0 beta, but not with earlier versions of the JDK?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The reason is a common misconception about how <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/Line.html#open()" target="_top"><tt class="function">Line.open()</tt></a> works. According to the specification, <tt class="function">open()</tt> without parameters opens a line in a "default format". The default format of a line is an implementation specific property. It is <span class="emphasis"><em>not</em></span> the <tt class="classname">AudioFormat</tt> used in the <tt class="classname">DataLine.Info</tt> object. Rather, the format in <tt class="classname">DataLine.Info</tt> is used to request a <tt class="classname">DataLine</tt> instance that is <span class="emphasis"><em>capable</em></span> of handling this format. This does not necessarily mean that the line has to be opened in that format. Note that it is possible to construct <tt class="classname">DataLine.Info</tt> with an array of <tt class="classname">AudioFormat</tt> objects. This means that the requested line has to be able to handle any of the given formats.</p><p>The Java Sound implementaion prior to JDK 1.5.0 had the following property: If only one <tt class="classname">AudioFormat</tt> is given in a <tt class="classname">DataLine.Info</tt>, this <tt class="classname">AudioFormat</tt> becomes the default format of the line. This caused the behaviour that it was possible to specify the format for <tt class="function">open()</tt> via the <tt class="classname">DataLine.Info</tt> object. However, this behaviour was never specified, it is just an implementation specific property you can't rely on in general. The "Direct Audio Device" mixers in JDK 1.5.0 beta (see also <a href="#mixers">What are all these mixers?</a>) behave different: they just pick one of the supported hardware formats as default format. This is a correct behaviour according to the specification, since the specification doesn't specify how the default format is chosen.</p><p>Therefore, it is recommended to always specify the format when opening a <tt class="classname">DataLine</tt>: use <tt class="function">open(AudioFormat format)</tt> or <tt class="function">open(AudioFormat format, int buffersize)</tt> rather than <tt class="function">Line.open()</tt> without parameters. See also <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/Line.html#open()" target="_top"><tt class="function">Line.open()</tt></a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/SourceDataLine.html#open(javax.sound.sampled.AudioFormat)" target="_top"><tt class="function">SourceDataLine.open(AudioFormat)</tt></a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/SourceDataLine.html#open(javax.sound.sampled.AudioFormat,%20int)" target="_top"><tt class="function">SourceDataLine.open(AudioFormat, int)</tt></a>, <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/TargetDataLine.html#open(javax.sound.sampled.AudioFormat)" target="_top"><tt class="function">TargetDataLine.open(AudioFormat)</tt></a> and <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/TargetDataLine.html#open(javax.sound.sampled.AudioFormat,%20int)" target="_top"><tt class="function">TargetDataLine.open(AudioFormat, int)</tt></a></p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th valign="top">Wrong code</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td valign="top"> <pre class="programlisting">
AudioFormat format = ...;
DataLine.Info info = new DataLine.Info(SourceDataLine.class, format);
// line is *capable* of being opened in format
SourceDataLine line = (SourceDataLine) AudioSystem.getLine(info);
// open in default format, not necessarily the same as format
line.open();</pre> </td>
               </tr>
              </tbody>
             </table>
             <table border="1">
              <colgroup>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th valign="top">Correct code</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td valign="top"> <pre class="programlisting">
AudioFormat format = ...;
DataLine.Info info = new DataLine.Info(SourceDataLine.class, format);
// line is *capable* of being opened in format
SourceDataLine line = (SourceDataLine) AudioSystem.getLine(info);
// open in desired format
line.open(format);</pre> </td>
               </tr>
              </tbody>
             </table>
            </div><p>It was decided to change the behaviour for the final version of the JDK 1.5.0 to provide backward compatibility with the JDK 1.4. The former unportable technique will be specified behaviour. See also bugs <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=5053380" target="_top">#5053380</a> and <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=5067526" target="_top">#5067526</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_targetdataline"></a><h4 class="title"><a name="sec_targetdataline"></a>1.3. TargetDataLine</h4></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              1.3.1. 
              <a href="#capture_source">How can I capture from a specific source (microphone or line-in)?</a>
             </dt>
             <dt>
              1.3.2. 
              <a href="#multiple_tdl_per_card">How can I get more than one TargetDataLine?</a>
             </dt>
             <dt>
              1.3.3. 
              <a href="#multiple_tdl">Why is in not possible to open more than one TargetDataLine at the same time?</a>
             </dt>
             <dt>
              1.3.4. 
              <a href="#established_device_format">Why do I get a LineUnavailableException: "Requested format incompatible with already established device format"?</a>
             </dt>
             <dt>
              1.3.5. 
              <a href="#recording_volume">How can I control the volume when recording with a TargetDataLine?</a>
             </dt>
             <dt>
              1.3.6. 
              <a href="#stop_drain_tdl">How should I use stop() and drain() on a TargetDataLine?</a>
             </dt>
             <dt>
              1.3.7. 
              <a href="#read_blocking">Why is TargetDataLine.read() blocking for a long time?</a>
             </dt>
             <dt>
              1.3.8. 
              <a href="#recordings_cutoff">Why is the end of recordings cut off prematurely?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="capture_source"></a><a name="N10309"></a><b>1.3.1.</b></td>
           <td valign="top" align="left"><p><a name="capture_source.q"></a>How can I capture from a specific source (microphone or line-in)?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You can use the system mixer of your operating system to select the recording source in the same way you would do it for a native program. With newer versions of the Sun JDK, you can achieve the same by using the <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/Port.html" target="_top">interface <tt class="classname">javax.sound.sampled.Port</tt></a>. See the section <a href="#sec_ports">Ports</a> for details. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="multiple_tdl_per_card"></a><a name="N1031C"></a><b>1.3.2.</b></td>
           <td valign="top" align="left"><p>How can I get more than one <tt class="classname">TargetDataLine</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Current implementations of the Java Sound API do not support multiple <tt class="classname">TargetDataLine</tt>s for the same recording source. There are no plans to change this behaviour. If, in the future, multi-channel soundcards are supported, it may be possible to get different <tt class="classname">TargetDataLine</tt> instances for the different inputs. If you just want to "split" lines, do it in your application. See also <a href="#multichannel">Can I use multi-channel sound?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="multiple_tdl"></a><a name="N10331"></a><b>1.3.3.</b></td>
           <td valign="top" align="left"><p>Why is in not possible to open more than one <tt class="classname">TargetDataLine</tt> at the same time?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Well, because it's a bug. The above is true for the Sun JDK up to version 1.4.2 on Solaris and Windows, and up to 1.4.1 on Linux. Beginning with version 1.5.0 for Solaris and Windows and version 1.4.2 for Linux there are the new "Direct Audio Device" mixer that don't have this limitation.</p><p>Tritonus is unaffected by this limitation. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="established_device_format"></a><a name="N1033E"></a><b>1.3.4.</b></td>
           <td valign="top" align="left"><p>Why do I get a LineUnavailableException: "Requested format incompatible with already established device format"?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is a bug that was fixed for 1.4.2. If you have to use an older version, there are two possible workarounds:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Do not play back anything using the "Java Sound Audio Engine" before recording. In version prior to 1.4.2, there is no way of doing playback at all without using the "Java Sound Audio Engine". If the "Java Sound Audio Engine" is used, it results in opening the sound device for 44100 Hz, 16 bit stereo, thereby setting the "previously established format".</p></li>
              <li><p>Always capture at 16 bit, stereo, 44100Hz. If you need your sound data in a different format, you can convert it afterwards. See also <a href="#sec_conversion">Conversion between sample representations</a> and <a href="#convert_sample_rate">How can I do sample rate conversion?</a></p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="recording_volume"></a><a name="N10356"></a><b>1.3.5.</b></td>
           <td valign="top" align="left"><p>How can I control the volume when recording with a <tt class="classname">TargetDataLine</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The obvious solution would be to get a <tt class="classname">Control</tt> object of type <tt class="constant">VOLUME</tt> or <tt class="constant">MASTER_GAIN</tt> for the <tt class="classname">TargetDataLine</tt> and manipulate the volume via this object. However, this is not possible, since no known Java Sound implementation supports any controls for <tt class="classname">TargetDataLine</tt> instances.</p><p>What you can do is to use the system mixer to control the recording volume --- it affects hardware settings in the soundcard. One possibility is to use the mixer application of the operating system. The other possibility is using <tt class="classname">Port</tt> lines from inside a Java Sound application. See the section <a href="#sec_ports">Ports</a> for details.</p><p>The remaining possibility is to implement a volume control digitally: multiplying each single sample of the sound data with a certain value that lowers or raises the level proportionally. See also <a class="olink" href="examples/AmplitudeConverter.html">Change the amplitude (volume) of an audio file</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="stop_drain_tdl"></a><a name="N1037F"></a><b>1.3.6.</b></td>
           <td valign="top" align="left"><p><a name="stop_drain_tdl.q"></a>How should I use <tt class="function">stop()</tt> and <tt class="function">drain()</tt> on a <tt class="classname">TargetDataLine</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>It is specified that <tt class="function">TargetDataLine.drain()</tt> has to wait until all data has been delivered to the <tt class="classname">TargetDataLine</tt>. If the line is not yet stopped, there is always data being delivered to the line. So you should call drain() only after stop(). In fact, drain() isn't needed with <tt class="classname">TargetDataLine</tt> at all.</p><p>A common technique to terminate reading from a <tt class="classname">TargetDataLine</tt> is the following:</p><pre class="programlisting">
TDL.stop();
do
{
    count = TDL.read();
}
while (count &gt; 0);
TDL.close();</pre><p>For an implementation of <tt class="function">TargetDataLine.drain()</tt> to be 100% compliant you need to block when the line is started and there is still data available. One way to do this is the following:</p><pre class="programlisting">
public void drain()
{
    while (isActive() &amp;&amp; (available() &gt; 0))
    {
        Thread.sleep(100);
    }
}</pre><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="read_blocking"></a><a name="N103B0"></a><b>1.3.7.</b></td>
           <td valign="top" align="left"><p><a name="read_blocking.q"></a>Why is <tt class="function">TargetDataLine.read()</tt> blocking for a long time?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>By specification, <tt class="function">TargetDataLine.read()</tt> is a blocking call: it waits until the requested amount of data is available. To use <tt class="function">read()</tt> in a non-blocking manner, you can check how much data is available with <tt class="function">available()</tt> and request only that amount. If you want to use <tt class="function">read()</tt> in a standard blocking manner, but need quick response for a real-time application, use smaller buffers for reading. See also <a href="#min_buffersize">What is the minimum buffer size I can use?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="recordings_cutoff"></a><a name="N103D1"></a><b>1.3.8.</b></td>
           <td valign="top" align="left"><p><a name="recordings_cutoff.q"></a>Why is the end of recordings cut off prematurely?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Even after calling <tt class="function">stop()</tt> on a <tt class="classname">TargetDataLine</tt>, there may be data remaining in its internal buffer. Make sure you read data until there is no more available. Then you can call <tt class="function">close()</tt> on the line. See also <a href="#">How should I use <tt class="function">stop()</tt> and <tt class="function">drain()</tt> on a <tt class="classname">TargetDataLine</tt>?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_clip"></a><h4 class="title"><a name="sec_clip"></a>1.4. Clip</h4></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              1.4.1. 
              <a href="#big_clip">Why do I get an out of memory exception when trying to use a Clip with a 5 MB audio file?</a>
             </dt>
             <dt>
              1.4.2. 
              <a href="#no_free_voices">Why do I get "LineUnavailableException: No Free Voices" when opening a Clip?</a>
             </dt>
             <dt>
              1.4.3. 
              <a href="#clip_rewind">How can I rewind a Clip?</a>
             </dt>
             <dt>
              1.4.4. 
              <a href="#clip_no_position_reset">Why does the frame/microsecond position not jump back to zero when a Clip is looped?</a>
             </dt>
             <dt>
              1.4.5. 
              <a href="#clip_play_multiple">Why are there failures, clicks and other random effects if a clip is played multiple times with 1.5?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="big_clip"></a><a name="N103EF"></a><b>1.4.1.</b></td>
           <td valign="top" align="left"><p><a name="big_clip.q"></a>Why do I get an out of memory exception when trying to use a <tt class="classname">Clip</tt> with a 5 MB audio file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>For files of this size, you should stream the audio. Like that you treat buffers of small size and feed them successively into the audio device. Look at the <a class="olink" href="examples/index.html">Java Sound Resources: Examples</a>, there are some streaming audio players to take as a start. (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="no_free_voices"></a><a name="N103FF"></a><b>1.4.2.</b></td>
           <td valign="top" align="left"><p>Why do I get "LineUnavailableException: No Free Voices" when opening a <tt class="classname">Clip</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This happens with the "Java Sound Audio Engine" when too many clips are open. While you can obtain any number of <tt class="classname">Clip</tt> instances, only 32 can be open at the same time. This is a hard limitation of the engine; it can only mix 32 channels. As a workaround, you can close unused clips and open them once they are needed again. If you really need more than 32 channels, you can do the mixing in your application and output the result to a <tt class="classname">SourceDataLine</tt>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="clip_rewind"></a><a name="N10410"></a><b>1.4.3.</b></td>
           <td valign="top" align="left"><p>How can I rewind a <tt class="classname">Clip</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Stop the clip by calling <tt class="function">stop()</tt>, then use <tt class="function">clip.setFramePosition(0)</tt> or <tt class="function">clip.setMicrosecondPosition(0)</tt>. Alternativly, you can set looping points so that rewinding occurs automatically: <tt class="function">clip.setLoopPoints(0, -1)</tt> (In this case you have to call <tt class="function">clip.loop(...)</tt> instead of <tt class="function">clip.start()</tt>.) (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="clip_no_position_reset"></a><a name="N10433"></a><b>1.4.4.</b></td>
           <td valign="top" align="left"><p><a name="clip_no_position_reset.q"></a>Why does the frame/microsecond position not jump back to zero when a <tt class="classname">Clip</tt> is looped?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p><tt class="function">getFramePosition()</tt> and <tt class="function">getMicrosecondPosition()</tt> are specified to return the position corresponding to the time since the line (or clip) was opened. If you want to get the position inside the loop of a looping clip, you can use something similar to this (assuming you are looping over the whole length of the clip):</p><pre class="programlisting">
currentFrame = clip.getFramePosition() %
clip.getFrameLength();</pre><p> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="clip_play_multiple"></a><a name="N1044B"></a><b>1.4.5.</b></td>
           <td valign="top" align="left"><p><a name="clip_play_multiple.q"></a>Why are there failures, clicks and other random effects if a clip is played multiple times with 1.5?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is a bug, and apparently one not easy to fix. See bug <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=6251460" target="_top">#6251460</a>. Note that you can work around this issue by using the old "Java Sound Audio Engine" instead of the "Direct Audio Device" mixers. This way, you get the same behaviour as in 1.4. See also <a href="#mixers">What are all these mixers?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_controls"></a><h3 class="title"><a name="sec_controls"></a>2. Controls</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              2.1. 
              <a href="#controls_of_dad_line">Why does the SourceDataLine instances I get when using the "Direct Audio Device" (ALSA on Linux) have no controls?</a>
             </dt>
             <dt>
              2.2. 
              <a href="#balance_vs_pan">What is the difference between a BALANCE and a PAN control? Which one should I use?</a>
             </dt>
             <dt>
              2.3. 
              <a href="#controls_of_mono_line">Why do mono lines from a "Direct Audio Device" have no PAN control?</a>
             </dt>
             <dt>
              2.4. 
              <a href="#controls_after_open">Why does obtaining a gain control work with 1.4.2, but not with 1.5.0?</a>
             </dt>
             <dt>
              2.5. 
              <a href="#no_volume_control">Why do Clip and SourceDataLine instances have no VOLUME control?</a>
             </dt>
             <dt>
              2.6. 
              <a href="#no_sr_control">Why is there no sample rate control in 1.5.0?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="controls_of_dad_line"></a><a name="N10462"></a><b>2.1.</b></td>
           <td valign="top" align="left"><p>Why does the <tt class="classname">SourceDataLine</tt> instances I get when using the "Direct Audio Device" (ALSA on Linux) have no controls?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Lines from these mixers do not provide controls in 1.4.2. In Florian's original opinion, "any control would obscure the initial idea, to provide high-performance direct audio access". However, he changed his mind and implemented volume and balance controls in 1.5.0. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="balance_vs_pan"></a><a name="N1046D"></a><b>2.2.</b></td>
           <td valign="top" align="left"><p><a name="balance_vs_pan.q"></a>What is the difference between a <tt class="constant">BALANCE</tt> and a <tt class="constant">PAN</tt> control? Which one should I use?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>In music, pan knobs are used for mono input lines to control how they are mapped to stereo output lines. On the other hand, for stereo input lines, the knob is labelled "balance". So you should get a <tt class="constant">PAN</tt> control for mono lines and a <tt class="constant">BALANCE</tt> control for stereo lines (and none for lines with more than 2 channels).</p><p>In the Sun J2SDK, <tt class="constant">PAN</tt> controls behave like <tt class="constant">BALANCE</tt> controls for stereo lines and <tt class="constant">BALANCE</tt> like <tt class="constant">PAN</tt> for mono lines. However, this is only a convenience for compatibility. To write portable programs, you should not rely on this behaviour. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="controls_of_mono_line"></a><a name="N10490"></a><b>2.3.</b></td>
           <td valign="top" align="left"><p>Why do mono lines from a "Direct Audio Device" have no <tt class="constant">PAN</tt> control?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>To implement a <tt class="constant">PAN</tt> control for a mono line, it has to be "distributed" between the left and right channel of a stereo line. This was no problem with the "Java Sound Audio Engine". The "Java Sound Audio Engine" always opens the soundcard in stereo, so it is always possible to do this "distribution". The "Direct Audio Device" implementation, however, opens the soundcard in mono if a mono line is requested. So it's not possible to implement a <tt class="constant">PAN</tt> control for such lines.</p><p>The workaround is to work with stereo: convert your stream to stereo and open the <tt class="classname">SourceDataLine</tt> in that stereo format. Then this line will have a BALANCE control, which works like a PAN control. See also <a href="#convert_channels">How can I convert between mono and stereo?</a> and <a href="#balance_vs_pan">What is the difference between a <tt class="constant">BALANCE</tt> and a <tt class="constant">PAN</tt> control? Which one should I use?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="controls_after_open"></a><a name="N104AE"></a><b>2.4.</b></td>
           <td valign="top" align="left"><p><a name="controls_after_open.q"></a>Why does obtaining a gain control work with 1.4.2, but not with 1.5.0?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Gain (<tt class="constant">FloatControl.Type.MASTER_GAIN</tt> / <tt class="constant">FloatControl.Type.VOLUME</tt>) controls are still available with the "Direct Audio Device" mixers in 1.5.0 (see also <a href="#mixers">What are all these mixers?</a>). However, the behaviour has been changed so that controls are only available after the line has been opened. This was necessary because in general, some control are only available if the device driver supports certain features, which can be queried only after the respective device has been opened. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="no_volume_control"></a><a name="N104C1"></a><b>2.5.</b></td>
           <td valign="top" align="left"><p><a name="no_volume_control.q"></a>Why do <tt class="classname">Clip</tt> and <tt class="classname">SourceDataLine</tt> instances have no <tt class="constant">VOLUME</tt> control?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p><tt class="classname">Clip</tt> and <tt class="classname">SourceDataLine</tt> instances provide a <tt class="constant">FloatControl.Type.MASTER_GAIN</tt> control rather than a <tt class="constant">FloatControl.Type.VOLUME</tt> control to control the playback volume. See also <a href="#controls_after_open">Why does obtaining a gain control work with 1.4.2, but not with 1.5.0?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="no_sr_control"></a><a name="N104E2"></a><b>2.6.</b></td>
           <td valign="top" align="left"><p>Why is there no sample rate control in 1.5.0?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The "Direct Audio Device" mixers in 1.5 (see <a href="#mixers">What are all these mixers?</a>) do not provide a sample rate control. To cite Florian:</p>
            <div class="blockquote">
             <blockquote class="blockquote">
              <p>&#x201c;<span class="quote">This is mostly because we wanted to give direct access to the sound hardware, without the problems of high-level features &#x2014; namely latency and processor usage. We may add sample rate in future if we find a good way to add it without affecting performance.</span>&#x201d;</p>
             </blockquote>
            </div><p>As an alternative, you can resample your data with a sample rate converter to achieve the same effect. See also <a href="#convert_sample_rate">How can I do sample rate conversion?</a></p><p>Or, you can still use the sample rate control of the "Java Sound Audio Engine" with 1.5 by requesting lines directly from it. See <a href="#select_mixer">How can I get a <tt class="classname">Line</tt> from a specific <tt class="classname">Mixer</tt>?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_buffers"></a><h3 class="title"><a name="sec_buffers"></a>3. DataLine buffers</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              3.1. 
              <a href="#min_buffersize">What is the minimum buffer size I can use?</a>
             </dt>
             <dt>
              3.2. 
              <a href="#default_buffersize">Why does a line have the default buffer size though a buffer size was specified in a DataLine.Info object when obtaining the line?</a>
             </dt>
             <dt>
              3.3. 
              <a href="#large_buffers">Why is it not possible to use large buffers for a DataLine with 1.5.0?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="min_buffersize"></a><a name="N10503"></a><b>3.1.</b></td>
           <td valign="top" align="left"><p><a name="min_buffersize.q"></a>What is the minimum buffer size I can use?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Obviously, this depends on the operating system, the hardware, the Java VM, which Mixer implementation you use and several other factors. The following measurements have been found experimentally on a very old PC (350 MHz) under Linux with the Sun JDK 1.4.2_02:</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th rowspan="2" valign="top">format</th>
                <th rowspan="2" valign="top">sample rate</th>
                <th colspan="2" align="center" valign="top">Playback</th>
                <th colspan="2" align="center" valign="top">Recording</th>
               </tr>
               <tr valign="top">
                <th valign="top">Java Sound Audio Engine</th>
                <th valign="top">Direct Audio Device</th>
                <th valign="top">Simple Input Device</th>
                <th valign="top">Direct Audio Device</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td rowspan="3" valign="top">8 bit mono</td>
                <td valign="top">11025 Hz</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td valign="top">22050 Hz</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td valign="top">44100 Hz</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td rowspan="3" valign="top">8 bit stereo</td>
                <td valign="top">11025 Hz</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td valign="top">22050 Hz</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td valign="top">44100 Hz</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td rowspan="3" valign="top">16 bit mono</td>
                <td valign="top">11025 Hz</td>
                <td valign="top">1024 bytes</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td valign="top">22050 Hz</td>
                <td valign="top">2048 bytes</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td valign="top">44100 Hz</td>
                <td valign="top">4096 bytes</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td rowspan="3" valign="top">16 bit stereo</td>
                <td valign="top">11025 Hz</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td valign="top">22050 Hz</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
               <tr valign="top">
                <td valign="top">44100 Hz</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
                <td valign="top">no results</td>
               </tr>
              </tbody>
             </table>
            </div><p>These measurements suggest that the latency introduced by buffers in the "Java Sound Audio Engine" is about 50 ms, independant of the sample rate. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="default_buffersize"></a><a name="N105D5"></a><b>3.2.</b></td>
           <td valign="top" align="left"><p>Why does a line have the default buffer size though a buffer size was specified in a <tt class="classname">DataLine.Info</tt> object when obtaining the line?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This happens with the "Direct Audio Device" of the JDK 1.5.0 if the line is opened with <tt class="function">open(AudioFormat)</tt> instead of <tt class="function">open(AudioFormat, int)</tt>. The reason for this behaviour is that by requiring a certain buffersize or range of buffersizes in <tt class="classname">DataLine.Info</tt>, you obtain a line that is <span class="emphasis"><em>capable</em></span> of setting its buffersize to the respective value. You still have to choose the actual value. This is done when opening the line: with <tt class="function">open(AudioFormat, int)</tt>, a certain buffer size for the line can be specified. If <tt class="function">open(AudioFormat)</tt> is used, the line is opened with the default buffer size. Until 1.4.2, a buffersize in <tt class="classname">DataLine.Info</tt> was used in opening if the <tt class="function">open()</tt> call does not specify a buffer size. However, it was decided that automatically taking over this value is a questionable convenience. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="large_buffers"></a><a name="N105FD"></a><b>3.3.</b></td>
           <td valign="top" align="left"><p>Why is it not possible to use large buffers for a <tt class="classname">DataLine</tt> with 1.5.0?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The <tt class="classname">DataLine</tt> implementation of the "Java Sound Audio Engine" has a circular buffer per line instance. For <tt class="classname">SourceDataLine</tt> instances, <tt class="function">write()</tt> writes data to this buffer. A separate thread reads from the circular buffer and transfers the data to the native layer of the engine. This allows for arbitrary sized buffers, but results in the overhead of an additional buffer and one thread per <tt class="classname">DataLine</tt>.</p><p>The <tt class="classname">DataLine</tt> implementation of the "Direct Audio Device" of 1.5.0 does not have a circular buffer. Instead, it writes/reads data directly to/from the soundcard driver. This gives higher performance and lower latency. On the other hand, it restricts buffer sizes to what the soundcard driver supports.</p><p>Adding a layer of buffering to the "Direct Audio Device" mixers would result in the same performance penalty as the <tt class="classname">DataLine</tt> implementation of the "Java Sound Audio Engine". It would introduce a general overhead though the additional functionality is only needed in special cases. Therefore, it is unlikely that the implementation of the "Direct Audio Device" mixers will be changed to allow larger buffers.</p><p>If you need larger buffers, you can implement an additional layer with a circular buffer in your application. Then you can choose any size you want for this buffer. And note that you need an additional thread &#x2014; like the "Java Sound Audio Engine". The <a class="olink" href="apps/am.html">Answering Machine</a> has classes that do a similar job. There is also the class <tt class="classname">org.tritonus.share.TCircularBuffer</tt> in <a href="http://www.tritonus.org/" target="_top">Tritonus</a> that you can use for this purpose. (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_mixers"></a><h3 class="title"><a name="sec_mixers"></a>4. Mixers</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              4.1. 
              <a href="#mixers">What are all these mixers?</a>
             </dt>
             <dt>
              4.2. 
              <a href="#no_sdl_from_mixer">Why are there mixers from which I can't get a SourceDataLine?</a>
             </dt>
             <dt>
              4.3. 
              <a href="#phone_output">How can I redirect sound output to a phone / modem device?</a>
             </dt>
             <dt>
              4.4. 
              <a href="#multiple_soundcards">Can I use multiple soundcards at the same time?</a>
             </dt>
             <dt>
              4.5. 
              <a href="#only_jsae_playback">Why can I record from different soundcards, but not play back to them?</a>
             </dt>
             <dt>
              4.6. 
              <a href="#supported_formats">How can I obtain the formats supported by a mixer (or at all)?</a>
             </dt>
             <dt>
              4.7. 
              <a href="#dad_supported_formats">What formats are supported by "Direct Audio Device" mixers?</a>
             </dt>
             <dt>
              4.8. 
              <a href="#sr_unspecified">Why are there AudioFormat objects with frame rate/sample rate reported as -1 when I query a Mixer for its supported formats?</a>
             </dt>
             <dt>
              4.9. 
              <a href="#match_port_mixer">How can I detect which Port Mixer belongs to which soundcard?</a>
             </dt>
             <dt>
              4.10. 
              <a href="#which_mixer_used">How can I find out which Mixer implementation is used?</a>
             </dt>
             <dt>
              4.11. 
              <a href="#why_jsae_default">Why do I get lines from the "Java Sound Audio Engine" in the JDK 1.5.0 though the "Direct Audio Device" mixers are available, too?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mixers"></a><a name="N10633"></a><b>4.1.</b></td>
           <td valign="top" align="left"><p><a name="mixers.q"></a>What are all these mixers?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There are several implementations of <tt class="classname">Mixer</tt> in Java Sound:</p>
            <div class="variablelist">
             <dl>
              <dt>
               <span class="term">"Java Sound Audio Engine", </span>
               <span class="term">beatnik engine</span>
              </dt>
              <dd>
               <p>This is a software mixing engine. It provides <tt class="classname">SourceDataLine</tt> and <tt class="classname">Clip</tt> instances. It does not provide <tt class="classname">TargetDataLine</tt> instances. Output of this mixer goes to the audio device. In versions up to 1.4.2, this mixer is the default for playback. In 1.5, it is only used if there is no other way to mix audio streams (because neither the soundcard hardware nor the device driver support mixing).</p>
              </dd>
              <dt>
               <span class="term">Simple Input Devices, </span>
               <span class="term">"Microsoft Sound Mapper" (Windows), </span>
               <span class="term">"Linux,dev/dsp,multi threaded" (Linux), </span>
               <span class="term">"Linux,dev/audio,multi threaded" (Linux, Solaris)</span>
              </dt>
              <dd>
               <p>In versions 1.4.2 and earlier, this mixer is used for recording. It provides <tt class="classname">TargetDataLine</tt> instances, but nothing else. In 1.5, it is no longer available, because the direct audio devices can be used for recording on all platforms.</p>
              </dd>
              <dt>
               <span class="term">Direct Audio Devices, </span>
               <span class="term">"Primary Sound Driver" (Windows), </span>
               <span class="term">"Primary Sound Capture Driver" (Windows), </span>
               <span class="term">"Soundcard [plughw:0,0]" (Linux)</span>
              </dt>
              <dd>
               <p>These are mixers that can be used for playback as well as for recording. They provide <tt class="classname">SourceDataLine</tt>, <tt class="classname">TargetDataLine</tt> and <tt class="classname">Clip</tt> instances. In 1.4.2, they became available on Linux; in 1.5, Solaris and Windows followed. These mixers allow simultaneous playback and recording (full-duplex) if the soundcard supports it. These mixers do not do software mixing. So mixing of multiple playback lines is only available if either the soundcard hardware or the device driver are capable of mixing. In other words: You may get only one <tt class="classname">SourceDataLine</tt>, and you will always get only one <tt class="classname">TargetDataLine</tt></p>
              </dd>
              <dt>
               <span class="term">Port Mixers, </span>
               <span class="term">"Port Soundcard" (Windows), </span>
               <span class="term">"Port Soundcard [hw:0,0]" (Linux)</span>
              </dt>
              <dd>
               <p>These mixers provide <tt class="classname">Port</tt> instances, but no other type of Line. So you can't play back or record with these mixers. They became available with 1.4.2 for Windows, and will be available for Solaris and Linux, too, in 1.5. See also <a href="#sec_ports">Ports</a></p>
              </dd>
             </dl>
            </div><p>Note that what Java Sound calls "Mixer" is different from what Windows calls "Mixer":</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th valign="top">Java Sound</th>
                <th valign="top">Windows</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td valign="top">Mixer</td>
                <td valign="top">audio device</td>
               </tr>
               <tr valign="top">
                <td valign="top">Port</td>
                <td valign="top">mixer</td>
               </tr>
              </tbody>
             </table>
            </div><p>See also <a href="#which_mixer_used">How can I find out which <tt class="classname">Mixer</tt> implementation is used?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="no_sdl_from_mixer"></a><a name="N106AA"></a><b>4.2.</b></td>
           <td valign="top" align="left"><p><a name="no_sdl_from_mixer.q"></a>Why are there mixers from which I can't get a <tt class="classname">SourceDataLine</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There are mixer that only provide <tt class="classname">TargetDataLine</tt> instances. In the Sun JDK up to 1.4.2, <tt class="classname">SourceDataLine</tt> instances are only provided by the "Java Sound Audio Engine", while <tt class="classname">TargetDataLine</tt> instances are only provided by the "Simple Input Device" mixers. This is subject to change for JDK 1.5.</p><p>Starting with version 1.4.2, there are additional mixers that provide only <tt class="classname">Port</tt> instances. See also <a href="#mixers">What are all these mixers?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="phone_output"></a><a name="N106C8"></a><b>4.3.</b></td>
           <td valign="top" align="left"><p><a name="phone_output.q"></a>How can I redirect sound output to a phone / modem device?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>With the Sun JDK 1.4.2 or earlier on Windows, you can set the default audio device to the telephone device: Control panel -&gt; Multimedia (or Sounds...) -&gt; Preferred Device. With the "Direct Audio Device" mixers of the JDK 1.5 it is also possible to use the default provider properties to set the default <tt class="classname">Mixer</tt> / <tt class="classname">MixerProvider</tt> inside Java Sound.</p><p>See also <a href="#no_sdl_from_mixer">Why are there mixers from which I can't get a <tt class="classname">SourceDataLine</tt>?</a>, <a href="#capture_source">How can I capture from a specific source (microphone or line-in)?</a>, <a href="#select_mixer">How can I get a <tt class="classname">Line</tt> from a specific <tt class="classname">Mixer</tt>?</a> and <a href="#only_jsae_playback">Why can I record from different soundcards, but not play back to them?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="multiple_soundcards"></a><a name="N106E9"></a><b>4.4.</b></td>
           <td valign="top" align="left"><p>Can I use multiple soundcards at the same time?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>For the Sun JDK, this is possible with version 1.4.2 and later for Linux and with version 1.5.0 and later for Solaris and Windows. For Tritonus, this is possible with the ALSA <tt class="classname">Mixer</tt> implementation. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="only_jsae_playback"></a><a name="N106F4"></a><b>4.5.</b></td>
           <td valign="top" align="left"><p><a name="only_jsae_playback.q"></a>Why can I record from different soundcards, but not play back to them?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is true for Solaris and Windows for Java versions up to 1.4.2. There, playback is only possible via the "Java Sound Audio Engine", which always uses the first soundcard. On the other hand, recording in these versions is done with the "Simple Input Device", which provider one <tt class="classname">Mixer</tt> instance per soundcard.</p><p>With the "Direct Audio Device" mixers, it is possible to choose different soundcards for output, too. See also <a href="#mixers">What are all these mixers?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="supported_formats"></a><a name="N10706"></a><b>4.6.</b></td>
           <td valign="top" align="left"><p><a name="supported_formats.q"></a>How can I obtain the formats supported by a mixer (or at all)?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>First, obtain a list of supported lines either from a <tt class="classname">Mixer</tt> object or from <tt class="classname">AudioSystem</tt>. For this, use the methods <tt class="function">getSourceLineInfo()</tt> and <tt class="function">getTargetLineInfo()</tt>. Then, check each of the returned <tt class="classname">Line.Info</tt> objects if it is an instance of <tt class="classname">DataLine.Info</tt>. If it is, cast the object to <tt class="classname">DataLine.Info</tt>. Now you can call <tt class="function">getFormats()</tt> to obtain the <tt class="classname">AudioFormat</tt> types supported by this line type.</p><p>A code example:</p><pre class="programlisting">
Line.Info[] infos = AudioSystem.getSourceLineInfo();
// or:
// Line.Info[] infos = AudioSystem.getTargetLineInfo();
for (int i = 0; i &lt; infos.length; i++)
{
  if (infos[i] instanceof DataLine.Info)
  {
    DataLine.Info dataLineInfo = (DataLine.Info) infos[i];
    AudioFormat[] supportedFormats = dataLineInfo.getFormats();
  }
}</pre><p>To see what is supported on your system, you can use the application <a class="olink" href="apps/jsinfo.html">jsinfo</a>. See also <a href="#sr_unspecified">Why are there <tt class="classname">AudioFormat</tt> objects with frame rate/sample rate reported as <tt class="constant">-1</tt> when I query a <tt class="classname">Mixer</tt> for its supported formats?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="dad_supported_formats"></a><a name="N1073D"></a><b>4.7.</b></td>
           <td valign="top" align="left"><p>What formats are supported by "Direct Audio Device" mixers?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>It depends on the hardware. The mixers just report formats that are supported by the device driver. Typically, there are between 8 and 20 supported formats. To write a portable application, you should not assume that a certain format is always supported (though in fact, 44.1 kHz 16 bit stereo is almost always supported). Rather, you should check the supported formats at run-time and try to convert your audio data to one of the available formats. See also <a href="#supported_formats">How can I obtain the formats supported by a mixer (or at all)?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="sr_unspecified"></a><a name="N10749"></a><b>4.8.</b></td>
           <td valign="top" align="left"><p><a name="sr_unspecified.q"></a>Why are there <tt class="classname">AudioFormat</tt> objects with frame rate/sample rate reported as <tt class="constant">-1</tt> when I query a <tt class="classname">Mixer</tt> for its supported formats?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The <tt class="constant">-1</tt> (<tt class="constant">AudioSystem.NOT_SPECIFIED</tt>) means that any reasonable sample rate is supported. Common soundcards typically support sample rates between 4 kHz and 48 kHz. See also <a href="#supported_formats">How can I obtain the formats supported by a mixer (or at all)?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="match_port_mixer"></a><a name="N10765"></a><b>4.9.</b></td>
           <td valign="top" align="left"><p><a name="match_port_mixer.q"></a>How can I detect which Port Mixer belongs to which soundcard?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There is no really satisfying solution. You can try to match the <tt class="varname">name</tt> in the <tt class="classname">Mixer.Info</tt> object of a Port Mixer against the one of a DataLine Mixer. On Linux, this is reliable by looking at the device id that is part of the mixer name: "(hw:0)", "(hw:1)", "(plughw:0,1)". The first (or only) number refers to the number of the soundcard.</p><p>Windows don't allow to query which port belongs to which soundcard (there are ways on Windows, but it was not possible to use them for Java Sound because they require actually opening the devices). So the only thing you can do is to match the name of the soundcard. However, this will not always work reliably. Especially, if there are two soundcards of the same model, their names will look the same.</p><p>See also <a href="#mixers">What are all these mixers?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="which_mixer_used"></a><a name="N1077C"></a><b>4.10.</b></td>
           <td valign="top" align="left"><p><a name="which_mixer_used.q"></a>How can I find out which <tt class="classname">Mixer</tt> implementation is used?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You can detect the mixer implementation from the class types of the lines you get:</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr>
                <th><tt class="classname">Mixer</tt> implementation</th>
                <th>interface type</th>
                <th>class name</th>
               </tr>
              </thead>
              <tbody>
               <tr>
                <td rowspan="3">Java Sound Audio Engine</td>
                <td><tt class="classname">Mixer</tt></td>
                <td><tt class="classname">HeadspaceMixer</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">SourceDataLine</tt></td>
                <td><tt class="classname">MixerSourceLine</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">Clip</tt></td>
                <td><tt class="classname">MixerClip</tt></td>
               </tr>
               <tr>
                <td rowspan="4">Direct Audio Device</td>
                <td><tt class="classname">Mixer</tt></td>
                <td><tt class="classname">DirectAudioDevice</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">SourceDataLine</tt></td>
                <td><tt class="classname">DirectAudioDevice$DirectSDL</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">TargetDataLine</tt></td>
                <td><tt class="classname">DirectAudioDevice$DirectTDL</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">Clip</tt></td>
                <td><tt class="classname">DirectAudioDevice$DirectClip</tt></td>
               </tr>
               <tr>
                <td rowspan="2">Simple Input Device</td>
                <td><tt class="classname">Mixer</tt></td>
                <td><tt class="classname">SimpleInputDevice</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">TargetDataLine</tt></td>
                <td><tt class="classname">SimpleInputDevice$InputDeviceDataLine</tt></td>
               </tr>
               <tr>
                <td rowspan="4">Tritonus ESD mixer</td>
                <td><tt class="classname">Mixer</tt></td>
                <td><tt class="classname">EsdMixer</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">SourceDataLine</tt></td>
                <td><tt class="classname">EsdSourceDataLine</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">TargetDataLine</tt></td>
                <td><tt class="classname">EsdTargetDataLine</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">Clip</tt></td>
                <td><tt class="classname">EsdClip</tt></td>
               </tr>
               <tr>
                <td rowspan="3">Tritonus ALSA mixer</td>
                <td><tt class="classname">Mixer</tt></td>
                <td><tt class="classname">AlsaDataLineMixer</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">SourceDataLine</tt></td>
                <td><tt class="classname">AlsaSourceDataLine</tt></td>
               </tr>
               <tr>
                <td><tt class="classname">TargetDataLine</tt></td>
                <td><tt class="classname">AlsaTargetDataLine</tt></td>
               </tr>
              </tbody>
             </table>
            </div><p>See also <a href="#mixers">What are all these mixers?</a> and <a href="#which_driver_used">How can I find out which soundcard driver is used?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="why_jsae_default"></a><a name="N10820"></a><b>4.11.</b></td>
           <td valign="top" align="left"><p><a name="why_jsae_default.q"></a>Why do I get lines from the "Java Sound Audio Engine" in the JDK 1.5.0 though the "Direct Audio Device" mixers are available, too?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>In the JDK 1.5.0, the "Direct Audio Device" mixers are used by default if they support more than one concurrently active <tt class="classname">SourceDataLine</tt>. This is the case if either the soundcard hardware supports mixing of multiple channels (and the driver supports it) or the driver does software mixing of multiple channels.</p><p>If this is not the case, the "Java Sound Audio Engine" is used by default. If you don't mind the limitation that there will be only one <tt class="classname">SourceDataLine</tt> or <tt class="classname">Clip</tt> instance, you can still use the "Direct Audio Device" mixers by addressing them directly (see <a href="#select_mixer">How can I get a <tt class="classname">Line</tt> from a specific <tt class="classname">Mixer</tt>?</a>).</p><p>See also <a href="#alsa_default">Can I make ALSA the default in version 1.4.2?</a> and <a href="#alsa_mixing">How can I enable mixing with the "Direct Audio Device" mixers on Linux?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_drivers"></a><h3 class="title"><a name="sec_drivers"></a>5. Soundcard Drivers</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              5.1. 
              <a href="#which_driver_possible">Which soundcard drivers can be used by Java Sound?</a>
             </dt>
             <dt>
              5.2. 
              <a href="#which_driver_used">How can I find out which soundcard driver is used?</a>
             </dt>
             <dt>
              5.3. 
              <a href="#use_alsa">I've installed ALSA and the JDK 1.4.2 to take advantage of the ALSA support. Now, how do I use it?</a>
             </dt>
             <dt>
              5.4. 
              <a href="#alsa_default">Can I make ALSA the default in version 1.4.2?</a>
             </dt>
             <dt>
              5.5. 
              <a href="#alsa_mixing">How can I enable mixing with the "Direct Audio Device" mixers on Linux?</a>
             </dt>
             <dt>
              5.6. 
              <a href="#req_direct_audio">What are the requirements for using the direct audio devices?</a>
             </dt>
             <dt>
              5.7. 
              <a href="#which_linux_driver">How can I find out which soundcard driver is installed on my Linux system?</a>
             </dt>
             <dt>
              5.8. 
              <a href="#hardware_buffers">How does Java Sound deal with hardware buffers of the soundcard?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="which_driver_possible"></a><a name="N10848"></a><b>5.1.</b></td>
           <td valign="top" align="left"><p><a name="which_driver_possible.q"></a>Which soundcard drivers can be used by Java Sound?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left">
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th valign="top">Mixer implementation</th>
                <th valign="top">Windows</th>
                <th valign="top">Linux</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td valign="top">Java Sound Audio Engine</td>
                <td valign="top">Windows Multimedia API</td>
                <td valign="top">OSS or ALSA OSS emulation</td>
               </tr>
               <tr valign="top">
                <td valign="top">Direct Audio Device</td>
                <td valign="top">DirectSound</td>
                <td valign="top">ALSA</td>
               </tr>
               <tr valign="top">
                <td valign="top">Simple Input Device</td>
                <td valign="top">Windows Multimedia API</td>
                <td valign="top">OSS or ALSA OSS emulation</td>
               </tr>
               <tr valign="top">
                <td valign="top">Tritonus ALSA Mixer</td>
                <td valign="top">---</td>
                <td valign="top">ALSA</td>
               </tr>
               <tr valign="top">
                <td valign="top">Tritonus ESD Mixer</td>
                <td valign="top">---</td>
                <td valign="top">depends on the version of Esound. There are versions for OSS and ALSA.</td>
               </tr>
               <tr valign="top">
                <td valign="top">jsasio</td>
                <td valign="top">ASIO Driver API</td>
                <td valign="top">---</td>
               </tr>
              </tbody>
             </table>
            </div><p>See also <a href="#mixers">What are all these mixers?</a> and <a class="olink" href="faq_misc.html#asio">Q:&nbsp;3.5</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="which_driver_used"></a><a name="N10897"></a><b>5.2.</b></td>
           <td valign="top" align="left"><p><a name="which_driver_used.q"></a>How can I find out which soundcard driver is used?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>First, check which mixer is used (see <a href="#which_mixer_used">How can I find out which <tt class="classname">Mixer</tt> implementation is used?</a>). Then consult the table in <a href="#which_driver_possible">Which soundcard drivers can be used by Java Sound?</a> to find out the driver.</p><p>For Linux, there is no way to tell from Java Sound if a real OSS driver or ALSA's OSS emulation is used. See also <a href="#which_linux_driver">How can I find out which soundcard driver is installed on my Linux system?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="use_alsa"></a><a name="N108AE"></a><b>5.3.</b></td>
           <td valign="top" align="left"><p>I've installed ALSA and the JDK 1.4.2 to take advantage of the ALSA support. Now, how do I use it?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>In 1.4.2, the "Java Sound Audio Engine" is still the default. To use the ALSA support, you have to obtain the Mixer object representing the direct audio access. Then, obtain lines from this object instead of via <tt class="classname">AudioSystem</tt>. See also <a href="#select_mixer">How can I get a <tt class="classname">Line</tt> from a specific <tt class="classname">Mixer</tt>?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="alsa_default"></a><a name="N108BD"></a><b>5.4.</b></td>
           <td valign="top" align="left"><p><a name="alsa_default.q"></a>Can I make ALSA the default in version 1.4.2?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You can, but only with an ugly trick: rename, remove or disable the device files <tt class="filename">/dev/dsp*</tt>. This disables the Java Sound Audio Engine, so the JDK falls back to use the ALSA mixers. But be aware that this disables the software synthesizer ("Java Sound Synthesizer"), too. So you won't be able to play MIDI files. And of course native applications using <tt class="filename">/dev/dsp</tt> won't be happy, too. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="alsa_mixing"></a><a name="N108CE"></a><b>5.5.</b></td>
           <td valign="top" align="left"><p><a name="alsa_mixing.q"></a>How can I enable mixing with the "Direct Audio Device" mixers on Linux?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The "Direct Audio Device" implementation on Linux is based on <a href="http://www.alsa-project.org/" target="_top">ALSA</a>. Mixing is available in the <tt class="classname">Mixer</tt> instance if ALSA provides mixing. This is the case if the soundcard can do mixing in hardware and its ALSA driver supports this feature. This is true for some common soundcards like Soundblaster LIFE! and Soundblaster Audigy and cards based on the Trident 4D Wave NX chipset. If this feature is available at all, it needs no special configuration. It is enabled by default.</p><p>Using ALSA's <a href="http://alsa.opensrc.org/index.php?page=DmixPlugin" target="_top">dmix plug-in</a> does not work together with Java Sound. The reason is that the "Direct Audio Device" mixer implementation based on ALSA queries the available hardware devices. However, a dmix device in ALSA is no hardware device, so it is not recognized. Discussions about this issue led to the conclusion that there is no easy way to integrate a query for additional devices.</p><p>See also <a class="olink" href="faq_misc.html#no_daemons">Q:&nbsp;3.4</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="req_direct_audio"></a><a name="N108EA"></a><b>5.6.</b></td>
           <td valign="top" align="left"><p>What are the requirements for using the direct audio devices?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>According to Florian:</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr>
                <th>Operating System</th>
                <th>JDK version</th>
                <th>Audio Device driver</th>
               </tr>
              </thead>
              <tbody>
               <tr>
                <td>Linux</td>
                <td>1.4.2</td>
                <td><a href="http://www.alsa-project.org/" target="_top">ALSA</a> 0.9.2 or later</td>
               </tr>
               <tr>
                <td>Windows</td>
                <td>1.5.0</td>
                <td>DirectSound 5.0 or later (included with Windows ME/2000/XP)</td>
               </tr>
               <tr>
                <td>Solaris</td>
                <td>1.5.0</td>
                <td>Mixer enabled (available in Solaris 8 and later)</td>
               </tr>
              </tbody>
             </table>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="which_linux_driver"></a><a name="N10919"></a><b>5.7.</b></td>
           <td valign="top" align="left"><p><a name="which_linux_driver.q"></a>How can I find out which soundcard driver is installed on my Linux system?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Run <span><b class="command">/sbin/lsmod</b></span> to show the currently loaded kernel modules. If there are entries "snd" and "snd-*", you are running ALSA. A typical picture of ALSA is like this:</p><pre class="screen">
snd-mixer-oss          12672   1 (autoclean) [snd-pcm-oss]
snd-seq                38348   0 (autoclean) (unused)
snd-emu10k1            65956   1 (autoclean)
snd-hwdep               5024   0 (autoclean) [snd-emu10k1]
snd-rawmidi            13792   0 (autoclean) [snd-emu10k1]
snd-pcm                64416   0 (autoclean) [snd-pcm-oss snd-emu10k1]
snd-page-alloc          6148   0 (autoclean) [snd-emu10k1 snd-pcm]
snd-timer              15040   0 (autoclean) [snd-seq snd-pcm]
snd-ac97-codec         42200   0 (autoclean) [snd-emu10k1]
snd-seq-device          4116   0 (autoclean) [snd-seq snd-emu10k1 snd-rawmidi]
snd-util-mem            1504   0 (autoclean) [snd-emu10k1]
snd                    36832   0 (autoclean) [snd-pcm-oss snd-mixer-oss snd-seq
snd-emu10k1 snd-hwdep snd-rawmidi snd-pcm snd-timer snd-ac97-codec
snd-seq-device snd-util-mem]
soundcore               3556   6 (autoclean) [snd]
		  </pre><p>An alternative way it to look for the directory <tt class="filename">/proc/asound/</tt>. It is only present if ALSA is active. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="hardware_buffers"></a><a name="N1092F"></a><b>5.8.</b></td>
           <td valign="top" align="left"><p><a name="hardware_buffers.q"></a>How does Java Sound deal with hardware buffers of the soundcard?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Internally, Java Sound implementations usually do not work with hardware buffers. Instead, they use the platform's audio API for accessing the soundcard. See also <a href="#sec_buffers">DataLine buffers</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_synchronization"></a><h3 class="title"><a name="sec_synchronization"></a>6. Synchronization</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              6.1. 
              <a href="#sync_playback">How can I synchronize two or more playback lines?</a>
             </dt>
             <dt>
              6.2. 
              <a href="#sync_playback_recording">How can I synchronize playback (SourceDataLines) with recording (TargetDataLines)?</a>
             </dt>
             <dt>
              6.3. 
              <a href="#sync_playback_externally">How can I synchronize playback to an external clock?</a>
             </dt>
             <dt>
              6.4. 
              <a href="#sync_clip">Do multiple Clip instances that are looped stay in sync?</a>
             </dt>
             <dt>
              6.5. 
              <a href="#clock_drift">Why does recording or playing for a certain period of time results in audio data that is shorter or longer than the period I recorded / played?</a>
             </dt>
             <dt>
              6.6. 
              <a href="#mixer_synchronize">How can I use Mixer.synchronize()?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="sync_playback"></a><a name="N10942"></a><b>6.1.</b></td>
           <td valign="top" align="left"><p><a name="sync_playback.q"></a>How can I synchronize two or more playback lines?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The synchronization functions in <tt class="classname">Mixer</tt> are not implemented. Nevertheless, playback typically stays in sync. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="sync_playback_recording"></a><a name="N1094E"></a><b>6.2.</b></td>
           <td valign="top" align="left"><p><a name="sync_playback.q"></a>How can I synchronize playback (SourceDataLines) with recording (TargetDataLines)?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>As with multiple playback lines from the same <tt class="classname">Mixer</tt> object, playback and recording lines from the same <tt class="classname">Mixer</tt> object stay in sync once they are started. In practice, this means that you can achieve synchronization this easy way only by using the "Direct Audio Device" mixers. Since the "Java Sound Audio Engine" only provides playback lines, but no recording lines, playback/recording sync is not as easy with the "Java Sound Audio Engine". See also <a href="#sync_playback">How can I synchronize two or more playback lines?</a></p><p>If playback and recording lines originate from different <tt class="classname">Mixer</tt> objects, you need to synchronize the soundcards that are represented by the <tt class="classname">Mixer</tt> objects. So the situation is similar to external synchronization. See also <a href="#sync_playback_externally">How can I synchronize playback to an external clock?</a></p><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="sync_playback_externally"></a><a name="N1096D"></a><b>6.3.</b></td>
           <td valign="top" align="left"><p><a name="sync_playback_externally.q"></a>How can I synchronize playback to an external clock?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is possible in one of two ways:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>On the hardware level if your soundcard has the possibility to synchronize its internal clock to an external one. This is typically the case on "pro" soundcards that have a "word clock" input. Java Sound does not provide a way to query this possibility or to switch it on or off. However, if soundcards are configured to use external synchronization (by using a native tool), this also takes effect for sound handling with Java Sound.</p></li>
              <li><p>On the software level this is possible with a time streching/shrinking algorithm. See also <a href="#clock_drift">Why does recording or playing for a certain period of time results in audio data that is shorter or longer than the period I recorded / played?</a></p></li>
             </ul>
            </div><p>See also <a class="olink" href="faq_midi.html#synchronize_seq">Q:&nbsp;3.12</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="sync_clip"></a><a name="N10986"></a><b>6.4.</b></td>
           <td valign="top" align="left"><p><a name="sync_clip.q"></a>Do multiple <tt class="classname">Clip</tt> instances that are looped stay in sync?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Yes. There is no mechanism in Java Sound to start <tt class="classname">Clip</tt> instances synchronuously. However, calling <tt class="function">start()</tt> for all <tt class="classname">Clip</tt> instances in a loop with the <tt class="classname">Clip</tt> instances otherwise prepared should be precise enough. Once started, <tt class="classname">Clip</tt> instances played on the same <tt class="classname">Mixer</tt> instance should stay in sync. If they don't, make sure they have the exactly same length. <tt class="classname">Clip</tt> instances played on different <tt class="classname">Mixer</tt> instance are likely to drift away from each other, unless the soundcard clocks are synchronized (which is only possible on "pro" soundcards). (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="clock_drift"></a><a name="N109AB"></a><b>6.5.</b></td>
           <td valign="top" align="left"><p><a name="clock_drift.q"></a>Why does recording or playing for a certain period of time results in audio data that is shorter or longer than the period I recorded / played?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The reason of this problem is clock drift. There are two clocks involved in this scenario: The <span class="emphasis"><em>real time clock</em></span> is used to measure the period of time you are recording or playing. The <span class="emphasis"><em>soundcard clock</em></span> determine how many samples are recorded or played during this period. Since there are two different hardware devices, the inherently drift away from each other over time.</p><p>There are several ways to deal with this problem:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>You can try to minimize the drift by making both clocks high-precision. The real-time clock of the computer can be synchronized to atomic clocks by using some means of synchronization. The Network Time Protocol (NTP) is commonly used for this on the internet. On Windows, the utility <a href="http://www.arachnoid.com/abouttime/" target="_top">AboutTime</a> can be used for synchronization. The precision of the soundcard clock can be enhanced by using a professional soundcard with a "word clock" input. This input has to be connected to an external high-precision time base. In this case, the soundcard clock is synchronized to the external clock source. Professional studios often spend tens of thousands of dollars to purchase a high-precision time base. Note that this solution minimizes the drift, but cannot remove it completely.</p></li>
              <li><p>You can use the soundcard clock as your time base to measure wall-clock time. This way, you have removed the second clock, so there is no drift. While this may sound inconvenient, it may be a good solution if the audio data has to be synchronized to, for instance, video playback or the playback of slides, mouse events or MIDI. If your soundcard's clock is synchronized to an external time base as described in the previous point, using it to measure wall-clock time is likely to give much better results than using the computer's (unsynchronized) "real time" clock.</p></li>
              <li><p>If both of the above solutions are not appropriate, you can adapt the length of the audio data by doing time streching/shrinking. This usually requires fairly advanced and computationally expensive DSP algorithms. In this case, you do not remove the clock drift, but remove the effect of it on your audio data.</p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mixer_synchronize"></a><a name="N109CC"></a><b>6.6.</b></td>
           <td valign="top" align="left"><p>How can I use <tt class="function">Mixer.synchronize()</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Synchronization isn't implemented in any known Java Sound implementation. It may be implemented in future versions. Note that you can check the availability of synchronization with the method <a href="http://java.sun.com/j2se/1.5.0/docs/api/javax/sound/sampled/Mixer.html#isSynchronizationSupported(javax.sound.sampled.Line[],%20boolean)" target="_top"><tt class="function">Mixer.isSynchronizationSupported()</tt></a>. See also <a href="#sync_clip">Do multiple <tt class="classname">Clip</tt> instances that are looped stay in sync?</a>, <a href="#sync_playback">How can I synchronize two or more playback lines?</a> and <a href="#clock_drift">Why does recording or playing for a certain period of time results in audio data that is shorter or longer than the period I recorded / played?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_files"></a><h3 class="title"><a name="sec_files"></a>7. Audio Files</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              7.1. 
              <a href="#save_audio_data">How can I save audio data to a file, like .wav or .aiff?</a>
             </dt>
             <dt>
              7.2. 
              <a href="#add_chunks">How can I add special chunks to .wav or .aiff files (like for a descriptive text or copyright)?</a>
             </dt>
             <dt>
              7.3. 
              <a href="#read_looppoints">Is it possible to get information about loop points (e.g. from the 'smpl' chunk in .wav files) using the AudioFileFormat properties?</a>
             </dt>
             <dt>
              7.4. 
              <a href="#getframelength">Why does AudioFileFormat.getFrameLength() always return -1 for .wav files?</a>
             </dt>
             <dt>
              7.5. 
              <a href="#8bit_signed_wav">Why does a .wav file contain PCM_UNSIGNED data if I try to save 8 bit PCM_SIGNED data?</a>
             </dt>
             <dt>
              7.6. 
              <a href="#read_vox">How can I read in a .vox file and save it as .wav file?</a>
             </dt>
             <dt>
              7.7. 
              <a href="#read_headerless">How can I read from a headerless audio file?</a>
             </dt>
             <dt>
              7.8. 
              <a href="#file_length">How can I determine the length or the duration of an audio file?</a>
             </dt>
             <dt>
              7.9. 
              <a href="#write_parts">How can I write an audio file in smaller parts?</a>
             </dt>
             <dt>
              7.10. 
              <a href="#wav_not_recognized">Why are some .wav files not recognized by Java Sound?</a>
             </dt>
             <dt>
              7.11. 
              <a href="#big_endian_wav">Why is it not possible to write big-endian data using a WaveAudioOutputStream?</a>
             </dt>
             <dt>
              7.12. 
              <a href="#edit_file">How can I edit or modify audio files?</a>
             </dt>
             <dt>
              7.13. 
              <a href="#audio_data_cached">How can I play audio files where the data is cached in the RAM?</a>
             </dt>
             <dt>
              7.14. 
              <a href="#write_file_vs_outputstream">Why is there a difference between using AudioSystem.write(..., File) and using AudioSystem.write(..., OutputStream) with a FileOutputStream?</a>
             </dt>
             <dt>
              7.15. 
              <a href="#aos_docs">Where can I find documentation on the AudioOutputStream programming?</a>
             </dt>
             <dt>
              7.16. 
              <a href="#ais_skip">How can I start playback of a file at a certain position?</a>
             </dt>
             <dt>
              7.17. 
              <a href="#multichannel_files">Is it possible to read and write multichannel audio files?</a>
             </dt>
             <dt>
              7.18. 
              <a href="#compare_files">How can I compare two audio files?</a>
             </dt>
             <dt>
              7.19. 
              <a href="#overwrite_file">Is it possible to insert recorded audio data into an existing file?</a>
             </dt>
             <dt>
              7.20. 
              <a href="#file_in_bytearray">How can I store an audio file in a byte array?</a>
             </dt>
             <dt>
              7.21. 
              <a href="#aos_unknown_length">Which value should I use for the length of the file in AudioOutputStreams if the length is not known in advance?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="save_audio_data"></a><a name="N109F0"></a><b>7.1.</b></td>
           <td valign="top" align="left"><p>How can I save audio data to a file, like <tt class="filename">.wav</tt> or <tt class="filename">.aiff</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Have a look at the <a class="olink" href="examples/index.html">Java Sound Resources: Examples</a>. (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="add_chunks"></a><a name="N10A04"></a><b>7.2.</b></td>
           <td valign="top" align="left"><p>How can I add special chunks to <tt class="filename">.wav</tt> or <tt class="filename">.aiff</tt> files (like for a descriptive text or copyright)?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The Java Sound API does not support this currently. Future versions are likely to, because this is indeed quite important. For the moment, you will need to implement your own class for writing <tt class="filename">.wav</tt> or <tt class="filename">.aiff</tt> files. Or make meaningful filenames... (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="read_looppoints"></a><a name="N10A1C"></a><b>7.3.</b></td>
           <td valign="top" align="left"><p><a name="read_looppoints.q"></a>Is it possible to get information about loop points (e.g. from the 'smpl' chunk in <tt class="filename">.wav</tt> files) using the <tt class="classname">AudioFileFormat</tt> properties?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>While with the JDK 1.5's properties there is a way to represent such information, Sun's <tt class="classname">AudioFileReader</tt> implementation just ignores such chunks. However, it is possible to write an own implementation that handles the chunks and places the information in <tt class="classname">AudioFileFormat</tt> properties. See also <a class="olink" href="faq_misc.html#sec_spi">Q &amp; A&nbsp;2, &#x201c;Service Provider Interface (SPI)&#x201d;</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="getframelength"></a><a name="N10A36"></a><b>7.4.</b></td>
           <td valign="top" align="left"><p>Why does <tt class="function">AudioFileFormat.getFrameLength()</tt> always return <tt class="constant">-1</tt> for <tt class="filename">.wav</tt> files?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This information is never given in the <tt class="classname">AudioFileFormat</tt> for <tt class="filename">.wav</tt> files. It is a more or less reasonable choice from an implementation point of view. The reason is the chunk-oriented structure of the <tt class="filename">.wav</tt> file format. The information about the audio data length is in the format chunk of the <tt class="filename">.wav</tt> file. According to the specification, this chunk may be the last one. In other words: It may be the case that for getting the format information, you have to read to the end of a 20 MB file. That's why the implementors decided to not give this information.</p><p>The workaround: fetch an <tt class="classname">AudioInputStream</tt> with <tt class="function">AudioSystem.getAudioInputStream(File)</tt>. Then query the <tt class="classname">AudioInputStream</tt> object for its length. You can see an example of this technique in <a class="olink" href="examples/AudioFileInfo.html">Getting information about an audio file</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="8bit_signed_wav"></a><a name="N10A68"></a><b>7.5.</b></td>
           <td valign="top" align="left"><p>Why does a <tt class="filename">.wav</tt> file contain <tt class="constant">PCM_UNSIGNED</tt> data if I try to save 8 bit <tt class="constant">PCM_SIGNED</tt> data?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>By the specification, 8 bit data in <tt class="filename">.wav</tt> files has to be unsigned. Therefore, the signedness is converted automatically by Java Sound's file writer. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="read_vox"></a><a name="N10A7E"></a><b>7.6.</b></td>
           <td valign="top" align="left"><p>How can I read in a <tt class="filename">.vox</tt> file and save it as <tt class="filename">.wav</tt> file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Probably it's simplest to do all by yourself: use a <tt class="classname">RandomAccessFile</tt> or similar to open the vox file, parse the headers, etc. You need to know the vox file format, you can find many documents specifying it on the Internet. To create a <tt class="filename">.wav</tt> file from that, create a <tt class="classname">AudioFileFormat</tt> instance with the format read from the vox-header and supply an InputStream with the audi data of the vox file. You can then use <tt class="function">AudioSystem.write()</tt> to write a <tt class="filename">.wav</tt> file. (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="read_headerless"></a><a name="N10AA0"></a><b>7.7.</b></td>
           <td valign="top" align="left"><p>How can I read from a headerless audio file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>If you know the format of your data, you can use the following approach:</p><pre class="programlisting">
File file = new File("headerless_audio_data.dat");
InputStream is = new FileInputStream(file);
is = new BufferedInputStream(is);
AudioFormat format = new AudioFormat(...);
long lLengthInFrames = file.length() / format.getFrameSize();
AudioInputStream ais = new AudioInputStream(is, format,
               lLengthInFrames);</pre><p>See also the example <a class="olink" href="examples/RawAudioDataConverter.html">Converting raw data (headerless) files</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="file_length"></a><a name="N10AB1"></a><b>7.8.</b></td>
           <td valign="top" align="left"><p><a name="file_length.q"></a>How can I determine the length or the duration of an audio file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>A common technique that works for PCM data is shown in the example <a class="olink" href="examples/AudioFileInfo.html">Getting information about an audio file</a>. For files with encoded data, the general technique is the following:</p><pre class="programlisting">
File file = new File("my_file.ext");
AudioFileFormat audioFileFormat = AudioSystem.getAudioFileFormat(file);
// get all properties
Map&lt;String, Object&gt; properties = audioFileFormat.properties();
// duration is in microseconds
Long duration = (Long) properties.get("duration");
}</pre><p>Note that this technique requires the JDK 1.5.0. Even with this version, it currently does not work for ordinary <tt class="filename">.aiff</tt>, <tt class="filename">.au</tt> and <tt class="filename">.wav</tt> files (this is an implementation issue that can be fixed easily).</p><p>With recent javazoom versions of the <a href="#sec_mp3">mp3</a> and <a href="#sec_vorbis">Ogg Vorbis</a> plug-ins (not with the Tritonus versions), you can use a hack that tries to simulate the above programming technique. It can be used with older JDK versions:</p><pre class="programlisting">
import org.tritonus.share.sampled.file.TAudioFileFormat

File file = new File("my_file.ext");
AudioFileFormat audioFileFormat = AudioSystem.getAudioFileFormat(file);
if (audioFileFormat instanceof TAudioFileFormat)
{
    // Tritonus SPI compliant audio file format.
    Map properties = ((TAudioFileFormat) audioFileFormat).properties();
    // duration is in microseconds
    Long duration = (Long) properties.get("duration");
}</pre><p>See also <a href="#ais_unknown_length">Why does <tt class="function">AudioInputStream.getFrameLength()</tt> return <tt class="constant">-1</tt>?</a>, <a href="#vorbis_duration">How can I get the duration of an Ogg Vorbis file?</a>, <a href="#detect_mp3_length">How can I get the length of an mp3 stream?</a> and <a href="#calculate_gsm_duration">How can I calculate the duration of a GSM file?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="write_parts"></a><a name="N10AEE"></a><b>7.9.</b></td>
           <td valign="top" align="left"><p><a name="write_parts.q"></a>How can I write an audio file in smaller parts?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p><tt class="function">AudioSystem.write()</tt> assumes that the <tt class="classname">AudioInputStream</tt> you pass to it contains everything that should go into the file. If you don't want to write the file as a whole, but in blocks, you can't use <tt class="function">AudioSystem.write()</tt>. The alternative is to use Tritonus' <tt class="classname">AudioOutputStream</tt> architecture. See <a href="http://www.tritonus.org/plugins.html" target="_top">Tritonus plug-ins</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="wav_not_recognized"></a><a name="N10B08"></a><b>7.10.</b></td>
           <td valign="top" align="left"><p>Why are some <tt class="filename">.wav</tt> files not recognized by Java Sound?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Most types of audio files formats, including <tt class="filename">.wav</tt>, can contain audio data in various compressed formats. Only some of the formats are handled by the standard audio file readers. The formats handled are A-law and &#x3bc;-law. Not handled are IMA ADPCM, MS ADPCM, and others. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="big_endian_wav"></a><a name="N10B18"></a><b>7.11.</b></td>
           <td valign="top" align="left"><p>Why is it not possible to write big-endian data using a <tt class="classname">WaveAudioOutputStream</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p><tt class="filename">.wav</tt> files always store data in little-endian order. And by design, <tt class="classname">AudioOutputStreams</tt> do not do any magic. Especially, they do not automatically convert endianess or signedness. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="edit_file"></a><a name="N10B29"></a><b>7.12.</b></td>
           <td valign="top" align="left"><p>How can I edit or modify audio files?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There are no special methods for this in Java Sound. Nevertheless, it is obviously possible: read data from a file into a byte array, modify the audio data there and save the modified array to a file. See also <a href="#file_bytearray">How can I read an audio file and store the audio data in a byte array?</a> and <a href="#bytearray_file">How can I write audio data from a byte array to an audio file?</a>.</p><p>An alternative approach is to write a subclass of <tt class="classname">AudioInputStream</tt> that modifies the data "flowing" through it. You can see an example of this technique in <a class="olink" href="examples/AmplitudeConverter.html">Change the amplitude (volume) of an audio file</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="audio_data_cached"></a><a name="N10B42"></a><b>7.13.</b></td>
           <td valign="top" align="left"><p>How can I play audio files where the data is cached in the RAM?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There are two possibilities:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Use <tt class="classname">Clip</tt> lines. They load the data into the RAM before playback. However, there is a limit to the size of the data somwhere between 2 and 5 MB. See also <a href="#sec_clip">Clip</a></p></li>
              <li><p>Read the whole file (including its headers) into a byte array. Then construct a <tt class="classname">ByteArrayInputStream</tt> from this array and pass it to <tt class="function">AudioSystem.getAudioInputStream(InputStream)</tt> to obtain an <tt class="classname">AudioInputStream</tt>.</p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="write_file_vs_outputstream"></a><a name="N10B63"></a><b>7.14.</b></td>
           <td valign="top" align="left"><p>Why is there a difference between using <tt class="function">AudioSystem.write(..., File)</tt> and using <tt class="function">AudioSystem.write(..., OutputStream)</tt> with a <tt class="classname">FileOutputStream</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The basic problem is that the length of the audio data has to be given in the header of an audio file, and the header is written at the beginning of the file. The length may not be known at the time the header is written. If the <tt class="classname">AudioInputStream</tt> passed to <tt class="function">write()</tt> has a known length, this length is used for filling in the header. If, however, the <tt class="classname">AudioInputStream</tt> has an unknown length (<tt class="constant">AudioSystem.NOT_SPECIFIED</tt>), there is no valid information to fill in the header at the beginning. <tt class="classname">OutputStream</tt> allows only sequential writing: once the header is written, it cannot be changed any more. So if the length of the audio data is unknown, the header will contain invalid length information. If the destination is given as a <tt class="classname">File</tt>, the audio file writer can open the file in random access mode. After writing all audio data, it goes back to the beginning of the file and fixes the header with the then-known length information. This method is called "backpatching".</p><p>Due to this behaviour, <tt class="function">AudioSystem.write(..., File)</tt> is recommended over <tt class="function">AudioSystem.write(..., OutputStream)</tt>, if using it is possible. See also <a href="#ais_unknown_length">Why does <tt class="function">AudioInputStream.getFrameLength()</tt> return <tt class="constant">-1</tt>?</a></p><p>The <tt class="classname">AudioOutputStream</tt> architecture of Tritonus has to deals with the same problem. There, the difference exists between using a <tt class="classname">TSeekableDataOutputStream</tt> (representing a <tt class="classname">File</tt>, allows backpatching) and using a <tt class="classname">TNonSeekableDataOutputStream</tt> (representing an <tt class="classname">OutputStream</tt>, does not allow backpatching). See also <a href="#write_parts">How can I write an audio file in smaller parts?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="aos_docs"></a><a name="N10BAB"></a><b>7.15.</b></td>
           <td valign="top" align="left"><p>Where can I find documentation on the <tt class="classname">AudioOutputStream</tt> programming?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The API documentation is part of the Tritonus docs. See <a class="olink" href="faq_tritonus.html#api_docs">Q:&nbsp;9</a> The recommended way to learn about programming with the <tt class="classname">AudioOutputStream</tt> architecture is to look at the examples that use it like <a class="olink" href="examples/OscillatorFileAOS.html">Saving waveform data to a file (AudioOutputStream version)</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="ais_skip"></a><a name="N10BC1"></a><b>7.16.</b></td>
           <td valign="top" align="left"><p>How can I start playback of a file at a certain position?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You can call <tt class="function">skip()</tt> on the <tt class="classname">AudioInputStream</tt> you obtain for the file. Note that <tt class="function">skip()</tt> can only advance the position, it cannot go back. To rewind see <a href="#rewind_ais">How do I rewind an <tt class="classname">AudioInputStream</tt>?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="multichannel_files"></a><a name="N10BD8"></a><b>7.17.</b></td>
           <td valign="top" align="left"><p><a name="multichannel_files.q"></a>Is it possible to read and write multichannel audio files?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The file readers and writers of both the Sun JDK and Tritonus should support interleaved multi-channel WAVE files. This feature hasn't been tested extensively, so there may be minor bugs, but it should basically work.</p><p>Interleaved multichannel PCM formats are represented by an <tt class="classname">AudioFormat</tt> instance with the respective number of channels.</p><p>See also <a href="#multichannel">Can I use multi-channel sound?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="compare_files"></a><a name="N10BEC"></a><b>7.18.</b></td>
           <td valign="top" align="left"><p><a name="compare_files.q"></a>How can I compare two audio files?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>If you want to compare files if they are exactly the same, this is easy: just compare them byte by byte. However, typically, you want to compare two different recordings of the same piece of music. Because of noise, quantisation errors, different volume levels and other effects, two recordings do never match exactly. So a simple comparison can't be used.</p><p>A useful comparison is a non-trivial task that requires knowledge about digital signal processing. One approach to do such a comparison is the following:</p>
            <div class="orderedlist">
             <ol type="1">
              <li><p>normalize the file based on signal power</p></li>
              <li><p>transform to frequency domain with an FFT</p></li>
              <li><p>scale down the FFT components</p></li>
              <li><p>compare the series of frequency components with a statistical analysis for correlation</p></li>
             </ol>
            </div><p>You may get better results by exchanging step 1 with step 2 and/or using a wavelet transformation instead of FFT.</p><p>See also <a href="#fft1">How can I do equalizing / noise reduction / fft / echo cancellation / ...?</a> and <a class="olink" href="faq_performance.html#fft2">Q:&nbsp;2</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="overwrite_file"></a><a name="N10C12"></a><b>7.19.</b></td>
           <td valign="top" align="left"><p><a name="overwrite_file.q"></a>Is it possible to insert recorded audio data into an existing file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>With standard Java Sound functionality, it is not possible to insert recorded sound into an existing file. The obvious workaround is to record to a new, temporary file and then put the pieces together to the file you want.</p><p>If direct writing to an existing file is important to you, you could try to hack the AudioOutputStream classes of Tritonus. I think it is possible to introduce a constructor flag for "open existing" instead of "overwrite file completely" and to introduce a skip() method to move to a cue point. If you're interested in this, Florian and I will help you to find your way through the implementation of AudioOutputStreams. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="file_in_bytearray"></a><a name="N10C1D"></a><b>7.20.</b></td>
           <td valign="top" align="left"><p><a name="file_in_bytearray.q"></a>How can I store an audio file in a byte array?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You can pass an instance of <tt class="classname">ByteArrayOutputStream</tt> to <tt class="function">AudioSystem.write(..., OutputStream)</tt>. The byte array you extract from the <tt class="classname">ByteArrayOutputStream</tt> will contain the complete file including the headers. This technique is especially useful if you want to store audio files in a database. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="aos_unknown_length"></a><a name="N10C30"></a><b>7.21.</b></td>
           <td valign="top" align="left"><p><a name="aos_unknown_length.q"></a>Which value should I use for the length of the file in <tt class="classname">AudioOutputStream</tt>s if the length is not known in advance?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>If the length of the file is not known in advance, you should use the value <tt class="constant">AudioSystem.NOT_SPECIFIED</tt>. Pass this value to the constructors of <tt class="classname">AudioOutputStream</tt> subclasses directly or use it in requesting an <tt class="classname">AudioOutputStream</tt> instance via <tt class="function">AudioSystemShadow.getAudioOutputStream()</tt>.</p><p>Note that not knowing the length makes it impossible to use <tt class="classname">OutputStream</tt>s as target for some audio file types (<tt class="classname">File</tt> targets should work always). (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_audioformat"></a><h3 class="title"><a name="sec_audioformat"></a>8. Sample Representation and AudioFormat</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              8.1. 
              <a href="#digital_audio_representation">How is audio represented digitally?</a>
             </dt>
             <dt>
              8.2. 
              <a href="#floating_point">In which cases should I use a floating point representation for audio data?</a>
             </dt>
             <dt>
              8.3. 
              <a href="#frame_rate">What is the meaning of frame rate in AudioFormat?</a>
             </dt>
             <dt>
              8.4. 
              <a href="#frame_size">What is the meaning of frame size in Audioformat?</a>
             </dt>
             <dt>
              8.5. 
              <a href="#signedness">What is signed / unsigned?</a>
             </dt>
             <dt>
              8.6. 
              <a href="#unsigned_in_byte">How can I use Java's signed byte type to store an 8 bit unsigned sample?</a>
             </dt>
             <dt>
              8.7. 
              <a href="#detect_signedness">How can I find out if an AudioFormat is signed or unsigned?</a>
             </dt>
             <dt>
              8.8. 
              <a href="#endianess">What is endianess / big endian / little endian?</a>
             </dt>
             <dt>
              8.9. 
              <a href="#samples_organized">How are samples organized in a byte array/stream?</a>
             </dt>
             <dt>
              8.10. 
              <a href="#unknown_sample_rate">What does "unknown sample rate" in an AudioFormat object mean?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="digital_audio_representation"></a><a name="N10C57"></a><b>8.1.</b></td>
           <td valign="top" align="left"><p><a name="digital_audio_representation.q"></a>How is audio represented digitally?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Each second of sound has so many (on a CD, 44,100) digital samples of sound pressure per second. The number of samples per second is called sample rate or sample frequency. In PCM (pulse code modulation) coding, each sample is usually a linear representation of amplitude as a signed integer (sometimes unsigned for 8 bit). There is one such sample for each channel, one channel for mono, two channels for stereo, four channels for quad, more for surround sound. One sample frame consists of one sample for each of the channels in turn, by convention running from left to right.</p><p>Each sample can be one byte (8 bits), two bytes (16 bits), three bytes (24 bits), or maybe even 20 bits or a floating-point number. Sometimes, for more than 16 bits per sample, the sample is padded to 32 bits (4 bytes) The order of the bytes in a sample is different on different platforms. In a Windows WAV soundfile, the less significant bytes come first from left to right ("little endian" byte order). In an AIFF soundfile, it is the other way round, as is standard in Java ("big endian" byte order). Floating-point numbers (4 byte float or 8 byte double) are the same on all platforms.</p><p>See also <a href="#samples_organized">How are samples organized in a byte array/stream?</a> and <a href="#endianess">What is endianess / big endian / little endian?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="floating_point"></a><a name="N10C6C"></a><b>8.2.</b></td>
           <td valign="top" align="left"><p><a name="floating_point.q"></a>In which cases should I use a floating point representation for audio data?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Converting sample data to a floating point representation (float or double data type) is handy if you are doing DSP stuff. In this case, it gives greater precision and greater dynamic range. In all other cases, there is no advantage. Note also that conversion to or from floats is expensive, while dealing only with integer formats is typically much faster. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="frame_rate"></a><a name="N10C75"></a><b>8.3.</b></td>
           <td valign="top" align="left"><p>What is the meaning of frame rate in <tt class="classname">AudioFormat</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>For PCM, A-law and &#x3bc;-law data, a frame is all data that belongs to one sampling intervall. This means that the frame rate is the same as the sample rate.</p><p>For compressed formats like <a href="#sec_vorbis">Ogg Vorbis</a>, <a href="#sec_mp3">mp3</a> and <a href="#sec_gsm">GSM 06.10</a>, the situation is different. A frame is a block of data as it is output by the encoder. Often, these blocks contain the information for several sampling intervalls. For instance, a mp3 frame represents about 24 ms. So the frame rate is about 40 Hz. However, the sample rate of the original is preserved even inside the frames and is correctly restored after decoding. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="frame_size"></a><a name="N10C8E"></a><b>8.4.</b></td>
           <td valign="top" align="left"><p>What is the meaning of frame size in <tt class="classname">Audioformat</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>As outlined in the previous question, it depends on what a frame is. For PCM, the frame size is just the number of bytes for one sample, multiplied with the number of channels. Note that usually each individual sample is represented in an integer number of bytes. For instance, a 12 bit stereo frame uses 4 bytes, not 3. For compressed formats, the frame size is some more-or-less arbitrarily chosen number that is a property of the compression schema. Some compression methods do not have a constant, but variable frame size. In this case the value returned by <tt class="function">AudioFormat.getFrameSize()</tt> is <tt class="constant">-1</tt>. Some common frame sizes:</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr>
                <th>format</th>
                <th>frame size</th>
               </tr>
              </thead>
              <tbody>
               <tr>
                <td>PCM, 8 bit mono</td>
                <td>1 byte</td>
               </tr>
               <tr>
                <td>PCM, 8 bit stereo</td>
                <td>2 bytes</td>
               </tr>
               <tr>
                <td>PCM, 16 bit mono</td>
                <td>2 bytes</td>
               </tr>
               <tr>
                <td>PCM, 16 bit stereo</td>
                <td>4 bytes</td>
               </tr>
               <tr>
                <td><a href="#sec_gsm">GSM 06.10</a></td>
                <td>33 bytes</td>
               </tr>
               <tr>
                <td><a href="#sec_mp3">mp3</a></td>
                <td>-1 (variable)</td>
               </tr>
               <tr>
                <td><a href="#sec_vorbis">Ogg Vorbis</a></td>
                <td>-1 (variable)</td>
               </tr>
              </tbody>
             </table>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="signedness"></a><a name="N10CD6"></a><b>8.5.</b></td>
           <td valign="top" align="left"><p>What is signed / unsigned?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>For PCM, sample values are represented by integers. These integers can be signed or unsigned, similar to signed or unsigned data types in programming languages like C. The following table shows the value ranges for signed and unsigned integers of common sizes and of the general case:</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr>
                <th>sample size</th>
                <th>signedness</th>
                <th>minimum value</th>
                <th>center value</th>
                <th>maximum value</th>
               </tr>
              </thead>
              <tbody>
               <tr>
                <td rowspan="2">8 bit</td>
                <td>unsigned</td>
                <td>0</td>
                <td>128</td>
                <td>255</td>
               </tr>
               <tr>
                <td>signed</td>
                <td>-128</td>
                <td>0</td>
                <td>127</td>
               </tr>
               <tr>
                <td rowspan="2">16 bit</td>
                <td>unsigned</td>
                <td>0</td>
                <td>32768</td>
                <td>65536</td>
               </tr>
               <tr>
                <td>signed</td>
                <td>-32768</td>
                <td>0</td>
                <td>32767</td>
               </tr>
               <tr>
                <td rowspan="2">24 bit</td>
                <td>unsigned</td>
                <td>0</td>
                <td>8388608</td>
                <td>16777215</td>
               </tr>
               <tr>
                <td>signed</td>
                <td>-8388608</td>
                <td>0</td>
                <td>8388607</td>
               </tr>
               <tr>
                <td rowspan="2">32 bit</td>
                <td>unsigned</td>
                <td>0</td>
                <td>2147423648</td>
                <td>4294967295</td>
               </tr>
               <tr>
                <td>signed</td>
                <td>-2147423648</td>
                <td>0</td>
                <td>2147423647</td>
               </tr>
               <tr>
                <td rowspan="2">n bit</td>
                <td>unsigned</td>
                <td>0</td>
                <td>2<sup>n - 1</sup></td>
                <td>2<sup>n</sup> - 1</td>
               </tr>
               <tr>
                <td>signed</td>
                <td>-(2<sup>n - 1</sup>)</td>
                <td>0</td>
                <td>2<sup>n - 1</sup> - 1</td>
               </tr>
              </tbody>
             </table>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="unsigned_in_byte"></a><a name="N10D65"></a><b>8.6.</b></td>
           <td valign="top" align="left"><p>How can I use Java's signed byte type to store an 8 bit unsigned sample?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Basically, a byte is a storage container for 8 bits. Whether these 8 bits are used to store a signed or an unsigned numer is a matter of interpretation. Yes, Java always interprets bytes as signed. But they can be interpreted just the other way, too.</p><p>The 8 bits can always represent 256 different bit patterns. In unsigned interpretation, these 256 bit patterns are interpreted as the decimal values 0 to 255. In signed interpretation, patterns are interpreted as the decimal values -128 to 127.</p><p>The following table may help to understand this.</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th valign="top">bit pattern</th>
                <th valign="top">unsigned (straight binary)</th>
                <th valign="top">signed (two's complement)</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td valign="top">0000 0000</td>
                <td valign="top">0</td>
                <td valign="top">0</td>
               </tr>
               <tr valign="top">
                <td valign="top">0000 0001</td>
                <td valign="top">1</td>
                <td valign="top">1</td>
               </tr>
               <tr valign="top">
                <td valign="top">...</td>
                <td valign="top">...</td>
                <td valign="top">...</td>
               </tr>
               <tr valign="top">
                <td valign="top">0111 1110</td>
                <td valign="top">126</td>
                <td valign="top">126</td>
               </tr>
               <tr valign="top">
                <td valign="top">0111 1111</td>
                <td valign="top">127</td>
                <td valign="top">127</td>
               </tr>
               <tr valign="top">
                <td valign="top">1000 0000</td>
                <td valign="top">128</td>
                <td valign="top">-128</td>
               </tr>
               <tr valign="top">
                <td valign="top">1000 0001</td>
                <td valign="top">129</td>
                <td valign="top">-127</td>
               </tr>
               <tr valign="top">
                <td valign="top">...</td>
                <td valign="top">...</td>
                <td valign="top">...</td>
               </tr>
               <tr valign="top">
                <td valign="top">1111 1110</td>
                <td valign="top">254</td>
                <td valign="top">-2</td>
               </tr>
               <tr valign="top">
                <td valign="top">1111 1111</td>
                <td valign="top">255</td>
                <td valign="top">-1</td>
               </tr>
              </tbody>
             </table>
            </div><p>In representing wave forms, the range of the respective interpretation is used to express minimum and maximum of the wave.</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th valign="top">waveform point</th>
                <th valign="top">unsigned coding</th>
                <th valign="top">signed coding</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td valign="top">minimum value</td>
                <td valign="top">0</td>
                <td valign="top">-128</td>
               </tr>
               <tr valign="top">
                <td valign="top">center value</td>
                <td valign="top">128</td>
                <td valign="top">0</td>
               </tr>
               <tr valign="top">
                <td valign="top">maximum value</td>
                <td valign="top">255</td>
                <td valign="top">127</td>
               </tr>
              </tbody>
             </table>
            </div><p>As you can see, the difference between signed and unsigned notation, expressed in decimal, is 128. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="detect_signedness"></a><a name="N10DF9"></a><b>8.7.</b></td>
           <td valign="top" align="left"><p>How can I find out if an <tt class="classname">AudioFormat</tt> is signed or unsigned?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>For PCM, check if the encoding equals either <tt class="constant">AudioFormat.Encoding.PCM_SIGNED</tt> or <tt class="constant">AudioFormat.Encoding.PCM_UNSIGNED</tt>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="endianess"></a><a name="N10E0A"></a><b>8.8.</b></td>
           <td valign="top" align="left"><p><a name="endianess.q"></a>What is endianess / big endian / little endian?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Most common computers have their memory organized in units of 8 bits, called a byte. The bytes can be adressed by ordinal numbers, starting with zero. (The hardware organization of the memory is often in rows of 16, 32, 64, 128 or even more bits. But the instruction set of the processor still gives you the view of the byte-organized memory.) If you want to store a value that needs more than 8 bits, the question arises how the bits of the value are divided into bytes and stored in memory. If you have a value with 16 bits, there is not much discussion that it has to be divided into two groups: bit 0 to 7 and bits 8 to 15. But then, the fight starts. Some CPUs store the first group (bit 0 to 7) in the byte with the lower address and the second group (bits 8 to 15) in the byte with the higher address. This schema is called little endian. As an example, all Intel architecture and Alpha CPUs are little endian. Other types of CPUs do it the other way round, which is called big endian. Sparc (Sun), PowerPC (Motorola, IBM) and Mips (PMC-Sierra) CPUs are big endian.</p><p>For Java Sound, endianess matters if the size of samples (as given by <tt class="function">AudioFormat.getSampleSizeInBits()</tt>) is greater than 8 bit. For 8 bit data, while the endianess still has to be specified in an <tt class="classname">AudioFormat</tt> object, it has no significance. It is a convention in Java Sound that <tt class="classname">Mixer</tt>, <tt class="classname">AudioFileWriter</tt> and <tt class="classname">FormatConversionProvider</tt> implementations handle both endianesses, but you can't really rely on this. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="samples_organized"></a><a name="N10E25"></a><b>8.9.</b></td>
           <td valign="top" align="left"><p><a name="samples_organized.q"></a>How are samples organized in a byte array/stream?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>It depends on the format of the data, which is given as an <tt class="classname">AudioFormat</tt> instance. Below are some common cases.</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th valign="top">byte</th>
                <th valign="top">0</th>
                <th valign="top">1</th>
                <th valign="top">2</th>
                <th valign="top">3</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td valign="top">PCM (signed or unsigned) 8 bit mono (1 channel)</td>
                <td valign="top">1. sample</td>
                <td valign="top">2. sample</td>
                <td valign="top">3. sample</td>
                <td valign="top">4. sample</td>
               </tr>
               <tr valign="top">
                <td valign="top">PCM (signed or unsigned) 8 bit stereo (2 channels)</td>
                <td valign="top">1. frame, left sample</td>
                <td valign="top">1. frame, right sample</td>
                <td valign="top">2. frame, left sample</td>
                <td valign="top">2. frame, right sample</td>
               </tr>
               <tr valign="top">
                <td valign="top">PCM (signed or unsigned) 16 bit mono (1 channel), little endian</td>
                <td valign="top">1. sample, low byte</td>
                <td valign="top">1. sample, high byte</td>
                <td valign="top">2. sample, low byte</td>
                <td valign="top">2. sample, high byte</td>
               </tr>
               <tr valign="top">
                <td valign="top">PCM (signed or unsigned) 16 bit mono (1 channel), big endian</td>
                <td valign="top">1. sample, high byte</td>
                <td valign="top">1. sample, low byte</td>
                <td valign="top">2. sample, high byte</td>
                <td valign="top">2. sample, low byte</td>
               </tr>
               <tr valign="top">
                <td valign="top">PCM (signed or unsigned) 16 bit stereo (2 channels), little endian</td>
                <td valign="top">1. frame, left sample, low byte</td>
                <td valign="top">1. frame, left sample, high byte</td>
                <td valign="top">1. frame, right sample, low byte</td>
                <td valign="top">1. frame, right sample, high byte</td>
               </tr>
               <tr valign="top">
                <td valign="top">PCM (signed or unsigned) 16 bit stereo (2 channels), big endian</td>
                <td valign="top">1. frame, left sample, high byte</td>
                <td valign="top">1. frame, left sample, low byte</td>
                <td valign="top">1. frame, right sample, high byte</td>
                <td valign="top">1. frame, right sample, low byte</td>
               </tr>
               <tr valign="top">
                <td valign="top">PCM (signed or unsigned) 32 bit mono (1 channel), big endian</td>
                <td valign="top">1. frame, 1. sample, 4. byte (bit 24-31)</td>
                <td valign="top">1. frame, 1. sample, 3. byte (bit 16-23)</td>
                <td valign="top">1. frame, 1. sample, 2. byte (bit 8-15)</td>
                <td valign="top">1. frame, 1. sample, 1. byte (bit 0-7)</td>
               </tr>
               <tr valign="top">
                <td valign="top">PCM (signed or unsigned) 32 bit mono (1 channel), little endian</td>
                <td valign="top">1. frame, 1. sample, 1. byte (bit 0-7)</td>
                <td valign="top">1. frame, 1. sample, 2. byte (bit 8-15)</td>
                <td valign="top">1. frame, 1. sample, 3. byte (bit 16-23)</td>
                <td valign="top">1. frame, 1. sample, 4. byte (bit 24-31)</td>
               </tr>
              </tbody>
             </table>
            </div><p>To understand the terms little endian, big endian, high byte and low byte, see <a href="#endianess">What is endianess / big endian / little endian?</a> See also <a href="#short_to_byte">How do I convert short (16 bit) samples to bytes to store them in a byte array?</a> and <a href="#reconstruct_samples">How can I reconstruct sample values from a byte array?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="unknown_sample_rate"></a><a name="N10EB1"></a><b>8.10.</b></td>
           <td valign="top" align="left"><p>What does "unknown sample rate" in an <tt class="classname">AudioFormat</tt> object mean?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Since 1.5.0, "unknown sample rate" is output by <tt class="function">AudioFormat.toString()</tt> if the sample rate is <tt class="constant">-1</tt> (<tt class="constant">AudioSystem.NOT_SPECIFIED</tt>). See also <a href="#sr_unspecified">Why are there <tt class="classname">AudioFormat</tt> objects with frame rate/sample rate reported as <tt class="constant">-1</tt> when I query a <tt class="classname">Mixer</tt> for its supported formats?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_conversion"></a><h3 class="title"><a name="sec_conversion"></a>9. Conversion between sample representations</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              9.1. 
              <a href="#convert_signedness">How can I convert 8 bit signed samples to 8 bit unsigned or vice versa?</a>
             </dt>
             <dt>
              9.2. 
              <a href="#short_to_byte">How do I convert short (16 bit) samples to bytes to store them in a byte array?</a>
             </dt>
             <dt>
              9.3. 
              <a href="#float_to_byte">How do I convert float or double samples to bytes to store them in a byte array?</a>
             </dt>
             <dt>
              9.4. 
              <a href="#reconstruct_samples">How can I reconstruct sample values from a byte array?</a>
             </dt>
             <dt>
              9.5. 
              <a href="#convert_channels">How can I convert between mono and stereo?</a>
             </dt>
             <dt>
              9.6. 
              <a href="#mono_mapping">How can I make a mono stream appear on one channel of a stereo stream?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="convert_signedness"></a><a name="N10ED0"></a><b>9.1.</b></td>
           <td valign="top" align="left"><p>How can I convert 8 bit signed samples to 8 bit unsigned or vice versa?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Signed to unsigned:</p><pre class="programlisting">
byte unsigned = (byte) (signed + 128);</pre><p>Unsigned to signed:</p><pre class="programlisting">
byte signed = (byte) (unsigned - 128);</pre><p>Alternativly, you can use for both conversions:</p><pre class="programlisting">
byte changed = (byte) (original ^ 0x80);</pre><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="short_to_byte"></a><a name="N10EE7"></a><b>9.2.</b></td>
           <td valign="top" align="left"><p><a name="short_to_byte.q"></a>How do I convert short (16 bit) samples to bytes to store them in a byte array?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Generally:</p><pre class="programlisting">
short sample = ...;
byte high = (byte) (sample &gt;&gt; 8) &amp; 0xFF;
byte low = (byte) (sample &amp; 0xFF);</pre><p>If you want to store them in an array in big endian byte order:</p><pre class="programlisting">
short sample = ...;
byte[] buffer = ...;
int offset = ...;
// high byte
buffer[offset + 0] = (byte) (sample &gt;&gt; 8) &amp; 0xFF;
// low byte
buffer[offset + 1] = (byte) (sample &amp; 0xFF);</pre><p>If you want to store them in an array in little endian byte order:</p><pre class="programlisting">
short sample = ...;
byte[] buffer = ...;
int offset = ...;
// low byte
buffer[offset + 0] = (byte) (sample &amp; 0xFF);
// high byte
buffer[offset + 1] = (byte) (sample &gt;&gt; 8) &amp; 0xFF;</pre><p>Note that in Java arithmetic operations on integers are always done with int's (32 bit) or long's (64 bit). Using arithmetic operations on byte or short leads to extending them to int. Therefore, storing 16 bit values in int (32 bit) variables uses less processing time if you want to do calculations like the above. On the other hand, it doubles memory usage.</p><p>Optimized code to do these conversions can be found in the class <a href="http://tritonus.cvs.sourceforge.net/tritonus/tritonus/src/org/tritonus/share/sampled/TConversionTool.java?view=markup" target="_top"><tt class="classname">TConversionTool</tt></a> of <a href="http://www.tritonus.org/" target="_top">Tritonus</a>. See also <a href="#samples_organized">How are samples organized in a byte array/stream?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="float_to_byte"></a><a name="N10F0E"></a><b>9.3.</b></td>
           <td valign="top" align="left"><p>How do I convert float or double samples to bytes to store them in a byte array?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You can do this with the following steps:</p>
            <div class="orderedlist">
             <ol type="1">
              <li><p>Make sure the values of the samples are normalized to a range <tt class="constant">-1.0</tt> to <tt class="constant">+1.0</tt></p></li>
              <li><p>Multiply the values with <tt class="constant">32767.0</tt></p></li>
              <li><p>Convert the values to int, preferrably by using <tt class="function">Math.round()</tt></p></li>
              <li><p>Proceed as described in <a href="#short_to_byte">How do I convert short (16 bit) samples to bytes to store them in a byte array?</a></p></li>
             </ol>
            </div><p>Code example for float samples:</p><pre class="programlisting">
// the sample to process
float fSample = ...;
// saturation
fSample = Math.min(1.0F, Math.max(-1.0F, fSample);
// scaling and conversion to integer
int nSample = Math.round(fSample * 32767.0F);
byte high = (byte) (nSample &gt;&gt; 8) &amp; 0xFF;
byte low = (byte) (nSample &amp; 0xFF);</pre><p>Code example for double samples:</p><pre class="programlisting">
// the sample to process
double dSample = ...;
// saturation
dSample = Math.min(1.0, Math.max(-1.0, dSample);
// scaling and conversion to integer
int nSample = (int) Math.round(dSample * 32767.0);
byte high = (byte) (nSample &gt;&gt; 8) &amp; 0xFF;
byte low = (byte) (nSample &amp; 0xFF);</pre><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="reconstruct_samples"></a><a name="N10F3F"></a><b>9.4.</b></td>
           <td valign="top" align="left"><p><a name="reconstruct_samples.q"></a>How can I reconstruct sample values from a byte array?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The code below assumes that buffer is an array of bytes and offset an int, used as a an index into the buffer. It further assumes that the sample values are signed for sample sizes greater than 8 bit.</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th align="center" valign="top">sample size</th>
                <th align="center" valign="top">data type</th>
                <th align="center" valign="top">endianess or signedness</th>
                <th align="center" valign="top">code</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td rowspan="6" align="center" valign="top">8 bit</td>
                <td rowspan="2" align="center" valign="top">short (upper 8 bit contain the value, lower 8 bit are filled with zero)</td>
                <td align="center" valign="top">signed</td>
                <td align="center" valign="top"> <pre class="programlisting">
short sample = (short)
(buffer[offset] &lt;&lt; 8);</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">unsigned</td>
                <td align="center" valign="top"> <pre class="programlisting">
short sample = (short)
( (buffer[offset] ^ 0x80 ) &lt;&lt; 8);</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="2" align="center" valign="top">float (normalized to the range [-1.0 .. +1.0])</td>
                <td align="center" valign="top">signed</td>
                <td align="center" valign="top"> <pre class="programlisting">
float sample =
buffer[offset] / 128.0F;</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">unsigned</td>
                <td align="center" valign="top"> <pre class="programlisting">
float sample =
( (buffer[offset] &amp; 0xFF) - 128)
/ 128.0F;</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="2" align="center" valign="top">double (normalized to the range [-1.0 .. +1.0])</td>
                <td align="center" valign="top">signed</td>
                <td align="center" valign="top"> <pre class="programlisting">
double sample =
buffer[offset] / 128.0;</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">unsigned</td>
                <td align="center" valign="top"> <pre class="programlisting">
double sample =
( (buffer[offset] &amp; 0xFF) - 128)
/ 128.0;</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="8" align="center" valign="top">16 bit</td>
                <td rowspan="2" align="center" valign="top">short (all bits used)</td>
                <td align="center" valign="top">little</td>
                <td align="center" valign="top"> <pre class="programlisting">
short sample = (short)
(  (buffer[offset + 0] &amp; 0xFF)
 | (buffer[offset + 1] &lt;&lt; 8)  );</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">big</td>
                <td align="center" valign="top"> <pre class="programlisting">
short sample = (short)
(  (buffer[offset + 0] &lt;&lt; 8)
 | (buffer[offset + 1] &amp; 0xFF) );</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="2" align="center" valign="top">int (lower 16 bit contain the value, upper 16 bit are sign extended)</td>
                <td align="center" valign="top">little</td>
                <td align="center" valign="top"> <pre class="programlisting">
int sample =
  (buffer[offset + 0] &amp; 0xFF)
| (buffer[offset + 1] &lt;&lt; 8);</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">big</td>
                <td align="center" valign="top"> <pre class="programlisting">
int sample =
  (buffer[offset + 0] &lt;&lt; 8)
| (buffer[offset + 1] &amp; 0xFF);</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="2" align="center" valign="top">float (normalized to the range [-1.0 .. +1.0])</td>
                <td align="center" valign="top">little</td>
                <td align="center" valign="top"> <pre class="programlisting">
float sample =
(  (buffer[offset + 0] &amp; 0xFF)
 | (buffer[offset + 1] &lt;&lt; 8) )
/ 32768.0F;</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">big</td>
                <td align="center" valign="top"> <pre class="programlisting">
float sample =
(  (buffer[offset + 0] &lt;&lt; 8)
 | (buffer[offset + 1] &amp; 0xFF) )
/ 32768.0F;</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="2" align="center" valign="top">double (normalized to the range [-1.0 .. +1.0])</td>
                <td align="center" valign="top">little</td>
                <td align="center" valign="top"> <pre class="programlisting">
double sample =
(  (buffer[offset + 0] &amp; 0xFF)
 | (buffer[offset + 1] &lt;&lt; 8) )
/ 32768.0;</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">big</td>
                <td align="center" valign="top"> <pre class="programlisting">
double sample =
(  (buffer[offset + 0] &lt;&lt; 8)
 | (buffer[offset + 1] &amp; 0xFF) )
/ 32768.0;</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="6" align="center" valign="top">24 bit</td>
                <td rowspan="2" align="center" valign="top">int (lower 24 bit contain the value, upper 8 bit are sign extended)</td>
                <td align="center" valign="top">little</td>
                <td align="center" valign="top"> <pre class="programlisting">
int sample =
   (buffer[offset + 0] &amp; 0xFF)
| ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 8)
|  (buffer[offset + 2] &lt;&lt; 16);</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">big</td>
                <td align="center" valign="top"> <pre class="programlisting">
int sample =
   (buffer[offset + 0] &lt;&lt; 16)
| ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 8)
|  (buffer[offset + 2] &amp; 0xFF);</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="2" align="center" valign="top">float (normalized to the range [-1.0 .. +1.0])</td>
                <td align="center" valign="top">little</td>
                <td align="center" valign="top"> <pre class="programlisting">
float sample =
(   (buffer[offset + 0] &amp; 0xFF)
 | ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 8)
 |  (buffer[offset + 2] &lt;&lt; 16) )
/ 8388606.0F;</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">big</td>
                <td align="center" valign="top"> <pre class="programlisting">
float sample =
(   (buffer[offset + 0] &lt;&lt; 16)
 | ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 8)
 |  (buffer[offset + 2] &amp; 0xFF) )
/ 8388606.0F;</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="2" align="center" valign="top">double (normalized to the range [-1.0 .. +1.0])</td>
                <td align="center" valign="top">little</td>
                <td align="center" valign="top"> <pre class="programlisting">
double sample =
(   (buffer[offset + 0] &amp; 0xFF)
 | ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 8)
 |  (buffer[offset + 2] &lt;&lt; 16) )
/ 8388606.0;</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">big</td>
                <td align="center" valign="top"> <pre class="programlisting">
double sample =
(   (buffer[offset + 0] &lt;&lt; 16)
 | ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 8)
 |  (buffer[offset + 2] &amp; 0xFF) )
/ 8388606.0;</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="6" align="center" valign="top">32 bit</td>
                <td rowspan="2" align="center" valign="top">int (all bits used)</td>
                <td align="center" valign="top">little</td>
                <td align="center" valign="top"> <pre class="programlisting">
int sample =
   (buffer[offset + 0] &amp; 0xFF)
| ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 8)
| ((buffer[offset + 2] &amp; 0xFF) &lt;&lt; 16)
|  (buffer[offset + 3] &lt;&lt; 24);</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">big</td>
                <td align="center" valign="top"> <pre class="programlisting">
int sample =
   (buffer[offset + 0] &lt;&lt; 24)
| ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 16)
| ((buffer[offset + 2] &amp; 0xFF) &lt;&lt; 8)
|  (buffer[offset + 3] &amp; 0xFF);</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="2" align="center" valign="top">float (normalized to the range [-1.0 .. +1.0])</td>
                <td align="center" valign="top">little</td>
                <td align="center" valign="top"> <pre class="programlisting">
float sample =
(   (buffer[offset + 0] &amp; 0xFF)
 | ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 8)
 | ((buffer[offset + 2] &amp; 0xFF) &lt;&lt; 16)
 |  (buffer[offset + 3] &lt;&lt; 24) )
/ 2147483648.0F;</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">big</td>
                <td align="center" valign="top"> <pre class="programlisting">
float sample =
(   (buffer[offset + 0] &lt;&lt; 24)
 | ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 16)
 | ((buffer[offset + 2] &amp; 0xFF) &lt;&lt; 8)
 |  (buffer[offset + 3] &amp; 0xFF) )
/ 2147483648.0F;</pre> </td>
               </tr>
               <tr valign="top">
                <td rowspan="2" align="center" valign="top">double (normalized to the range [-1.0 .. +1.0])</td>
                <td align="center" valign="top">little</td>
                <td align="center" valign="top"> <pre class="programlisting">
double sample =
(   (buffer[offset + 0] &amp; 0xFF)
 | ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 8)
 | ((buffer[offset + 2] &amp; 0xFF) &lt;&lt; 16)
 |  (buffer[offset + 3] &lt;&lt; 24) )
/ 2147483648.0;</pre> </td>
               </tr>
               <tr valign="top">
                <td align="center" valign="top">big</td>
                <td align="center" valign="top"> <pre class="programlisting">
double sample =
(   (buffer[offset + 0] &lt;&lt; 24)
 | ((buffer[offset + 1] &amp; 0xFF) &lt;&lt; 16)
 | ((buffer[offset + 2] &amp; 0xFF) &lt;&lt; 8)
 |  (buffer[offset + 3] &amp; 0xFF) )
/ 2147483648.0;</pre> </td>
               </tr>
              </tbody>
             </table>
            </div><p>Optimized code to do these conversions can be found in the class <a href="http://tritonus.cvs.sourceforge.net/tritonus/tritonus/src/org/tritonus/share/sampled/TConversionTool.java?view=markup" target="_top"><tt class="classname">TConversionTool</tt></a> of <a href="http://www.tritonus.org/" target="_top">Tritonus</a>. See also <a href="#samples_organized">How are samples organized in a byte array/stream?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="convert_channels"></a><a name="N1109F"></a><b>9.5.</b></td>
           <td valign="top" align="left"><p><a name="convert_channels.q"></a>How can I convert between mono and stereo?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is possible with the PCM2PCM converter of Tritonus. It is available as part of the "Tritonus Miscellaneous" package. See <a href="http://www.tritonus.org/plugins.html" target="_top">Tritonus Plug-ins</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mono_mapping"></a><a name="N110AC"></a><b>9.6.</b></td>
           <td valign="top" align="left"><p><a name="mono_mapping.q"></a>How can I make a mono stream appear on one channel of a stereo stream?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You can use a technique like shown below. The example assumes that the data is 8 bit unsigned.</p><pre class="programlisting">
// incoming: mono input stream
// outgoing: stereo output stream
void monoToSingleSideStereo(byte[] incoming, byte[] outgoing)
{
    int nSignalOffset;
    int nSilenceOffset;
    // this is for unsigned data. For signed data, use the value 0.
    int nSilenceValue = -128;

    if (copyToLeftChannel)
    {
        nSignalOffset = 0;
        nSilenceOffset = 1;
    }
    else // signal to the right channel
    {
        nSignalOffset = 1;
        nSilenceOffset = 0;
    }
    for (int i = 0; i &lt; incoming.length; i++)
    {
        outgoing[(i * 2) + nSignalOffset] = incoming[i];
        outgoing[(i * 2) + nSilenceOffset] = nSilenceValue;
    }
} </pre><p>Alternativly, you can use a <tt class="constant">PAN</tt> control on a <tt class="classname">SourceDataLine</tt> while doing playback. Note that this only works with the "Java Sound Audio Engine". With the "Direct Audio Device" mixers, you have to use a workaround: convert the mono stream to a stereo stream (see <a href="#convert_channels">How can I convert between mono and stereo?</a>), open the line in stereo and use a <tt class="constant">BALANCE</tt> control. See also <a href="#dad_mono_lines">Why are there no mono lines with the "Direct Audio Devices" mixers on Linux?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_audioinputstream"></a><h3 class="title"><a name="sec_audioinputstream"></a>10. AudioInputStreams and Byte Arrays</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              10.1. 
              <a href="#file_bytearray">How can I read an audio file and store the audio data in a byte array?</a>
             </dt>
             <dt>
              10.2. 
              <a href="#bytearray_file">How can I write audio data from a byte array to an audio file?</a>
             </dt>
             <dt>
              10.3. 
              <a href="#calculate_skip">How can I calculate the number of bytes to skip from the length in seconds?</a>
             </dt>
             <dt>
              10.4. 
              <a href="#rewind_ais">How do I rewind an AudioInputStream?</a>
             </dt>
             <dt>
              10.5. 
              <a href="#skip_back_ais">How do I skip backwards on an AudioInputStream?</a>
             </dt>
             <dt>
              10.6. 
              <a href="#ais_length_unknown">How can I implement a real-time AudioInputStream, though I cannot give a length for it, as it is not known in advance?</a>
             </dt>
             <dt>
              10.7. 
              <a href="#mix_ais">How can I mix two (or more) AudioInputStream instances to a resulting AudioInputStream?</a>
             </dt>
             <dt>
              10.8. 
              <a href="#ais_section">How can I create an AudioInputStream that represents a portion of another AudioInputStream?</a>
             </dt>
             <dt>
              10.9. 
              <a href="#ais_unknown_length">Why does AudioInputStream.getFrameLength() return -1?</a>
             </dt>
             <dt>
              10.10. 
              <a href="#audiosystem_getAIS_vs_new_AIS">What is the difference between AudioSystem.getAudioInputStream(InputStream) and new AudioInputStream(InputStream, AudioFormat, long)?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="file_bytearray"></a><a name="N110D1"></a><b>10.1.</b></td>
           <td valign="top" align="left"><p><a name="file_bytearray.q"></a>How can I read an audio file and store the audio data in a byte array?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Create a <tt class="classname">ByteArrayOutputStream</tt> object. Then, in a loop, read form the AudioInputStream and write the data read from it to the <tt class="classname">ByteArrayOutputStream</tt>. Once all data is processed, call <tt class="function">ByteArrayOutputStream.toByteArray()</tt> to get a byte array with all the data. See <a class="olink" href="examples/AudioDataBuffer.html">Buffering of audio data in memory</a> for a code example.</p><p>As an alternative, you can do the following:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Calculate the required size of the byte array from the number of frames and the frame size (see <a href="#file_length">How can I determine the length or the duration of an audio file?</a>).</p></li>
              <li><p>Create a byte array of the calculated size.</p></li>
              <li><p>Call <tt class="function">AudioInputStream.read()</tt> with this array. Note that while this typically reads the whole file in one call, this is not quaranteed. If, for some reason, reading the whole content of the <tt class="classname">AudioInputStream</tt> does not succeed, only part of the data may be written to the byte array. Therefore, you have to compare the return value of <tt class="function">read()</tt> against the length of the byte array. If some part is missing, you have to call <tt class="function">read()</tt> again with an appropriate offset.</p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="bytearray_file"></a><a name="N11109"></a><b>10.2.</b></td>
           <td valign="top" align="left"><p><a name="bytearray_file.q"></a>How can I write audio data from a byte array to an audio file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Create a <tt class="classname">ByteArrayInputStream</tt> object from the byte array, create an <tt class="classname">AudioInputStream</tt> from it, then call <tt class="function">AudioSystem.write()</tt>. See <a class="olink" href="examples/AudioDataBuffer.html">Buffering of audio data in memory</a> for a code example. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="calculate_skip"></a><a name="N11120"></a><b>10.3.</b></td>
           <td valign="top" align="left"><p>How can I calculate the number of bytes to skip from the length in seconds?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Use one of the following formulas: </p>
            <div class="blockquote">
             <blockquote class="blockquote">
              <p>bytes = seconds * sample rate * channels * (bits per sample / 8)</p>
             </blockquote>
            </div> or 
            <div class="blockquote">
             <blockquote class="blockquote">
              <p>bytes = seconds * sample rate * frame size</p>
             </blockquote>
            </div> You can get the sample rate, number of channels, bits per sample and frame size from an <tt class="classname">AudioFormat</tt> object. (Matthias)<p></p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="rewind_ais"></a><a name="N11133"></a><b>10.4.</b></td>
           <td valign="top" align="left"><p><a name="rewind_ais.q"></a>How do I rewind an <tt class="classname">AudioInputStream</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>See the example <a class="olink" href="examples/RewindingAudioPlayer.html">Playing an audio file multiple times</a>. Note that the way the JavaSoundDemo does it is not recommended, because it relies on implementation specific behaviour. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="skip_back_ais"></a><a name="N11143"></a><b>10.5.</b></td>
           <td valign="top" align="left"><p><a name="skip_back_ais.q"></a>How do I skip backwards on an <tt class="classname">AudioInputStream</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>In general, there is no clean way besides buffering the whole content of the <tt class="classname">AudioInputStream</tt> as done in the example <a class="olink" href="examples/RewindingAudioPlayer.html">Playing an audio file multiple times</a>. There is one possibility: if the <tt class="classname">AudioInputStream</tt> is created from a <tt class="classname">FileInputStream</tt>, you can use <tt class="function">AudioInputStream.skip()</tt> with a negative skipp amount. This works because the <tt class="classname">AudioInputStream</tt> implementation just passes the <tt class="function">skip()</tt> call to its underlying stream and the <tt class="classname">FileInputStream</tt> implementation is able to handle random accesses. Note, however, that this relies on unspecified, implementation specific behaviour of the Sun JDK. Therefore, this approach should be used with care. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="ais_length_unknown"></a><a name="N1116A"></a><b>10.6.</b></td>
           <td valign="top" align="left"><p><a name="ais_length_unknown.q"></a>How can I implement a real-time <tt class="classname">AudioInputStream</tt>, though I cannot give a length for it, as it is not known in advance?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You should use <tt class="constant">AudioSystem.NOT_SPECIFIED</tt> as length. This approach seems logical to me and it works fine in my program. (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mix_ais"></a><a name="N11179"></a><b>10.7.</b></td>
           <td valign="top" align="left"><p><a name="mix_ais.q"></a>How can I mix two (or more) <tt class="classname">AudioInputStream</tt> instances to a resulting <tt class="classname">AudioInputStream</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There are no special methods in the Java Sound API to do this. However, mixing is a trivial signal processing task, it can be accomplished with plain Java code. Have a look at <a class="olink" href="examples/AudioConcat.html">Concatenating or mixing audio files</a>. See also <a href="#mixing">How can I do mixing of audio streams?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="ais_section"></a><a name="N11190"></a><b>10.8.</b></td>
           <td valign="top" align="left"><p><a name="ais_section.q"></a>How can I create an <tt class="classname">AudioInputStream</tt> that represents a portion of another <tt class="classname">AudioInputStream</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>To create a derived <tt class="classname">AudioInputStream</tt> that starts at frame <tt class="varname">start</tt> of the original <tt class="classname">AudioInputStream</tt> and has a length of <tt class="varname">length</tt> frames, you can use the folloing code:</p><pre class="programlisting">
AudioInputStream originalAIS = ...
int start = ...; // in frames
int length = ...; // in frames

int frameSize = originalAIS.getFormat().getFrameSize();
originalAIS.skip(start * frameSize);
AudioInputStream derivedAIS = new AudioInputStream(originalAIS,
                                     originalAIS.getFormat(), length);</pre><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="ais_unknown_length"></a><a name="N111B0"></a><b>10.9.</b></td>
           <td valign="top" align="left"><p><a name="ais_unknown_length.q"></a>Why does <tt class="function">AudioInputStream.getFrameLength()</tt> return <tt class="constant">-1</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>A length of <tt class="constant">-1</tt> (<tt class="constant">AudioSystem.NOT_SPECIFIED</tt>) means that the length of the stream is unknown. This typically happens in two situations:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>If an <tt class="classname">AudioInputStream</tt> obtains its data from a <tt class="classname">TargetDataLine</tt>, the amount of data (and therefore, the length of the stream) is determined by the length of the recording. Obviously, this cannot be known at the time the <tt class="classname">AudioInputStream</tt> instance is created.</p></li>
              <li><p>If audio data is encoded to or decoded from a compression format like <a href="#sec_vorbis">Ogg Vorbis</a> or <a href="#sec_mp3">mp3</a>, where the length of the encoded data is not a simple fraction of the length of the unencoded data. In this case, it is not possible for the codec to calculate the length of the converted stream. So it has to state that the lengt is unknown.</p></li>
             </ul>
            </div><p>To write portable programs, you should always expect that the length of an <tt class="classname">AudioInputStream</tt> may be <tt class="constant">-1</tt>. For instance, if you are calculating a buffer size from the stream length, you should handle this case separately. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="audiosystem_getAIS_vs_new_AIS"></a><a name="N111E6"></a><b>10.10.</b></td>
           <td valign="top" align="left"><p><a name="audiosystem_getAIS_vs_new_AIS.q"></a>What is the difference between <tt class="function">AudioSystem.getAudioInputStream(InputStream)</tt> and new <tt class="function">AudioInputStream(InputStream, AudioFormat, long)</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p><tt class="function">AudioSystem.getAudioInputStream(InputStream)</tt> "intelligently" parses the header of the file in <tt class="classname">InputStream</tt> and tries to retrieve the format of it. This fails for "raw" audio files or files that aren't recognized by Java Sound. The <tt class="classname">AudioInputStream</tt> returned by this method is at the position where the actual audio data starts, the file header is skipped.</p><p><tt class="function">AudioInputStream(InputStream, AudioFormat, long)</tt> is a "stupid" constructor that just returns an <tt class="classname">AudioInputStream</tt> with the <tt class="classname">InputStream</tt> used "as is". No attempt is made to verify the format with the given <tt class="classname">AudioFormat</tt> instance - if you pass a wrong <tt class="classname">AudioFormat</tt>, the data in <tt class="classname">InputStream</tt> is interpreted in a wrong way.</p><p>Using the second way on an <tt class="classname">InputStream</tt> that is obtained from an audio file would give an <tt class="classname">AudioInputStream</tt> where the "audio data" starts with the file header. Often, the difference won't be noticable, because headers are typically short (typically 44 bytes for <tt class="filename">.wav</tt> files, 24 bytes for <tt class="filename">.au</tt> files). However, there is no quarantee that the header is not much longer in some audio files, and that it will be audible as clicks or noise.</p><p>An exception are audio files without a header. These are typically "streamable" formats, e.g. <a href="#sec_mp3">mp3</a> and <a href="#sec_gsm">GSM 06.10</a>. There, the data is organized in frames, and each frame has a very basic description of the audio data. So for these headerless formats, the two ways to get an <tt class="classname">AudioInputStream</tt> are equivalent. (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_processing"></a><h3 class="title"><a name="sec_processing"></a>11. Data Processing (Amplifying, Mixing, Signal Processing)</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              11.1. 
              <a href="#processing_alaw">How can I do some processing on an A-law stream (like amplifing it)?</a>
             </dt>
             <dt>
              11.2. 
              <a href="#detect_level">How can I detect the level of sound while I am recording it?</a>
             </dt>
             <dt>
              11.3. 
              <a href="#convert_sample_rate">How can I do sample rate conversion?</a>
             </dt>
             <dt>
              11.4. 
              <a href="#detect_frequency">How can I detect the frequency (or pitch) of sound data?</a>
             </dt>
             <dt>
              11.5. 
              <a href="#fft1">How can I do equalizing / noise reduction / fft / echo cancellation / ...?</a>
             </dt>
             <dt>
              11.6. 
              <a href="#silence_supression">How can I do silence supression or silence detection?</a>
             </dt>
             <dt>
              11.7. 
              <a href="#mixing">How can I do mixing of audio streams?</a>
             </dt>
             <dt>
              11.8. 
              <a href="#float_vs_double">Should I use float or double for signal processing?</a>
             </dt>
             <dt>
              11.9. 
              <a href="#complex_numbers">How can I do computations with complex numbers in Java?</a>
             </dt>
             <dt>
              11.10. 
              <a href="#pitch_shifting">How can I change the pitch (frequency) of audio data without changing the duration?</a>
             </dt>
             <dt>
              11.11. 
              <a href="#time_streching">How can I change the duration of audio data without changing the pitch (frequency)?</a>
             </dt>
             <dt>
              11.12. 
              <a href="#reverb">How can I use reverbation?</a>
             </dt>
             <dt>
              11.13. 
              <a href="#max_volume">How can I find out the maximum volume of a sound file?</a>
             </dt>
             <dt>
              11.14. 
              <a href="#normalize_volume">How can I normalize the volume of sound?</a>
             </dt>
             <dt>
              11.15. 
              <a href="#calculate_power">How can I calculate the power of a signal?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="processing_alaw"></a><a name="N11237"></a><b>11.1.</b></td>
           <td valign="top" align="left"><p>How can I do some processing on an A-law stream (like amplifing it)?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>It is much easier to change gain with linear encoding (PCM). I would strongly suggest that - especially when you have the data in linear format at first. You'd have to convert it back to A-law after processing. (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="detect_level"></a><a name="N1123F"></a><b>11.2.</b></td>
           <td valign="top" align="left"><p>How can I detect the level of sound while I am recording it?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>First of all, you should have the data in PCM format (preferable in signed PCM). Then you can look at the samples to detect the amplitude (level). Some statistics are suitable, too, like taking the average of the absolute values or RMS. (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="convert_sample_rate"></a><a name="N11247"></a><b>11.3.</b></td>
           <td valign="top" align="left"><p><a name="convert_sample_rate.q"></a>How can I do sample rate conversion?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Currently, this is not supported by the Sun JDK (see bug <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4916960" target="_top">#4916960</a>). <a href="http://www.tritonus.org/" target="_top">Tritonus</a> has a sample rate converter that is available as a plug-in for other Java Sound implementations, too. See the 'Tritonus Miscellaneous' package at <a href="http://www.tritonus.org/plugins.html" target="_top">Tritonus Plug-ins</a>. See <a class="olink" href="examples/SampleRateConverter.html">Converting the sample rate of audio files</a> for a code example. Also, <a href="http://java.sun.com/products/java-media/jmf/" target="_top">JMF</a> supports sample rate conversion. See also <a href="#convert_encoded_to_encoded">How can I convert between two encoded formats directly (e.g. from mp3 to A-law)?</a> and <a class="olink" href="faq_tritonus.html#which_src_algorithm">Q:&nbsp;16</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="detect_frequency"></a><a name="N1126C"></a><b>11.4.</b></td>
           <td valign="top" align="left"><p>How can I detect the frequency (or pitch) of sound data?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>What you need is an algorithm called 'fast fourier transform', abbreviated 'FFT'. See also <a href="#fft1">How can I do equalizing / noise reduction / fft / echo cancellation / ...?</a> and <a class="olink" href="faq_performance.html#fft2">Q:&nbsp;2</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="fft1"></a><a name="N1127C"></a><b>11.5.</b></td>
           <td valign="top" align="left"><p><a name="fft1.q"></a>How can I do equalizing / noise reduction / fft / echo cancellation / ...?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Java Sound is an API concerned with basic sound input and output. It does not contain digital signal processing algorithms. Nevertheless, you can do this with Java; you just have to code it on your own. Craig Lindley's book (see <a class="olink" href="faq_resources.html#books">Q:&nbsp;1</a>) contains some DSP algorithm. Also, it is often easy to transform C or C++ code found on the net to Java.</p><p>You may want to have a look at the <a href="http://www.bdti.com/faq/dsp_faq.htm" target="_top">comp.dsp FAQ</a></p><p>For code that does fft, have a look at the <a href="http://www.seas.smu.edu/~cjuliano/peruna.html" target="_top">Peruna Project</a> (original website is offline, view it at the <a href="http://www.archive.org/" target="_top">Internet Archive</a>). (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="silence_supression"></a><a name="N11298"></a><b>11.6.</b></td>
           <td valign="top" align="left"><p>How can I do silence supression or silence detection?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This can be achieved with a variant of a common DSP algorith called "noise gate". A noise gate is a special form of a compressor, which belongs to the area of dynamic processing. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mixing"></a><a name="N112A0"></a><b>11.7.</b></td>
           <td valign="top" align="left"><p><a name="mixing.q"></a>How can I do mixing of audio streams?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>If you want to do playback of multiple streams, just obtain multiple instances of <tt class="classname">SourceDataLine</tt>, one for each stream to play. The data fed to the <tt class="classname">SourceDataLine</tt> instances is mixed inside the <tt class="classname">Mixer</tt> instance, either in software or in hardware. There is no way to monitor the result of the mixing, other than looping the soundcard's output line to some input line.</p><p>For mixing without playback see <a href="#mix_ais">How can I mix two (or more) <tt class="classname">AudioInputStream</tt> instances to a resulting <tt class="classname">AudioInputStream</tt>?</a></p><p>If the sources of the audio data are not <tt class="classname">AudioInputStream</tt> instances, but byte buffers, you can use the class <tt class="classname">FloatSampleBuffer</tt> of Tritonus. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="float_vs_double"></a><a name="N112BF"></a><b>11.8.</b></td>
           <td valign="top" align="left"><p>Should I use float or double for signal processing?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is a question discussed over and over again. It seems that there is no definitive answer. Which way to go depends on the circumstances and the requirements. Here are some arguments in favour of each alternative.</p><p>Advantages of using float:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>It uses half of the memory size used by double: 4 bytes instead of 8 bytes per sample. This may be an issue if lage amounts of data are stored in a floating point representation.</p></li>
              <li><p>Calculations may be faster. This depends on the processor. For Pentium-class processors, there is no performance gain by using float with the standard FPU (Floating Point Unit): Both float and double are handled using an 80 bit represention internally anyway. However, "multimedia" instructions that execute more than one operation simultaneously are only available for float.</p></li>
              <li><p>The memory bandwidth needed to transfer data from the RAM to the processor and vice versa is half of that needed for double. This is an issue in real time systems with high throuput, where the memory bandwidth is the limiting factor.</p></li>
             </ul>
            </div><p>Advantages of using double:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>There are smaller rounding errors for filter constants, so for algorithms with feedback (IIR filters), the propapility of numerical instability is lower.</p></li>
              <li><p>Some algorithms with a lot of feedback like reverb may require double.</p></li>
              <li><p>Several mathematical functions (for instance <tt class="function">sin()</tt>, <tt class="function">log()</tt>, <tt class="function">pow()</tt>) are only available with double parameters and return values. Using double throughout instead of float saves the conversions between float and double.</p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="complex_numbers"></a><a name="N112ED"></a><b>11.9.</b></td>
           <td valign="top" align="left"><p>How can I do computations with complex numbers in Java?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Here are two implementations of classes for complex numbers: <a href="http://www.daa.com.au/~james/fractals/mandel/Cmplx.java" target="_top">Cmplx.java</a>, <a href="http://hoschek.home.cern.ch/hoschek/colt/" target="_top">The Colt Distribution</a> (Open Source Libraries for High Performance Scientific and Technical Computing in Java). (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="pitch_shifting"></a><a name="N112FD"></a><b>11.10.</b></td>
           <td valign="top" align="left"><p><a name="pitch_shifting.q"></a>How can I change the pitch (frequency) of audio data without changing the duration?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is a quite complex problem called "pitch shifting". It requires advanced DSP algorithms. This is not available as part of the Java Sound API and is unlikely to ever become so. However, it is possible to do this in Java. One example is in Craig Lindley's book (see <a class="olink" href="faq_resources.html#books">Q:&nbsp;1</a>). (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="time_streching"></a><a name="N1130A"></a><b>11.11.</b></td>
           <td valign="top" align="left"><p><a name="time_streching.q"></a>How can I change the duration of audio data without changing the pitch (frequency)?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is a problem similar to pitch shifting: It requires non-trivial DSP algorithms. See <a href="http://archives.java.sun.com/cgi-bin/wa?A2=ind0412&amp;L=javasound-interest&amp;F=&amp;S=&amp;P=4794" target="_top">Marvin's mail</a> and <a href="http://archives.java.sun.com/cgi-bin/wa?A2=ind0412&amp;L=javasound-interest&amp;F=&amp;S=&amp;P=5149" target="_top">Simon's mail</a> for some links. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="reverb"></a><a name="N1131B"></a><b>11.12.</b></td>
           <td valign="top" align="left"><p>How can I use reverbation?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The "Java Sound Audio Engine" (see <a href="#mixers">What are all these mixers?</a>) has an implementation of a Reverb control (it is implemented as <tt class="classname">Control</tt> of the <tt class="classname">Mixer</tt>. Note that <tt class="classname">Mixer</tt> extends <tt class="classname">Line</tt>, so you can get controls from a <tt class="classname">Mixer</tt>, too). However, it seems that it is not working.</p><p>In general, it is recommended to implement reverb yourself. The reason is that the availability of reverb as a control of a <tt class="classname">Mixer</tt> as an implementation-specific property of certain <tt class="classname">Mixer</tt> implementations. The "Java Sound Audio Engine" supports reverb, all other mixers don't. So relying on reverb in the mixer makes your program not portable. In the upcoming JDK 1.5.0, the "Java Sound Audio Engine" is no longer the default mixer, the default are now the "Direct Audio Device" mixers. There are many good reasons to use the "Direct Audio Device" mixers instead of the "Java Sound Audio Engine", including low latency and support for multiple soundcards. But if you need the reverberation, you are hooked to the "Java Sound Audio Engine". And one day, the "Java Sound Audio Engine" may disappear completely. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="max_volume"></a><a name="N1133E"></a><b>11.13.</b></td>
           <td valign="top" align="left"><p>How can I find out the maximum volume of a sound file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>In a loop, go through the whole file and examine each sample. The maximum volume is the maximum of the absolute values of all samples. For getting the sample values, see <a href="#samples_organized">How are samples organized in a byte array/stream?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="normalize_volume"></a><a name="N1134A"></a><b>11.14.</b></td>
           <td valign="top" align="left"><p>How can I normalize the volume of sound?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>One way to do it is to scan the whole wave to find it's max (and min, or abs() it) valued sample, get the ratio of this to the available max and scale up the whole wave.</p><p>An alternative that might work in practice is to use a compressor - i.e. apply a scaling algorithm that boosts the lower-level parts of the signal. This has the perceived effect of making everything sound louder - it's often done to TV ads.</p><p>The latter (compression) is the preferrable approach. Just looking for the maximum and minimum sample may result in not getting a silent tune louder, because it may have a single peak to the maximum. It's better to calculate the average level of the whole piece and use this value in relation to the possible maximum level to predict a compression ratio. Note that this usage of the term "compression" refers to reducing the dynamic range of music. It has nothing to do with the compression of MP3, which means reducing the storage size or bitrate. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="calculate_power"></a><a name="N11356"></a><b>11.15.</b></td>
           <td valign="top" align="left"><p><a name="calculate_power.q"></a>How can I calculate the power of a signal?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You have to calculate the root-mean-square average of continuous samples. For four samples, the formula looks like this:</p>
            <div class="blockquote">
             <blockquote class="blockquote">
              <p>rms = sqrt( (x0^2 + x1^2 + x2^2 + x3^2) / 4)</p>
             </blockquote>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_compression"></a><h3 class="title"><a name="sec_compression"></a>12. Compression and Encodings</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              12.1. 
              <a href="#sec_vorbis">Ogg Vorbis</a>
             </dt>
             <dd>
              <dl>
               <dt>
                12.1.1. 
                <a href="#what_is_vorbis">What is Ogg Vorbis?</a>
               </dt>
               <dt>
                12.1.2. 
                <a href="#decode_ogg">How can I play back Ogg Vorbis files?</a>
               </dt>
               <dt>
                12.1.3. 
                <a href="#encode_ogg">How can I encode Ogg Vorbis files?</a>
               </dt>
               <dt>
                12.1.4. 
                <a href="#vorbis_in_jdk">Who should we lobby to get Ogg Vorbis support in the Sun JRE?</a>
               </dt>
               <dt>
                12.1.5. 
                <a href="#vorbis_duration">How can I get the duration of an Ogg Vorbis file?</a>
               </dt>
              </dl>
             </dd>
             <dt>
              12.2. 
              <a href="#sec_mp3">mp3</a>
             </dt>
             <dd>
              <dl>
               <dt>
                12.2.1. 
                <a href="#decode_mp3">How can I play back mp3 files?</a>
               </dt>
               <dt>
                12.2.2. 
                <a href="#mp3_in_jre">Why is there no mp3 decoder in the Sun JRE/JDK?</a>
               </dt>
               <dt>
                12.2.3. 
                <a href="#mp3_legal">What is the legal state of the JLayer mp3 decoder?</a>
               </dt>
               <dt>
                12.2.4. 
                <a href="#decoder_differences">What are the differences between the JLayer mp3 decoder plug-in and the Sun mp3 decoder plug-in?</a>
               </dt>
               <dt>
                12.2.5. 
                <a href="#encode_mp3">How can I encode mp3 files?</a>
               </dt>
               <dt>
                12.2.6. 
                <a href="#pure_java_mp3_encoder">Is there a mp3 encoder implemented in pure java?</a>
               </dt>
               <dt>
                12.2.7. 
                <a href="#mp3_encoder_input_formats">Which input formats can I use for the mp3 encoder?</a>
               </dt>
               <dt>
                12.2.8. 
                <a href="#mp3_encoder_on_mac">Is mp3 encoding possible on Mac OS?</a>
               </dt>
               <dt>
                12.2.9. 
                <a href="#mp3_problems">Why do I get an UnsupportedAudioFileException when trying to play a mp3 file?</a>
               </dt>
               <dt>
                12.2.10. 
                <a href="#detect_mp3_length">How can I get the length of an mp3 stream?</a>
               </dt>
              </dl>
             </dd>
             <dt>
              12.3. 
              <a href="#sec_gsm">GSM 06.10</a>
             </dt>
             <dd>
              <dl>
               <dt>
                12.3.1. 
                <a href="#gsm">Is there support for GSM?</a>
               </dt>
               <dt>
                12.3.2. 
                <a href="#gsm_codec_formats">Why does the GSM codec refuses to encode from/decode to the format I want?</a>
               </dt>
               <dt>
                12.3.3. 
                <a href="#gsm_in_wav">How can I read a .wav file with GSM data or store GSM-encoded data in a .wav file?</a>
               </dt>
               <dt>
                12.3.4. 
                <a href="#gsm_with_byte_arrays">I want to convert to/from GSM using the Tritonus plug-in. However, I do not work with files or streams. Rather, I want to convert byte[] arrays.</a>
               </dt>
               <dt>
                12.3.5. 
                <a href="#gsm_from_bits">How can I decode GSM from frames of 260 bit?</a>
               </dt>
               <dt>
                12.3.6. 
                <a href="#calculate_gsm_duration">How can I calculate the duration of a GSM file?</a>
               </dt>
               <dt>
                12.3.7. 
                <a href="#native_gsm_codecs">Are there native implementations of codecs that are compatible with the framing format used by the Java Sound GSM codec?</a>
               </dt>
              </dl>
             </dd>
             <dt>
              12.4. 
              <a href="#sec_comp_xlaw">A-law and &#x3bc;-law</a>
             </dt>
             <dd>
              <dl>
               <dt>
                12.4.1. 
                <a href="#alaw_ulaw">What are A-law and &#x3bc;-law?</a>
               </dt>
               <dt>
                12.4.2. 
                <a href="#convert_to_ulaw">How can I convert a PCM encoded byte[] to a &#x3bc;-law byte[]?</a>
               </dt>
              </dl>
             </dd>
             <dt>
              12.5. 
              <a href="#sec_comp_speex">Speex</a>
             </dt>
             <dd>
              <dl>
               <dt>
                12.5.1. 
                <a href="#what_is_speex">What is Speex?</a>
               </dt>
               <dt>
                12.5.2. 
                <a href="#support_for_speex">Is there support for Speex?</a>
               </dt>
               <dt>
                12.5.3. 
                <a href="#jspeex_usage">How do I use JSpeex?</a>
               </dt>
               <dt>
                12.5.4. 
                <a href="#speex_duration">How can I get the duration of a Speex file?</a>
               </dt>
              </dl>
             </dd>
             <dt>
              12.6. 
              <a href="#sec_comp_misc">Miscellaneous</a>
             </dt>
             <dd>
              <dl>
               <dt>
                12.6.1. 
                <a href="#adpcm">Is there support for ADPCM (a.k.a. G723) in Java Sound?</a>
               </dt>
               <dt>
                12.6.2. 
                <a href="#wma">Is there support for WMA and ASF in Java Sound?</a>
               </dt>
               <dt>
                12.6.3. 
                <a href="#convert_encoded_to_encoded">How can I convert between two encoded formats directly (e.g. from mp3 to A-law)?</a>
               </dt>
               <dt>
                12.6.4. 
                <a href="#compression_schemas">What compression schemas can I use?</a>
               </dt>
               <dt>
                12.6.5. 
                <a href="#encoding_constr_workaround">How can I get Encoding instances for GSM and mp3 with JDKs older than 1.5.0?</a>
               </dt>
               <dt>
                12.6.6. 
                <a href="#realaudio">Is there support for RealAudio / RealMedia (.ra / .rm files)?</a>
               </dt>
               <dt>
                12.6.7. 
                <a href="#new_format_support">How can I get support for a new encoding?</a>
               </dt>
              </dl>
             </dd>
            </dl></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_vorbis"></a><h4 class="title"><a name="sec_vorbis"></a>12.1. Ogg Vorbis</h4></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              12.1.1. 
              <a href="#what_is_vorbis">What is Ogg Vorbis?</a>
             </dt>
             <dt>
              12.1.2. 
              <a href="#decode_ogg">How can I play back Ogg Vorbis files?</a>
             </dt>
             <dt>
              12.1.3. 
              <a href="#encode_ogg">How can I encode Ogg Vorbis files?</a>
             </dt>
             <dt>
              12.1.4. 
              <a href="#vorbis_in_jdk">Who should we lobby to get Ogg Vorbis support in the Sun JRE?</a>
             </dt>
             <dt>
              12.1.5. 
              <a href="#vorbis_duration">How can I get the duration of an Ogg Vorbis file?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="what_is_vorbis"></a><a name="N11370"></a><b>12.1.1.</b></td>
           <td valign="top" align="left"><p>What is Ogg Vorbis?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>From the website:</p>
            <div class="blockquote">
             <blockquote class="blockquote">
              <p>Ogg Vorbis is a fully open, non-proprietary, patent-and-royalty-free, general-purpose compressed audio format for mid to high quality (8kHz-48.0kHz, 16+ bit, polyphonic) audio and music at fixed and variable bitrates from 16 to 128 kbps/channel. This places Vorbis in the same competitive class as audio representations such as MPEG-4 (AAC), and similar to, but higher performance than MPEG-1/2 audio layer 3, MPEG-4 audio (TwinVQ), WMA and PAC.</p>
              <p>Vorbis is the first of a planned family of Ogg multimedia coding formats being developed as part of Xiph.org's Ogg multimedia project.</p>
             </blockquote>
            </div><p>For more information see <a href="http://www.xiph.org/ogg/vorbis/" target="_top">The Ogg Vorbis CODEC project</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="decode_ogg"></a><a name="N11383"></a><b>12.1.2.</b></td>
           <td valign="top" align="left"><p>How can I play back Ogg Vorbis files?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>A <a href="http://www.tritonus.org/plugins.html" target="_top">Plug-in</a> for Java Sound is available from the <a href="http://www.tritonus.org/" target="_top">Tritonus project</a>. It uses <a href="http://www.jcraft.com/jorbis/" target="_top">JOrbis</a>, a pure Java decoder from the <a href="http://www.jcraft.com/" target="_top">JCraft project</a>. Under development is also a decoder based on native libraries. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="encode_ogg"></a><a name="N1139B"></a><b>12.1.3.</b></td>
           <td valign="top" align="left"><p>How can I encode Ogg Vorbis files?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>A beta version of an encoder based on native libraries is available as part of the <a href="http://www.tritonus.org/" target="_top">Tritonus project</a>. See <a href="http://www.tritonus.org/plugins.html" target="_top">plug-ins</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="vorbis_in_jdk"></a><a name="N113AB"></a><b>12.1.4.</b></td>
           <td valign="top" align="left"><p><a name="vorbis_in_jdk.q"></a>Who should we lobby to get Ogg Vorbis support in the Sun JRE?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You can vote for the <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4671067" target="_top">RFE #4671067</a> to include Ogg Vorbis in the JRE. A remark from Florian:</p>
            <div class="blockquote">
             <blockquote class="blockquote">
              <p>As far as I know, there is no development yet in Java Sound for Mustang. Also, there are legal problems (licenses...) for including ogg support in Java. Sun cannot just include 3rd party code, no matter what license it is published. I've tried to push inclusion of native bindings for ogg in Java so that you just need to install the ogg library locally to get ogg support in Java.</p>
             </blockquote>
            </div><p>See also <a href="http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=4499904" target="_top">RFE #4499904</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="vorbis_duration"></a><a name="N113C1"></a><b>12.1.5.</b></td>
           <td valign="top" align="left"><p><a name="vorbis_duration.q"></a>How can I get the duration of an Ogg Vorbis file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Currently, the JavaZOOM version of the Vorbis decoder plug-in (<a href="http://www.javazoom.net/vorbisspi/vorbisspi.html" target="_top">VorbisSPI</a>) sets the duration property in <tt class="classname">TAudioFileFormat</tt> if the data source is a <tt class="classname">File</tt>. Ways to provide length and duration information for <tt class="classname">URL</tt> and <tt class="classname">InputStream</tt> sources are under discussion; see the mailing list archives. See also <a href="#file_length">How can I determine the length or the duration of an audio file?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_mp3"></a><h4 class="title"><a name="sec_mp3"></a>12.2. mp3</h4></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              12.2.1. 
              <a href="#decode_mp3">How can I play back mp3 files?</a>
             </dt>
             <dt>
              12.2.2. 
              <a href="#mp3_in_jre">Why is there no mp3 decoder in the Sun JRE/JDK?</a>
             </dt>
             <dt>
              12.2.3. 
              <a href="#mp3_legal">What is the legal state of the JLayer mp3 decoder?</a>
             </dt>
             <dt>
              12.2.4. 
              <a href="#decoder_differences">What are the differences between the JLayer mp3 decoder plug-in and the Sun mp3 decoder plug-in?</a>
             </dt>
             <dt>
              12.2.5. 
              <a href="#encode_mp3">How can I encode mp3 files?</a>
             </dt>
             <dt>
              12.2.6. 
              <a href="#pure_java_mp3_encoder">Is there a mp3 encoder implemented in pure java?</a>
             </dt>
             <dt>
              12.2.7. 
              <a href="#mp3_encoder_input_formats">Which input formats can I use for the mp3 encoder?</a>
             </dt>
             <dt>
              12.2.8. 
              <a href="#mp3_encoder_on_mac">Is mp3 encoding possible on Mac OS?</a>
             </dt>
             <dt>
              12.2.9. 
              <a href="#mp3_problems">Why do I get an UnsupportedAudioFileException when trying to play a mp3 file?</a>
             </dt>
             <dt>
              12.2.10. 
              <a href="#detect_mp3_length">How can I get the length of an mp3 stream?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="decode_mp3"></a><a name="N113E4"></a><b>12.2.1.</b></td>
           <td valign="top" align="left"><p><a name="decode_mp3.q"></a>How can I play back mp3 files?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There is a pure Java decoder of the javazoom project. <a href="http://www.tritonus.org/" target="_top">Tritonus</a>, the open source implementation of Java Sound incorporates it. There is a <a href="http://www.tritonus.org/plugins.html" target="_top">plug-in</a> available which runs under any JVM.</p><p>Sun has also released a pure java mp3 decoder plug-in: <a href="http://java.sun.com/products/java-media/jmf/mp3/download.html" target="_top">Java MP3 PlugIn</a></p><p>There is also a native mp3 decoder implementation. It is part of the mp3 encoder plug-in. See <a href="http://www.tritonus.org/plugins.html" target="_top">Tritonus Plug-ins</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mp3_in_jre"></a><a name="N11400"></a><b>12.2.2.</b></td>
           <td valign="top" align="left"><p><a name="mp3_in_jre.q"></a>Why is there no mp3 decoder in the Sun JRE/JDK?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>A quote from Florian:</p>
            <div class="blockquote">
             <blockquote class="blockquote">
              <p>&#x201c;<span class="quote">As far as I know, Sun will not include MP3 support into the JRE, mostly because it would require a separate license to click through during installation. That's also the reason why it could not be enabled that your software downloads the plug-in on your own since the license must be acknowledged by every end-user. It's the crazy lawyers.</span>&#x201d;</p>
             </blockquote>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mp3_legal"></a><a name="N1140F"></a><b>12.2.3.</b></td>
           <td valign="top" align="left"><p><a name="mp3_legal.q"></a>What is the legal state of the JLayer mp3 decoder?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There was much discussion on the mailing list; see the archive for details. As a short summary, see <a href="http://archives.java.sun.com/cgi-bin/wa?A2=ind0411&amp;L=javasound-interest&amp;F=&amp;S=&amp;P=16739" target="_top">Eric's Mail</a> and <a href="http://archives.java.sun.com/cgi-bin/wa?A2=ind0411&amp;L=javasound-interest&amp;F=&amp;S=&amp;P=16848" target="_top">Florian's Mail</a>. If you want to avoid legal issues completly, it is recommended to use <a href="#sec_vorbis">Ogg Vorbis</a> instead of mp3. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="decoder_differences"></a><a name="N11424"></a><b>12.2.4.</b></td>
           <td valign="top" align="left"><p><a name="decoder_differences.q"></a>What are the differences between the JLayer mp3 decoder plug-in and the Sun mp3 decoder plug-in?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left">
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>The Sun decoder is twice as fast as the JLayer decoder though it is written in pure java, too.</p></li>
              <li><p>The Sun decoder only supports MPEG 1 audio layer III files, while the JLayer decoder supports MPEG 1 and MPEG2, audio layer I - III files.</p></li>
              <li><p>.</p></li>
             </ul>
            </div><p>See also <a href="#mp3_legal">What is the legal state of the JLayer mp3 decoder?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="encode_mp3"></a><a name="N1143B"></a><b>12.2.5.</b></td>
           <td valign="top" align="left"><p>How can I encode mp3 files?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Java is free, this collides with the (enforced) licences for mp3 encoders. I have studied very carefully the mp3 licencing model and also asked at Fraunhofer (inventors of mp3) for additional information: it won't be possible to deliver a free mp3 encoder legally. (If anyone knows a "hole", please let me know. (not the available source code - this is not appropriate: the encoders available as source code - most of them based on the ISO reference implementation - create bad quality mp3's and the licence doesn't allow the use of such encoders!))</p><p>The <a href="http://www.tritonus.org/" target="_top">Tritonus</a> team is working on an interface to the open source encoder <a href="http://www.sulaco.org/mp3/" target="_top">LAME</a>. Like that people who do not fear licence problems can download LAME as a separate package and link it to Java Sound. See also <a class="olink" href="faq_applets.html#encode_mp3">Q:&nbsp;7</a> (Florian)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="pure_java_mp3_encoder"></a><a name="N11451"></a><b>12.2.6.</b></td>
           <td valign="top" align="left"><p>Is there a mp3 encoder implemented in pure java?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>No. At least none that is available to the public. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mp3_encoder_input_formats"></a><a name="N11459"></a><b>12.2.7.</b></td>
           <td valign="top" align="left"><p><a name="mp3_encoder_input_formats.q"></a>Which input formats can I use for the mp3 encoder?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The Tritonus mp3 encoder supports the following input formats: 16 bit signed PCM; mono or stereo; big or little endian; 8, 11.025, 12, 16, 22.05, 24, 32, 44.1 or 48 kHz sample rate. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mp3_encoder_on_mac"></a><a name="N11462"></a><b>12.2.8.</b></td>
           <td valign="top" align="left"><p>Is mp3 encoding possible on Mac OS?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>LAME and its Tritonus plug-in are reported to work on Mac OS X, but not on Mac OS 9. For details, see <a href="http://sourceforge.net/mailarchive/message.php?msg_id=10490531" target="_top">Steven's mail</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="mp3_problems"></a><a name="N1146E"></a><b>12.2.9.</b></td>
           <td valign="top" align="left"><p>Why do I get an <tt class="classname">UnsupportedAudioFileException</tt> when trying to play a mp3 file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>First, check your installation as described on the bottom of the <a href="http://www.tritonus.org/plugins.html" target="_top">Java Sound Plugins page</a>. If your installation is correct, but the file still doesn't play, there are two common reasons: id3v2 tags or a variable bit rate (VBR) header. Both are prepended to an ordinary mp3 file. And the <tt class="classname">AudioFileReader</tt> for mp3 can't detect this situation. The Tritonus team does not plan to fix this behaviour. However, <a href="http://www.javazoom.net/index.shtml" target="_top">JavaZOOM</a> provides a modified version of the <tt class="classname">AudioFileReader</tt>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="detect_mp3_length"></a><a name="N11487"></a><b>12.2.10.</b></td>
           <td valign="top" align="left"><p><a name="detect_mp3_length.q"></a>How can I get the length of an mp3 stream?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Currently, you can use the following hack with the JLayer decoder:</p><pre class="programlisting">
import java.io.*;
import javazoom.jl.decoder.*;
import javax.sound.sampled.*;

public class TestMP3Duration
{
    public static void main(String args[])
    {

        try
        {
            File f = new File(args[0]);
            Bitstream m_bitstream = new Bitstream(
                              new FileInputStream(f));
            Header m_header = m_bitstream.readFrame();

            int mediaLength = (int)f.length();
 
            int nTotalMS = 0;
            if (mediaLength != AudioSystem.NOT_SPECIFIED) {
               nTotalMS = Math.round(m_header.total_ms(mediaLength));
            }

            System.out.println("Length in ms: " + nTotalMS);
        } catch(Exception e) {
            e.printStackTrace();
        } 
    }
}</pre><p>It seems that the decoder released by Sun (see <a href="#decode_mp3">How can I play back mp3 files?</a>) does not support any means to obtain the length.</p><p>In the future (once the JDK 1.5.0 is released) it will be possible to get the length in a portable way using <tt class="classname">AudioFileFormat</tt> properties. See also <a href="#file_length">How can I determine the length or the duration of an audio file?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_gsm"></a><h4 class="title"><a name="sec_gsm"></a>12.3. GSM 06.10</h4></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              12.3.1. 
              <a href="#gsm">Is there support for GSM?</a>
             </dt>
             <dt>
              12.3.2. 
              <a href="#gsm_codec_formats">Why does the GSM codec refuses to encode from/decode to the format I want?</a>
             </dt>
             <dt>
              12.3.3. 
              <a href="#gsm_in_wav">How can I read a .wav file with GSM data or store GSM-encoded data in a .wav file?</a>
             </dt>
             <dt>
              12.3.4. 
              <a href="#gsm_with_byte_arrays">I want to convert to/from GSM using the Tritonus plug-in. However, I do not work with files or streams. Rather, I want to convert byte[] arrays.</a>
             </dt>
             <dt>
              12.3.5. 
              <a href="#gsm_from_bits">How can I decode GSM from frames of 260 bit?</a>
             </dt>
             <dt>
              12.3.6. 
              <a href="#calculate_gsm_duration">How can I calculate the duration of a GSM file?</a>
             </dt>
             <dt>
              12.3.7. 
              <a href="#native_gsm_codecs">Are there native implementations of codecs that are compatible with the framing format used by the Java Sound GSM codec?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="gsm"></a><a name="N114A8"></a><b>12.3.1.</b></td>
           <td valign="top" align="left"><p>Is there support for GSM?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Yes, you can download a service provider plug-in for <a href="http://kbs.cs.tu-berlin.de/~jutta/toast.html" target="_top">GSM 06.10</a> from <a href="http://www.tritonus.org/plugins.html" target="_top">Java Sound Plugins</a>. Since this implementation is pure-java, it can be used with any Java Sound implementation on any platform. For examples of using the GSM plug-in, see <a class="olink" href="examples/GSMEncoder.html">Encoding an audio file to GSM 06.10</a>, <a class="olink" href="examples/AudioDecoder.html">Decoding an encoded audio file</a> and <a class="olink" href="examples/DecodingAudioPlayer.html">Playing an encoded audio file</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="gsm_codec_formats"></a><a name="N114C4"></a><b>12.3.2.</b></td>
           <td valign="top" align="left"><p>Why does the GSM codec refuses to encode from/decode to the format I want?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>GSM 06.10 only works with 8 kHz sample rate. This is a property of the format and cannot be changed. The whole algorithm depends on this.</p><p>Therefore, Tritonus' GSM coded supports only two format at the PCM side: AudioFormat(AudioFormat.Encoding.PCM_SIGNED, 8000.0F, 16, 1, 2, 8000.0F, false) and AudioFormat(AudioFormat.Encoding.PCM_SIGNED, 8000.0F, 16, 1, 2, 8000.0F, true). If you want to use other source or target formats, you have to do the conversion in two steps:</p><p>For encoding, first convert the audio data from your source format to one the encoder accepts. Then you can do the encoding.</p><p>For decoding, decode to one of the format the decoder supports. In a second step, convert to your desired target format.</p><p>If your data has a sample rate different form 8 kHz, you have to do a sample rate conversion. See <a href="#convert_sample_rate">How can I do sample rate conversion?</a></p><p>Note that GSM actually uses only the 13 most significant bit of the 16 bit PCM samples. The 3 least significant bits are ignored while encoding, and set to zero while decoding. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="gsm_in_wav"></a><a name="N114D9"></a><b>12.3.3.</b></td>
           <td valign="top" align="left"><p><a name="gsm_in_wav.q"></a>How can I read a <tt class="filename">.wav</tt> file with GSM data or store GSM-encoded data in a <tt class="filename">.wav</tt> file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is not supported by Tritonus. The reason is that Microsoft specified a fancy scrambling of bits for GSM in <tt class="filename">.wav</tt>. We considered it too much work to comply with such "standards". For details, see the <a href="http://kbs.cs.tu-berlin.de/~jutta/toast.html" target="_top">GSM page of Jutta</a>. See also <a href="#native_gsm_codecs">Are there native implementations of codecs that are compatible with the framing format used by the Java Sound GSM codec?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="gsm_with_byte_arrays"></a><a name="N114F6"></a><b>12.3.4.</b></td>
           <td valign="top" align="left"><p>I want to convert to/from GSM using the Tritonus plug-in. However, I do not work with files or streams. Rather, I want to convert <span class="type">byte[]</span> arrays.</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You have two choices:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Convert the byte array to and from <tt class="classname">AudioInputStream</tt>s using <tt class="classname">ByteArrayInputStream</tt>s and <tt class="classname">ByteArrayOutputStream</tt>s. For details, see the questions <a href="#file_bytearray">How can I read an audio file and store the audio data in a byte array?</a> and <a href="#bytearray_file">How can I write audio data from a byte array to an audio file?</a>.</p><p>If you want to encode data captured with a <tt class="classname">TargetDataLine</tt>, use the <tt class="classname">AudioInputStream</tt> constructor with a <tt class="classname">TargetDataLine</tt> parameter. This is the recommended way, because it is clean and does not directely access low-level APIs. It is highly likely to be portable between different Java Sound implementations (Assuming that one day there will be an alternate GSM codec implementation).</p></li>
              <li><p>Use the low-level API of the GSM decoder and encoder. This is tricky and is not officially supported by the Tritonus team. The source code is your friend, besides that you may get support from the original authors. To say it short: it is not recommended. If you really want to do it, you can take the implementation of <tt class="filename">GSMFormatConversionProvider.java</tt> in <a href="http://www.tritonus.org/" target="_top">Tritonus</a> as an example.</p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="gsm_from_bits"></a><a name="N1152E"></a><b>12.3.5.</b></td>
           <td valign="top" align="left"><p>How can I decode GSM from frames of 260 bit?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>GSM frames indeed have a length of 260 bits, which is equal to 32.5 bytes. To store such frames in files, the common technique is to pad each frame with 4 zero bits at the end, so that a frame fits into 33 bytes. This is the format used by the GSM codec of Tritonus. So if you do the same padding, the data can be decoded by this codec. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="calculate_gsm_duration"></a><a name="N11536"></a><b>12.3.6.</b></td>
           <td valign="top" align="left"><p><a name="calculate_gsm_duration.q"></a>How can I calculate the duration of a GSM file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>If the length of the encoded data is known, calculating the total duration is quite easy: A GSM frame with 33 bytes contains information about 160 samples at a sample rate of 8 kHz; each frame represents 20 milliseconds. So the formula is:</p><pre class="programlisting">
long length_of_data = ...; // in bytes
long number_of_frames = length_of_data / 33;
long duration = number_of_frames * 20; // in milliseconds</pre><p>See also <a href="#file_length">How can I determine the length or the duration of an audio file?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="native_gsm_codecs"></a><a name="N11548"></a><b>12.3.7.</b></td>
           <td valign="top" align="left"><p><a name="native_gsm_codecs.q"></a>Are there native implementations of codecs that are compatible with the framing format used by the Java Sound GSM codec?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Yes, there are quite a number of programs listed on <a href="http://kbs.cs.tu-berlin.de/~jutta/toast.html#apps" target="_top">GSM Applications</a> and <a href="http://kbs.cs.tu-berlin.de/~jutta/toast.html#ports" target="_top">GSM for X</a>.</p><p>Note that Microsoft uses a different framing for GSM. Therefore, Microsoft GSM codecs are incompatible. See <a href="#gsm_in_wav">How can I read a <tt class="filename">.wav</tt> file with GSM data or store GSM-encoded data in a <tt class="filename">.wav</tt> file?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_comp_xlaw"></a><h4 class="title"><a name="sec_comp_xlaw"></a>12.4. A-law and &#x3bc;-law</h4></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              12.4.1. 
              <a href="#alaw_ulaw">What are A-law and &#x3bc;-law?</a>
             </dt>
             <dt>
              12.4.2. 
              <a href="#convert_to_ulaw">How can I convert a PCM encoded byte[] to a &#x3bc;-law byte[]?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="alaw_ulaw"></a><a name="N11565"></a><b>12.4.1.</b></td>
           <td valign="top" align="left"><p>What are A-law and &#x3bc;-law?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>These are logarithmic codings of a sample value. The values are stored in 8 bit, but the range of values is roughly equal to 14 bit linear. So coding 16 bit data to A-law and &#x3bc;-law means half the storage size with about 15 per cent quality loss. See a <a href="http://cui.unige.ch/OSG/info/AudioFormats/ap10.html" target="_top">mathematical definition</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="convert_to_ulaw"></a><a name="N11571"></a><b>12.4.2.</b></td>
           <td valign="top" align="left"><p>How can I convert a PCM encoded <span class="type">byte[]</span> to a &#x3bc;-law <span class="type">byte[]</span>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>When you are processing streams, read the documentation of <tt class="classname">AudioSystem</tt>. There are functions like <tt class="function">getAudioInputStream(AudioFormat, AudioInputStream)</tt> that do the conversion for you.</p><p>In case you absolutely want to do the conversion "by hand", look at how <a href="http://www.tritonus.org/" target="_top">Tritonus</a> is doing it: have a look at the class <a href="http://tritonus.cvs.sourceforge.net/tritonus/tritonus/src/org/tritonus/share/sampled/TConversionTool.java?view=markup" target="_top"><tt class="classname">TConversionTool</tt></a>. (Florian)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_comp_speex"></a><h4 class="title"><a name="sec_comp_speex"></a>12.5. Speex</h4></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              12.5.1. 
              <a href="#what_is_speex">What is Speex?</a>
             </dt>
             <dt>
              12.5.2. 
              <a href="#support_for_speex">Is there support for Speex?</a>
             </dt>
             <dt>
              12.5.3. 
              <a href="#jspeex_usage">How do I use JSpeex?</a>
             </dt>
             <dt>
              12.5.4. 
              <a href="#speex_duration">How can I get the duration of a Speex file?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="what_is_speex"></a><a name="N11597"></a><b>12.5.1.</b></td>
           <td valign="top" align="left"><p>What is Speex?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Speex is an audio compression format designed for speech. It is open source and patent free. For more information see the <a href="http://www.speex.org/" target="_top">Speex Homepage</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="support_for_speex"></a><a name="N115A3"></a><b>12.5.2.</b></td>
           <td valign="top" align="left"><p>Is there support for Speex?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Yes, have a look at the <a href="http://jspeex.sourceforge.net/" target="_top">JSpeex project</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="jspeex_usage"></a><a name="N115AF"></a><b>12.5.3.</b></td>
           <td valign="top" align="left"><p>How do I use JSpeex?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>See <a href="http://archives.java.sun.com/cgi-bin/wa?A2=ind0504&amp;L=javasound-interest&amp;F=&amp;S=&amp;P=6076" target="_top">Mark's mail</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="speex_duration"></a><a name="N115BB"></a><b>12.5.4.</b></td>
           <td valign="top" align="left"><p>How can I get the duration of a Speex file?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Currently, there seems to be no way to find out the duration. The typical problem with getting the duration of compressed audio data is that there is no linear relation between the length of the encoded data and the length of the unencoded data. So typcally, length information is available if either:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>There is a header that contains this information</p></li>
              <li><p>The implementor of the decoder decided to read or skip through the whole stream to gather this information. Whether this is possible depends on the encoded format and on the stream: it requires resetting, so this is only possible if the stream is seekable or can be reopened from the beginning or the whole content is cached in memory. Implementor typically decide against caching, since it may consume several megabytes of memory.</p></li>
             </ul>
            </div><p>I don't know details about the Speex format, so I don't know if there is a possibility to make length information available. See also <a href="#file_length">How can I determine the length or the duration of an audio file?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_comp_misc"></a><h4 class="title"><a name="sec_comp_misc"></a>12.6. Miscellaneous</h4></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              12.6.1. 
              <a href="#adpcm">Is there support for ADPCM (a.k.a. G723) in Java Sound?</a>
             </dt>
             <dt>
              12.6.2. 
              <a href="#wma">Is there support for WMA and ASF in Java Sound?</a>
             </dt>
             <dt>
              12.6.3. 
              <a href="#convert_encoded_to_encoded">How can I convert between two encoded formats directly (e.g. from mp3 to A-law)?</a>
             </dt>
             <dt>
              12.6.4. 
              <a href="#compression_schemas">What compression schemas can I use?</a>
             </dt>
             <dt>
              12.6.5. 
              <a href="#encoding_constr_workaround">How can I get Encoding instances for GSM and mp3 with JDKs older than 1.5.0?</a>
             </dt>
             <dt>
              12.6.6. 
              <a href="#realaudio">Is there support for RealAudio / RealMedia (.ra / .rm files)?</a>
             </dt>
             <dt>
              12.6.7. 
              <a href="#new_format_support">How can I get support for a new encoding?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="adpcm"></a><a name="N115D6"></a><b>12.6.1.</b></td>
           <td valign="top" align="left"><p>Is there support for ADPCM (a.k.a. G723) in Java Sound?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Currently not. There is an alpha version of a codec for IMA ADPCM in Tritonus. However, the file readers and writers haven't been adapted to handle this format, so the codec is of little use. Doing this is not really difficult, volunteers are appreciated. Developing support for MS ADPCM shouldn't be too difficult, too.</p><p>Also note that <a href="http://java.sun.com/products/java-media/jmf/" target="_top">JMF</a> can handle IMA ADPCM. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="wma"></a><a name="N115E4"></a><b>12.6.2.</b></td>
           <td valign="top" align="left"><p>Is there support for WMA and ASF in Java Sound?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>WMA and ASF are not supported by Java Sound or any known plug-in to it. Of course there are native programs that can do the conversion. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="convert_encoded_to_encoded"></a><a name="N115EC"></a><b>12.6.3.</b></td>
           <td valign="top" align="left"><p><a name="convert_encoded_to_encoded.q"></a>How can I convert between two encoded formats directly (e.g. from mp3 to A-law)?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>You have to do this in 2 to 4 steps:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Convert it to PCM, 16 bit, any endianess, sample rate and channels as the original input file</p></li>
              <li><p>If necessary, convert sample rate and number of channels (as separate steps) to the values you want in the target file.</p></li>
              <li><p>convert that PCM stream to the target format, same sample rate and channels.</p></li>
             </ul>
            </div><p>See also the example <a class="olink" href="examples/AudioConverter.html">Converting audio files to different encodings, sample size, channels, sample rate</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="compression_schemas"></a><a name="N11605"></a><b>12.6.4.</b></td>
           <td valign="top" align="left"><p><a name="compression_schemas.q"></a>What compression schemas can I use?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>The table below gives you an overview:</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th valign="top">schema</th>
                <th valign="top">availability</th>
                <th valign="top">location</th>
                <th valign="top">usable in applets</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td valign="top">A-law</td>
                <td valign="top">standard part of Java Sound implementations</td>
                <td valign="top">---</td>
                <td valign="top">yes</td>
               </tr>
               <tr valign="top">
                <td valign="top">&#x3bc;-law</td>
                <td valign="top">standard part of Java Sound implementations</td>
                <td valign="top">---</td>
                <td valign="top">yes</td>
               </tr>
               <tr valign="top">
                <td valign="top">GSM 06.10</td>
                <td valign="top">part of Tritonus, available as plug-in for other Java Sound implementations</td>
                <td valign="top"><a href="http://www.tritonus.org/plugins.html" target="_top">Tritonus plug-ins</a></td>
                <td valign="top">yes</td>
               </tr>
               <tr valign="top">
                <td valign="top"><a href="#sec_mp3">mp3</a></td>
                <td valign="top">part of Tritonus, available as plug-in for other Java Sound implementations</td>
                <td valign="top"><a href="http://www.tritonus.org/plugins.html" target="_top">Tritonus plug-ins</a></td>
                <td valign="top">decoding: yes, encoding: no</td>
               </tr>
               <tr valign="top">
                <td valign="top"><a href="#sec_vorbis">Ogg Vorbis</a></td>
                <td valign="top">part of Tritonus, available as plug-in for other Java Sound implementations.</td>
                <td valign="top"><a href="http://www.tritonus.org/plugins.html" target="_top">Tritonus plug-ins</a></td>
                <td valign="top">decoding: yes, encoding: no (pure java encoder is under development)</td>
               </tr>
               <tr valign="top">
                <td valign="top">Speex</td>
                <td valign="top">available as plug-in for other Java Sound implementations</td>
                <td valign="top"><a href="http://jspeex.sourceforge.net/index.php" target="_top">JSpeex project</a></td>
                <td valign="top">no</td>
               </tr>
               <tr valign="top">
                <td valign="top">IMA ADPCM</td>
                <td valign="top">under development in Tritonus</td>
                <td valign="top">---</td>
                <td valign="top">yes</td>
               </tr>
               <tr valign="top">
                <td valign="top">MS ADPCM</td>
                <td valign="top">not available</td>
                <td valign="top">---</td>
                <td valign="top">---</td>
               </tr>
              </tbody>
             </table>
            </div><p>See also <a href="#compression_network">What compression schema should I use to transfer audio data over a network?</a></p><p>Also note that <a href="http://java.sun.com/products/java-media/jmf/index.html" target="_top">JMF</a> has quite a few more <a href="http://java.sun.com/products/java-media/jmf/2.1.1/formats.html" target="_top">codecs</a> than Java Sound. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="encoding_constr_workaround"></a><a name="N1168B"></a><b>12.6.5.</b></td>
           <td valign="top" align="left"><p><a name="encoding_constr_workaround.q"></a>How can I get <tt class="classname">Encoding</tt> instances for GSM and mp3 with JDKs older than 1.5.0?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Since 1.5.0, the way to obtain <tt class="classname">Encoding</tt> instances for non-standard encodings like <a href="#sec_gsm">GSM 06.10</a>, <a href="#sec_vorbis">Ogg Vorbis</a> and <a href="#sec_mp3">mp3</a> is to use the constructor <tt class="function">Encoding(String name)</tt> (See, for instance, <a class="olink" href="examples/GSMEncoder.html">Encoding an audio file to GSM 06.10</a>). In JDKs older than 1.5.0, this constructor is protected. So calling it directly is not possible. The old workaround for this problem was a special class <tt class="classname">org.tritonus.share.sampled.Encodings</tt> introduced by Tritonus. It can be used to retrieve <tt class="classname">Encoding</tt> instances. See this <a href="http://jsresources.cvs.sourceforge.net/jsresources/jsresources/examples/src/GSMEncoder.java?view=markup" target="_top">older version of <tt class="classname">GSMEncoder</tt></a> for an example how to do this. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="realaudio"></a><a name="N116BA"></a><b>12.6.6.</b></td>
           <td valign="top" align="left"><p><a name="realaudio.q"></a>Is there support for RealAudio / RealMedia (<tt class="filename">.ra</tt> / <tt class="filename">.rm</tt> files)?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There isn't, and it doesn't look like there will be in the near future. RealAudio is a proprietary format; there is no specification available to the public. Due to that, it's hard to implement support for it. Currently, the only way to do this seems to use native libraries provided by RealNetworks. If you want to change this situation, bug RealNetworks to publish specs (politely, please). (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="new_format_support"></a><a name="N116CB"></a><b>12.6.7.</b></td>
           <td valign="top" align="left"><p><a name="new_format_support.q"></a>How can I get support for a new encoding?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>If you need support for an encoding that is currently not supported, you can code it yourself (or pay somebody to do so). Java Sound has an extension mechanism called "service provider interface" (SPI). For supporting a new format, you need to write a plug-in that implements the interface <tt class="classname">FormatConversionProvider</tt>. Typically, it is also necessary to write new audio file readers (interface <tt class="classname">AudioFileReader</tt>) and audio file writers (interface <tt class="classname">AudioFileWriter</tt>) or extend existing ones.</p><p>See also <a class="olink" href="faq_misc.html#sec_spi">Q &amp; A&nbsp;2, &#x201c;Service Provider Interface (SPI)&#x201d;</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_network"></a><h3 class="title"><a name="sec_network"></a>13. Audio data transfer over networks</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              13.1. 
              <a href="#streaming">How can I do streaming of audio data?</a>
             </dt>
             <dt>
              13.2. 
              <a href="#streaming_latency">Why do I get distorted sound in my streaming application if it is used on the internet, but works on a LAN?</a>
             </dt>
             <dt>
              13.3. 
              <a href="#upload">How can I upload recorded audio data to a server?</a>
             </dt>
             <dt>
              13.4. 
              <a href="#compression_network">What compression schema should I use to transfer audio data over a network?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="streaming"></a><a name="N116E9"></a><b>13.1.</b></td>
           <td valign="top" align="left"><p>How can I do streaming of audio data?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There is no special support for streaming protocols in the Java Sound API. Options include:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Implement your own streaming protocol based on the <tt class="classname">java.net.*</tt> classes.</p></li>
              <li><p>Use the realtime streaming protocol (RTP) implementation included in the <a href="http://java.sun.com/products/java-media/jmf/" target="_top">Java Media Framework (JMF)</a>.</p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="streaming_latency"></a><a name="N11701"></a><b>13.2.</b></td>
           <td valign="top" align="left"><p>Why do I get distorted sound in my streaming application if it is used on the internet, but works on a LAN?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>With a naive streaming approach (simply writing to and reading from sockets), you need a guaranteed network bandwidth and minimum network latency. Though this is not really guaranteed on an ethernet, the bandwidth is typically sufficient for smooth operation. On the internet, however, bandwidth is much more limited and latency much higher than on an ethernet. So packet are arriving late, with leads to clicks in the sound. To compensate for this effects, special streaming protocols are needed. The most common of there is the Real-time protocol (RTP). (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="upload"></a><a name="N11709"></a><b>13.3.</b></td>
           <td valign="top" align="left"><p>How can I upload recorded audio data to a server?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There are several ways to do this:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>One possibility is to use sockets (classes <tt class="classname">java.net.Socket</tt> and <tt class="classname">java.net.ServerSocket</tt>). See <a href="http://archives.java.sun.com/cgi-bin/wa?A2=ind9911&amp;L=javasound-interest&amp;F=&amp;S=&amp;P=4491" target="_top">this mail</a> for more details, including an example server program.</p></li>
              <li><p>Another possibility is to use HTTP requests. Both POST and PUT requests can be used for uploading.</p></li>
              <li><p>A more sophisticated approach is to use the realtime streaming protocol (RTP) implementation included in the <a href="http://java.sun.com/products/java-media/jmf/" target="_top">Java Media Framework (JMF)</a>.</p></li>
             </ul>
            </div><p>You may also want to have a look at <a class="olink" href="apps/am.html">Java Sound Resources: Applications: Answering Machine</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="compression_network"></a><a name="N1172F"></a><b>13.4.</b></td>
           <td valign="top" align="left"><p><a name="compression_network.q"></a>What compression schema should I use to transfer audio data over a network?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>It depends on your requirements. There is a general trade-off between bandwidth, processing power and quality. Better quality needs either more bandwidth or more processing power. Here is a short overview of some common compression schemas:</p>
            <div class="informaltable">
             <table border="1">
              <colgroup>
               <col>
               <col>
               <col>
               <col>
              </colgroup>
              <thead>
               <tr valign="top">
                <th valign="top">schema</th>
                <th valign="top">bandwidth</th>
                <th valign="top">processing req.</th>
                <th valign="top">quality</th>
               </tr>
              </thead>
              <tbody>
               <tr valign="top">
                <td valign="top">PCM uncompressed (CD quality)</td>
                <td valign="top">1.4 Mbit/s (176.4 kByte/s)</td>
                <td valign="top">none</td>
                <td valign="top">very good</td>
               </tr>
               <tr valign="top">
                <td valign="top">A-law, &#x3bc;-law</td>
                <td valign="top">64 kbit/s (8 kByte/s)</td>
                <td valign="top">low</td>
                <td valign="top">bad</td>
               </tr>
               <tr valign="top">
                <td valign="top"><a href="#sec_gsm">GSM 06.10</a></td>
                <td valign="top">13.6 kByte/s</td>
                <td valign="top">medium</td>
                <td valign="top">medium (speech), bad (music)</td>
               </tr>
               <tr valign="top">
                <td valign="top"><a href="#sec_mp3">mp3</a></td>
                <td valign="top">typically 8 - 40 kByte/s</td>
                <td valign="top">high</td>
                <td valign="top">medium to good</td>
               </tr>
              </tbody>
             </table>
            </div><p>For speech, <a href="#sec_gsm">GSM 06.10</a> is a common choise. It is widely used in internet phone and voice chat applications. For high-quality music, use <a href="#sec_mp3">mp3</a> or (better) <a href="#sec_vorbis">Ogg Vorbis</a>. See also <a href="#compression_schemas">What compression schemas can I use?</a> (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_ports"></a><h3 class="title"><a name="sec_ports"></a>14. Ports</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              14.1. 
              <a href="#use_ports">How do I use the interface Port?</a>
             </dt>
             <dt>
              14.2. 
              <a href="#no_ports">Why is it not possible to retrieve Port instances?</a>
             </dt>
             <dt>
              14.3. 
              <a href="#no_port_controls">Why is it not possible to retrieve Control instances from Port lines?</a>
             </dt>
             <dt>
              14.4. 
              <a href="#port_open_close">What does opening and closing mean for Port lines?</a>
             </dt>
             <dt>
              14.5. 
              <a href="#port_vs_dataline">Why is it not possible to read data from a microphone Port line?</a>
             </dt>
             <dt>
              14.6. 
              <a href="#ports_jmf">Can I use Java Sound's Port interface to control volume and tone of sound played with an application using JMF?</a>
             </dt>
             <dt>
              14.7. 
              <a href="#no_predefined_ports">Why are there no Port instances of certain predefined types (like Port.Info.MICROPHONE or Port.Info.COMPACT_DISC) on Linux?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="use_ports"></a><a name="N1178C"></a><b>14.1.</b></td>
           <td valign="top" align="left"><p><a name="use_ports.q"></a>How do I use the interface <tt class="classname">Port</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Have a look at the chapter <a href="http://java.sun.com/j2se/1.5.0/docs/guide/sound/programmer_guide/chapter6.html" target="_top">"Processing Audio with Controls"</a> in the <a href="http://java.sun.com/j2se/1.5.0/docs/guide/sound/programmer_guide/contents.html" target="_top">Java Sound Programmer's Guide</a>. You can also have a look at how the applications <a class="olink" href="apps/jsinfo.html">jsinfo</a> and <a class="olink" href="apps/mixer.html">systemmixer</a> deal with ports. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="no_ports"></a><a name="N117AA"></a><b>14.2.</b></td>
           <td valign="top" align="left"><p><a name="no_ports.q"></a>Why is it not possible to retrieve <tt class="classname">Port</tt> instances?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Up to version 1.4.1, there was no <tt class="classname">Port</tt> implementation in the Sun JDK. In 1.4.2, an implementation was added for Windows. In 1.5.0, an implementation was added for Solaris and Linux. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="no_port_controls"></a><a name="N117B9"></a><b>14.3.</b></td>
           <td valign="top" align="left"><p><a name="no_port_controls.q"></a>Why is it not possible to retrieve <tt class="classname">Control</tt> instances from <tt class="classname">Port</tt> lines?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Make sure you are opening the <tt class="classname">Port</tt> line before retrieving controls. For instance:</p><pre class="programlisting">
Port port = ...;
port.open();
Control[] controls = port.getControls();</pre><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="port_open_close"></a><a name="N117D0"></a><b>14.4.</b></td>
           <td valign="top" align="left"><p><a name="port_open_close.q"></a>What does opening and closing mean for <tt class="classname">Port</tt> lines?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Typically, the implementation of ports needs to query the soundcard's mixer for its properties and build internal data structures for <tt class="classname">Control</tt> instances. Since this is often an expensive operation, it is only done if the port is really used, i.e. when it is opened. So you need to open the <tt class="classname">Port</tt> to retrieve and use <tt class="classname">Control</tt> instances. After closing the port, the association between the <tt class="classname">Control</tt> instances and native resources of the soundcard are invalidated, so that changes to the controls do have no effect.</p><p>See also <a href="#no_port_controls">Why is it not possible to retrieve <tt class="classname">Control</tt> instances from <tt class="classname">Port</tt> lines?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="port_vs_dataline"></a><a name="N117EE"></a><b>14.5.</b></td>
           <td valign="top" align="left"><p>Why is it not possible to read data from a microphone <tt class="classname">Port</tt> line?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>This is due to the design of the hardware. Soundcards usually have only one Analog-Digital-Converter (ADC), but multiple input lines. You can obtain a <tt class="classname">TargetDataLine</tt> to get the digital data provided by the ADC. On the other hand, <tt class="classname">Port</tt> lines represent the analog inputs to the ADC and the analog outputs from the Digital-Analog-Converter (DAC). By using the controls of a <tt class="classname">Port</tt> line, you can influence the signal level on that line that reaches the ADC, or influence the volume on the output line that leads to your speakers. In other words, the <tt class="classname">Port</tt> lines are the abstraction of the hardware mixer on the soundcard. While one could question why <tt class="classname">Port</tt> and <tt class="classname">DataLine</tt> have a common base interface, it should be clear that you can't read digital data from an object representing an analog line.</p><p>See also <a href="#match_port_mixer">How can I detect which Port Mixer belongs to which soundcard?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="ports_jmf"></a><a name="N11811"></a><b>14.6.</b></td>
           <td valign="top" align="left"><p>Can I use Java Sound's <tt class="classname">Port</tt> interface to control volume and tone of sound played with an application using JMF?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Yes, this is possible. <tt class="classname">Port</tt> lines control the hardware mixer of the soundcard, so using them affects everything played, even sound from native applications. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="no_predefined_ports"></a><a name="N1181F"></a><b>14.7.</b></td>
           <td valign="top" align="left"><p>Why are there no <tt class="classname">Port</tt> instances of certain predefined types (like <tt class="constant">Port.Info.MICROPHONE</tt> or <tt class="constant">Port.Info.COMPACT_DISC</tt>) on Linux?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Some operating systems or soundcard driver APIs do not provide information on the type of the available mixer channels. In these cases, a Java Sound implementation cannot match mixer channels with pre-defined <tt class="classname">Port</tt> types. Especially, this is the case with <a href="http://www.alsa-project.org/" target="_top">ALSA</a>, which is used as the basis for the <tt class="classname">Port</tt> implementation of the Sun JDK on Linux.</p><p>To write portable programs, you should not rely on the availability of pre-defined <tt class="classname">Port</tt> types. If in doubt, obtain the list of available Ports and let the user decide which one to use. This is a good idea anyway, since some users don't have a microphone connected to the "mic in" channel of the soundcard, but via a preamp connected to the "line in" channel. (Matthias)</p></td>
          </tr>
          <tr class="qandadiv">
           <td colspan="2" valign="top" align="left"><a name="sec_misc"></a><h3 class="title"><a name="sec_misc"></a>15. Miscellaneous</h3></td>
          </tr>
          <tr colspan="2" class="toc">
           <td colspan="2" valign="top" align="left">
            <dl>
             <dt>
              15.1. 
              <a href="#quieter_playback">Why is playback of audio data with Java Sound significantly quieter than with a similar player on the native OS?</a>
             </dt>
             <dt>
              15.2. 
              <a href="#multichannel">Can I use multi-channel sound?</a>
             </dt>
             <dt>
              15.3. 
              <a href="#multichannel_cards">Which multi-channel soundcards can I use with Java Sound?</a>
             </dt>
             <dt>
              15.4. 
              <a href="#rear_channels">Can I use the rear channels of a four-channel soundcard (like Soundblaster Life! and Soundblaster Audigy)?</a>
             </dt>
             <dt>
              15.5. 
              <a href="#cdda">How can I read audio data from a CD?</a>
             </dt>
             <dt>
              15.6. 
              <a href="#no_sound_on_linux">Why is there no sound at all when running my program on Linux, while on Windows it works as expected?</a>
             </dt>
             <dt>
              15.7. 
              <a href="#display_waveform">How can I display audio data as a waveform?</a>
             </dt>
             <dt>
              15.8. 
              <a href="#ais_vs_tdl">What is the difference between AudioInputStream and TargetDataLine?</a>
             </dt>
             <dt>
              15.9. 
              <a href="#24_96">Does Java Sound support 24 bit/96 kHz audio?</a>
             </dt>
            </dl></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="quieter_playback"></a><a name="N11845"></a><b>15.1.</b></td>
           <td valign="top" align="left"><p><a name="quieter_playback.q"></a>Why is playback of audio data with Java Sound significantly quieter than with a similar player on the native OS?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There was the issue that Sun's implementation of Java Sound (at least up to version 0.99) lowers the level of output in order to avoid clippings when several lines are mixed. Probably this "feature" is the problem.</p><p>I find this "feature" quite doubtful. A Java Sound programmer should use GainControls attached to single lines to lower the volume, if wanted. Many applications won't profit of this "feature": e.g. they only play one line at a time. Or the mixed sounds don't create clippings. This is not unusual, as even "normalized" sounds leave most of the time enough room - there must coincide peaks to create a clipping. The case that the soft synth AND audio are playing simultaneously can be expected in "quality" programs which provide a way to lower the gain of the lines - or do the gain decrease automatically.</p><p>As Java Sound is supposed to be a low-level engine, such an approach would not be suitable. The problem of the feature is a general decrease of signal-to-noise ratio of all Java Sound programs. Automatic lowering of volume prevents the use in "serious" or professional environments... (Florian)</p><p>Note that the above is true for the "Java Sound Audio Engine". It does not apply to the "Direct Audio Device" mixers. See also <a href="#mixers">What are all these mixers?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="multichannel"></a><a name="N11858"></a><b>15.2.</b></td>
           <td valign="top" align="left"><p><a name="multichannel.q"></a>Can I use multi-channel sound?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>With the "Direct Audio Device" mixers (see <a href="#mixers">What are all these mixers?</a>) it is possible to use multi-channel cards.</p><p>On Windows, the device drivers of multi-channel cards usually split the hardware facilities into stereo channels, each provided by a separate logical device. On Linux with <a href="http://www.alsa-project.org/" target="_top">ALSA</a>, device drivers of multi-channel cards typically represent the hardware by one device with all channels together (interleaved). However, it is possible to split the channels using the ALSA configuration files.</p><p>Without the "Direct Audio Device" mixers, it is possible to record from, but not play back to logically splitted devices. For playback, the first one is used. See <a href="#only_jsae_playback">Why can I record from different soundcards, but not play back to them?</a></p><p>See also <a href="#multichannel_files">Is it possible to read and write multichannel audio files?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="multichannel_cards"></a><a name="N11876"></a><b>15.3.</b></td>
           <td valign="top" align="left"><p><a name="multichannel_cards.q"></a>Which multi-channel soundcards can I use with Java Sound?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Soundcards known to work well with Java Sound (JDK 1.5.0) on Windows as well as on Linux are the M-Audio Delta 44 and Delta 66. Another card working on Windows is the ESI Waveterminal 192X. However, it is reported to have stability problems with Java Sound. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="rear_channels"></a><a name="N1187F"></a><b>15.4.</b></td>
           <td valign="top" align="left"><p><a name="rear_channels.q"></a>Can I use the rear channels of a four-channel soundcard (like Soundblaster Life! and Soundblaster Audigy)?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Yes, if access to these channels are provided by the soundcard driver in a useful way. For Windows, there is no obvious solution; details are under investigation. For Linux, it should be possible. See also <a href="#multichannel">Can I use multi-channel sound?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="cdda"></a><a name="N1188C"></a><b>15.5.</b></td>
           <td valign="top" align="left"><p>How can I read audio data from a CD?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>On Linux, you can do this with Tritonus' CDDA extension. See <a href="http://www.tritonus.org/plugins.html" target="_top">Tritonus Plug-ins</a>, <a class="olink" href="examples/audio_cdda.html">Java Sound Resources: Examples: CD Digital Audio Extraction</a> and <a class="olink" href="apps/ripper.html">Java Sound Resources: Applications: Ripper</a>.</p><p>Currently, there is no implementation doing the same for Windows or other operating systems. Other possible solutions include:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>On some Windows systems as well as on some Linux systems, reading audio CDs is integrated into the operating system. Typically, the CD is mapped into the file system as another disk with one <tt class="filename">.wav</tt> file per track. In this case, you can just open and read one of these files with Java Sound as you would do with any other audio file.</p></li>
              <li><p>Use an external tool to extract the digital data from the CD to a <tt class="filename">.wav</tt> file. Then process this file with Java Sound. It's possible to keep this mechanism "under the hood": invoke the capturing utility from inside your java app (System.exec() or simular) and pass it the name of a temporary file it has to write to. After the utility has completed, read this file.</p></li>
              <li><p>On most systems, you can select the CD as a recording source in the system mixer (this requires your CD drive to be connected to your soundcard with an analog cable). Then do a audio recording with Java Sound. Of course, this does not result in a digital copy of the data on CD.</p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="no_sound_on_linux"></a><a name="N118B6"></a><b>15.6.</b></td>
           <td valign="top" align="left"><p><a name="no_sound_on_linux.q"></a>Why is there no sound at all when running my program on Linux, while on Windows it works as expected?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>A common pitfall on Linux are mixing daemons like esd and artsd. They open the audio device exclusively. So if they are running while the Java VM is started, the VM is denied access to the audio device. There are three possible solutions:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>Use a soundcard that does mixing in hardware. In this case, the Java VM and the mixing daemon can coexist, because opening the audio device is no longer exclusive; the audio streams of the VM and the daemon are mixed in hardware.</p><p>Using ALSA's <a href="http://alsa.opensrc.org/index.php?page=DmixPlugin" target="_top">dmix plug-in</a> is currently no solution, since the "Direct Audio Device" mixer implementation opens ALSA PCM devices in "hw" mode and therefore misses devices emulated by dmix.</p></li>
              <li><p>Kill or disable the mixing daemon while you are using Java Sound programs.</p></li>
              <li><p>As a "light-weight" solution, you can install ALSA including its OSS emulation and configure your system so that the sound daemon uses ALSA directly while the Java VM uses the OSS emulation or the other way round. This way the JVM and the sound daemon wont't interfere. Note that the "Java Sound Audio Engine" uses the OSS API while the "Direct Audio Device" mixer uses the ALSA API.</p></li>
             </ul>
            </div><p>See also <a class="olink" href="faq_misc.html#no_daemons">Q:&nbsp;3.4</a> and <a href="#alsa_mixing">How can I enable mixing with the "Direct Audio Device" mixers on Linux?</a>. (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="display_waveform"></a><a name="N118D9"></a><b>15.7.</b></td>
           <td valign="top" align="left"><p><a name="display_waveform.q"></a>How can I display audio data as a waveform?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>Well, you have to extract the sample values from the byte stream (see <a href="#samples_organized">How are samples organized in a byte array/stream?</a> and <a href="#reconstruct_samples">How can I reconstruct sample values from a byte array?</a>) and then draw some lines...</p><p>There are some examples of classes that implement such a thing:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p><a href="http://jsresources.cvs.sourceforge.net/jsresources/jsresources/apps/jam/src/org/jsresources/apps/jam/util/SimpleWaveformDisplay.java?view=markup" target="_top">SimpleWaveformDisplay.java</a></p></li>
              <li><p><tt class="classname">CapturePlayback.SamplingGraph</tt> in the JavaSoundDemo</p></li>
              <li><p><a href="http://archives.java.sun.com/cgi-bin/wa?A2=ind0005&amp;L=javasound-interest&amp;F=&amp;S=&amp;P=12661" target="_top">SignalPanel</a> from Joerg Prante</p></li>
              <li><p><tt class="classname">ScopeSurface</tt> in C. A. Linley's book "Digital Audio with Java" (see <a class="olink" href="faq_resources.html#books">Q:&nbsp;1</a>)</p></li>
             </ul>
            </div><p>See also <a href="#calculate_power">How can I calculate the power of a signal?</a> (Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="ais_vs_tdl"></a><a name="N1190C"></a><b>15.8.</b></td>
           <td valign="top" align="left"><p>What is the difference between <tt class="classname">AudioInputStream</tt> and <tt class="classname">TargetDataLine</tt>?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p><tt class="classname">InputStream</tt> represents a stream of bytes that may be read from a file, URL or other data source. <tt class="classname">AudioInputStream</tt> extends <tt class="classname">InputStream</tt> with properties that are needed for interpreting audio data: the data format (an <tt class="classname">AudioFormat</tt> object) and the length of the stream in frames. An <tt class="classname">AudioInputStream</tt> instance can be wrapped around any <tt class="classname">InputStream</tt> object to provide this information.</p><p><tt class="classname">TargetDataLine</tt> is much more specific: it represents an audio line to which data is output from an audio device (represented by a <tt class="classname">Mixer</tt> object). Data recorded from an audio capture device is delivered to a <tt class="classname">TargetDataLine</tt>, from which it can be read by the application. So lines of various types (<tt class="classname">TargetDataLine</tt>, <tt class="classname">SourceDataLine</tt>, <tt class="classname">Clip</tt>, <tt class="classname">Port</tt>) are not arbitrary software objects that can be created and connected to a mixer or audio device. Rather, they are part of the mixer or device itself.</p><p>The difference between <tt class="classname">AudioInputStream</tt> and <tt class="classname">TargetDataLine</tt> is mirrored by the difference between <tt class="classname">AudioOutputStream</tt> and <tt class="classname">SourceDataLine</tt>. While <tt class="classname">AudioOutputStream</tt> (a concept introduced by <a href="http://www.tritonus.org/" target="_top">Tritonus</a>) is a general concept of something you can write audio data to, <tt class="classname">SourceDataLine</tt> is specific to a <tt class="classname">Mixer</tt> instance.</p><p>For programming, there are two subtle differences:</p>
            <div class="itemizedlist">
             <ul type="disc">
              <li><p>The handling of read lengths that are not an integral multiple of the frame size: <tt class="classname">AudioInputStream</tt> silently rounds down the length (in bytes) to the nearest integer number of frames. <tt class="classname">TargetDataLine</tt> throws an <tt class="classname">IllegalArgumentException</tt>. </p></li>
              <li><p>The behaviour when the end of data is reached: <tt class="function">AudioInputStream.read()</tt> returns <tt class="constant">-1</tt> if there is no more data. <tt class="function">TargetDataLine.read()</tt> returns <tt class="constant">0</tt> if the line is closed (otherwise, <tt class="function">read()</tt> is guaranteed to block until the requested amount of data is available).</p></li>
             </ul>
            </div><p>(Matthias)</p></td>
          </tr>
          <tr class="question">
           <td valign="top" align="left"><a name="24_96"></a><a name="N11982"></a><b>15.9.</b></td>
           <td valign="top" align="left"><p>Does Java Sound support 24 bit/96 kHz audio?</p></td>
          </tr>
          <tr class="answer">
           <td valign="top" align="left"><b></b></td>
           <td valign="top" align="left"><p>There is nothing in the API that prevents dealing with 24 bit/96 kHz. The implementations of the API are a different story. The "Java Sound Audio Engine" does not support it. Therefore, there is no support for it in the JDK up to 1.4.2. With the "Direct Audio Device" mixers in the JDK 1.5.0 (Linux: 1.4.2), it should be possible. See also <a href="#mixers">What are all these mixers?</a> (Matthias)</p></td>
          </tr>
         </tbody>
        </table>
       </div><br></td>
     </tr>
     <tr>
      <td valign="top" align="left" bgcolor="#E0E0E0" width="230"><p class="navtoc"><a href="index.html"><img border="0" align="left" src="images/jsresources_small.jpg" alt="jsresources.org logo"></a><br clear="all"><br><span class="toplevel"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/index.html" title="Programming examples for the Java Sound API"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/open.gif"></a><span class="otherpage"><a href="examples/index.html" title="Programming examples for the Java Sound API">Examples</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/audio_playing_recording.html" title="Sample programs for the Java Sound API, Audio section"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/audio_playing_recording.html" title="Sample programs for the Java Sound API, Audio section">Audio Playback and Recording</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/audio_files.html" title="Sample programs for the Java Sound API, Audio Files section"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/audio_files.html" title="Sample programs for the Java Sound API, Audio Files section">Audio Files</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/audio_conversion.html" title="Sample programs for the Java Sound API, Audio Conversion section"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/audio_conversion.html" title="Sample programs for the Java Sound API, Audio Conversion section">Audio Conversion</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/audio_cdda.html" title="Sample programs for the Java Sound API, CD Digital Audio Extraction section"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/audio_cdda.html" title="Sample programs for the Java Sound API, CD Digital Audio Extraction section">CD Digital Audio Extraction</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/audio_dsp.html" title="Sample programs for the Java Sound API, DSP section"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/audio_dsp.html" title="Sample programs for the Java Sound API, DSP section">Digital Signal Processing</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/audio_misc.html" title="Sample programs for the Java Sound API, Misc Audio section"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/audio_misc.html" title="Sample programs for the Java Sound API, Misc Audio section">Misc Audio</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/midi_playback_and_recording.html" title="Sample programs for the Java Sound API, MIDI Playback and Recording section"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/midi_playback_and_recording.html" title="Sample programs for the Java Sound API, MIDI Playback and Recording section">MIDI Playback and Recording</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/midi_files.html" title="Sample programs for the Java Sound API, MIDI Files section"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/midi_files.html" title="Sample programs for the Java Sound API, MIDI Files section">MIDI Files</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/midi_io.html" title="Sample programs for the Java Sound API, MIDI Input/Output section"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/midi_io.html" title="Sample programs for the Java Sound API, MIDI Input/Output section">MIDI Input/Output</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/midi_synthesizer.html" title="Sample programs for the Java Sound API, MIDI Synthesizer section"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/midi_synthesizer.html" title="Sample programs for the Java Sound API, MIDI Synthesizer section">MIDI Synthesizer</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/examples_a_z.html" title="Sample programs for the Java Sound API, alphabetical list"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/closed.gif"></a><span class="otherpage"><a href="examples/examples_a_z.html" title="Sample programs for the Java Sound API, alphabetical list">A - Z</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="examples/examples_download.html" title="Sample programs for the Java Sound API, download page"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="examples/examples_download.html" title="Sample programs for the Java Sound API, download page">Download</a></span><br></span><span class="toplevel"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="faq.html" title="Frequently Asked Questions for the Java Sound API"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/open.gif"></a><span class="ancestor"><a href="faq.html" title="Frequently Asked Questions for the Java Sound API">FAQ</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="faq_general.html" title="Frequently Asked Questions for the Java Sound API"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="faq_general.html" title="Frequently Asked Questions for the Java Sound API">General</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="faq_audio.html" title="Frequently Asked Questions for the Java Sound API"><img border="0" alt="+" src="images/navicons/triangle/current/leaf.gif"></a><span class="curpage">Audio Programming&nbsp;<img alt="<-" src="images/navicons/triangle/current/pointer.gif"></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="faq_midi.html" title="Frequently Asked Questions for the Java Sound API"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="faq_midi.html" title="Frequently Asked Questions for the Java Sound API">MIDI Programming</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="faq_applets.html" title="Frequently Asked Questions for the Java Sound API"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="faq_applets.html" title="Frequently Asked Questions for the Java Sound API">Applets and Java WebStart</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="faq_performance.html" title="Frequently Asked Questions for the Java Sound API"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="faq_performance.html" title="Frequently Asked Questions for the Java Sound API">Performance Issues</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="faq_resources.html" title="Frequently Asked Questions for the Java Sound API"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="faq_resources.html" title="Frequently Asked Questions for the Java Sound API">Other Resources</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="faq_tritonus.html" title="Frequently Asked Questions for the Java Sound API"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="faq_tritonus.html" title="Frequently Asked Questions for the Java Sound API">Tritonus</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="faq_misc.html" title="Frequently Asked Questions for the Java Sound API"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="faq_misc.html" title="Frequently Asked Questions for the Java Sound API">Miscellaneous</a></span><br></span><span class="toplevel"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="apps/index.html" title="Applications using the Java Sound API"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/open.gif"></a><span class="otherpage"><a href="apps/index.html" title="Applications using the Java Sound API">Applications</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="apps/am.html" title="Anwering Machine"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="apps/am.html" title="Anwering Machine">Anwering Machine</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="apps/chat.html" title="Chat"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="apps/chat.html" title="Chat">Chat</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="apps/jam.html" title="Jam Session"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="apps/jam.html" title="Jam Session">Jam Session</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="apps/jsinfo.html" title="JSInfo: static information about the Java Sound implementation"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="apps/jsinfo.html" title="JSInfo: static information about the Java Sound implementation">JSInfo</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="apps/midiplayer.html" title="MidiPlayer"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="apps/midiplayer.html" title="MidiPlayer">MidiPlayer</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="apps/mixer.html" title="SystemMixer"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="apps/mixer.html" title="SystemMixer">SystemMixer</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="apps/radio.html" title="Time Turner Radio"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="apps/radio.html" title="Time Turner Radio">Time Turner Radio</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="apps/ripper.html" title="Ripper"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="apps/ripper.html" title="Ripper">Ripper</a></span><br></span><span class="toplevel"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="links.html" title="Links related to Java Sound"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="links.html" title="Links related to Java Sound">Links</a></span><br></span><span class="toplevel"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="search.html" title="Site search for jsresources.org"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="search.html" title="Site search for jsresources.org">Search</a></span><br></span><span class="toplevel"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="contact/index.html" title="Contact information for jsresources.org"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/open.gif"></a><span class="otherpage"><a href="contact/index.html" title="Contact information for jsresources.org">Contact</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="contact/q_guidelines.html" title="Guidelines to asking Questions on javasound-interest and tritonus-user"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="contact/q_guidelines.html" title="Guidelines to asking Questions on javasound-interest and tritonus-user">Question Guidelines</a></span><br></span><span class="shrink1"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="contact/authors.html" title="The authors of jsresources.org"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="contact/authors.html" title="The authors of jsresources.org">Authors</a></span><br></span><span class="toplevel"><img alt="&nbsp;&nbsp;&nbsp;" src="images/blank.gif"><a href="development/index.html" title="Resources for developers (cvs, bug tracking, etc.)"><img border="0" alt="&nbsp;" src="images/navicons/triangle/other/leaf.gif"></a><span class="otherpage"><a href="development/index.html" title="Resources for developers (cvs, bug tracking, etc.)">Development</a></span><br></span><br></p></td>
     </tr>
    </tbody>
   </table>
   <div class="navfoot">
    <hr>
    <table summary="Footer navigation" border="0" width="100%">
     <tbody>
      <tr>
       <td align="left" width="33%"><span class="footdate">$Date: 2006/05/27 07:37:36 $</span></td>
       <td align="center" width="34%"><span class="foothome"><a href="index.html">Home</a></span></td>
       <td align="right" width="33%">&nbsp;</td>
      </tr>
      <tr>
       <td align="right" colspan="3"><span class="footcopy"><span class="copyright">Copyright  2000, 2005 Matthias Pfisterer, Florian Bomers. </span></span></td>
      </tr>
     </tbody>
    </table>
   </div>
  </div>
 </body>
</html>