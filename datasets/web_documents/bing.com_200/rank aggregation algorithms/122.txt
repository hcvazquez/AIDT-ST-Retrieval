<html>
 <head>
  <title>Introduction to Genetic Algorithms</title> 
 </head>
 <body bgcolor="#000000" text="#FFFFFF" link="yellow" vlink="red" alink="lightblue"> 
  <a name="top"> <pre>
<h1><img SRC="article1.logo.gif"><strong>Genetic Algorithms</strong></h1>
</pre> <img SRC="article1.gradiated.gif"> <h1><strong>History</strong></h1> <i>
    <blockquote>
      Genetic Algorithms were invented to mimic some of the processes observed in natural evolution. Many people, biologists included, are astonished that life at the level of complexity that we observe could have evolved in the relatively short time suggested by the fossil record. The idea with GA is to use this power of evolution to solve optimization problems. The father of the original Genetic Algorithm was John Holland who invented it in the early 1970's. 
    </blockquote></i> <h2>Contents </h2> </a>
  <dl compact>
   <a name="top"> 
    <dd> 
     <img SRC="article1.star.gif">
     <a href="#introduction"> What is Genetic Algorithms </a> 
    </dd></a>
   <dd> 
    <img SRC="article1.star.gif">
    <a href="#why"> Why Genetic Algorithms </a> 
   </dd>
   <dd> 
    <img SRC="article1.star.gif">
    <a href="#overview"> Genetics Algorithms Overview </a> 
    <ul>
     <li><a href="#search"> Search Space </a></li>
    </ul> 
   </dd>
   <dd> 
    <img SRC="article1.star.gif">
    <a href="#implementation"> Implementation Details</a> 
    <ul> 
     <li><a href="#selection"> Selection Operator </a> </li>
     <li><a href="#crossover"> Crossover Operator </a> </li>
     <li><a href="#mutation"> Mutation Operator </a> </li>
     <li><a href="#effect"> Effect of Genetic Operator </a> </li>
     <li><a href="#algorithms"> The Algorithms </a> </li>
    </ul> 
   </dd>
   <dd> 
    <img SRC="article1.star.gif">
    <a href="#summary"> Summary </a> 
   </dd>
  </dl> 
  <br> 
  <img SRC="article1.eye.gif"> 
  <a name="introduction"> <h1><b>What is Genetic Algorithms?</b></h1> <p><font size="4"> Genetic Algorithms (GAs) are adaptive heuristic search algorithm based on the evolutionary ideas of natural selection and genetics. As such they represent an intelligent exploitation of a random search used to solve optimization problems. Although randomised, GAs are by no means random, instead they exploit historical information to direct the search into the region of better performance within the search space. The basic techniques of the GAs are designed to simulate processes in natural systems necessary for evolution, specially those follow the principles first laid down by Charles Darwin of "survival of the fittest.". Since in nature, competition among individuals for scanty resources results in the fittest individuals dominating over the weaker ones. </font></p><font size="4"> <br> <img SRC="article1.eye.gif"> </font></a>
  <font size="4"><a name="why"> <h1><strong>Why Genetic Algorithms?</strong></h1> <p> It is better than conventional AI in that it is more robust. Unlike older AI systems, they do not break easily even if the inputs changed slightly, or in the presence of reasonable noise. Also, in searching a large state-space, multi-modal state-space, or n-dimensional surface, a genetic algorithm may offer significant benefits over more typical search of optimization techniques. (linear programming, heuristic, depth-first, breath-first, and praxis.) </p> <br> <img SRC="article1.eye.gif"> </a><a name="overview"> <h1><strong>Genetic Algorithms Overview</strong></h1> <p> GAs simulate the survival of the fittest among individuals over consecutive generation for solving a problem. Each generation consists of a population of character strings that are analogous to the chromosome that we see in our DNA. Each individual represents a point in a search space and a possible solution. The individuals in the population are then made to go through a process of evolution.</p> <p>GAs are based on an analogy with the genetic structure and behaviour of chromosomes within a population of individuals using the following foundations:</p> 
    <ul> 
     <li> Individuals in a population compete for resources and mates. </li>
     <li> Those individuals most successful in each 'competition' will produce more offspring than those individuals that perform poorly. </li>
     <li> Genes from `good' individuals propagate throughout the population so that two good parents will sometimes produce offspring that are better than either parent. </li>
     <li> Thus each successive generation will become more suited to their environment. </li>
    </ul> <p></p> <br> </a><a name="search"> <h3><strong>Search Space</strong></h3> <p>A population of individualsare is maintained within <strong>search space</strong> for a GA, each representing a possible solution to a given problem. Each individual is coded as a finite length vector of components, or variables, in terms of some alphabet, usually the <b>binary</b> alphabet <b>{0,1}</b>. To continue the genetic analogy these individuals are likened to chromosomes and the variables are analogous to genes. Thus a chromosome (solution) is composed of several genes (variables). A <b>fitness score</b> is assigned to each solution representing the abilities of an individual to `compete'. The individual with the optimal (or generally near optimal) fitness score is sought. The GA aims to use selective `breeding' of the solutions to produce `offspring' better than the parents by combining information from the chromosomes.</p> <br> <br> 
    <center>
     <img SRC="article1.gene.gif">
    </center> <br> <p>The GA maintains a population of n chromosomes (solutions) with associated fitness values. Parents are selected to mate, on the basis of their fitness, producing offspring via a reproductive plan. Consequently highly fit solutions are given more opportunities to reproduce, so that offspring inherit characteristics from each parent. As parents mate and produce offspring, room must be made for the new arrivals since the population is kept at a static size. Individuals in the population die and are replaced by the new solutions, eventually creating a new generation once all mating opportunities in the old population have been exhausted. In this way it is hoped that over successive generations better solutions will thrive while the least fit solutions die out.</p> <p>New generations of solutions are produced containing, on average, more good genes than a typical solution in a previous generation. Each successive generation will contain more good `partial solutions' than previous generations. Eventually, once the population has converged and is not producing offspring noticeably different from those in previous generations, the algorithm itself is said to have converged to a set of solutions to the problem at hand.</p> <br> <img SRC="article1.eye.gif"> </a><a name="implementation"> <h1><strong>Implementation Details</strong></h1> <h3><strong>Based on Natural Selection</strong></h3> After an initial population is randomly generated, the algorithm evolves the through three operators: 
    <ol> 
     <li> <strong>selection</strong> which equates to survival of the fittest; </li>
     <li> <strong>crossover</strong> which represents mating between individuals; </li>
     <li> <strong>mutation</strong> which introduces random modifications. </li>
    </ol> <br> <br> </a><a name="selection"> <h3><strong>1. Selection Operator</strong></h3> 
    <ul> 
     <li> key idea: give prefrence to better individuals, allowing them to pass on their genes to the next generation. </li>
     <li> The goodness of each individual depends on its fitness. </li>
     <li> Fitness may be determined by an objective function or by a subjective judgement. </li>
    </ul> </a><a name="crossover"> <h3><strong>2. Crossover Operator</strong></h3> 
    <ul> 
     <li> Prime distinguished factor of GA from other optimization techniques </li>
     <li> Two individuals are chosen from the population using the selection operator </li>
     <li> A crossover site along the bit strings is randomly chosen </li>
     <li> The values of the two strings are exchanged up to this point </li>
     <li> If S1=000000 and s2=111111 and the crossover point is 2 then S1'=110000 and s2'=001111 </li>
     <li> The two new offspring created from this mating are put into the next generation of the population </li>
     <li> By recombining portions of good individuals, this process is likely to create even better individuals </li>
    </ul> <br> 
    <center>
     <img SRC="article1.cross.gif">
    </center> <br> </a><a name="mutation"> <h3><strong>3. Mutation Operator</strong></h3> 
    <ul> 
     <li> With some low probability, a portion of the new individuals will have some of their bits flipped. </li>
     <li> Its purpose is to maintain diversity within the population and inhibit premature convergence. </li>
     <li> Mutation alone induces a random walk through the search space </li>
     <li> Mutation and selection (without crossover) create a parallel, noise-tolerant, hill-climbing algorithms </li>
    </ul> <br> 
    <center>
     <img SRC="article1.mutation.gif">
    </center> <br> </a><a name="effect"> <h3><b>Effects of Genetic Operators</b></h3> 
    <ul> 
     <li> Using selection alone will tend to fill the population with copies of the best individual from the population </li>
     <li> Using selection and crossover operators will tend to cause the algorithms to converge on a good but sub-optimal solution </li>
     <li> Using mutation alone induces a random walk through the search space. </li>
     <li> Using selection and mutation creates a parrallel, noise-tolerant, hill climbing algorithm </li>
    </ul> </a><a name="algorithms"> <h3><b>The Algorithms</b></h3> 
    <ol> 
     <li> randomly initialize population(t) </li>
     <li> determine fitness of population(t) </li>
     <li> repeat 
      <ol> 
       <li> select parents from population(t) </li>
       <li> perform crossover on parents creating population(t+1) </li>
       <li> perform mutation of population(t+1) </li>
       <li> determine fitness of population(t+1) </li>
      </ol> </li>
     <li> until best individual is good enough </li>
    </ol> <br> <br> <img SRC="article1.eye.gif"> </a><a name="summary"> <h1><b>Summary</b></h1> <p>In previous subsection it has been claimed that via the operations of selection, crossover, and mutation the GA will converge over successive generations towards the global (or near global) optium. why these simple operation should produce a fast, useful and robust techiques is largely due to the fact that GAs combine direction and chance in the search in an effective and efficient manner. Since population implicitly contain much more information than simply the individual fitness scores, GAs combine the good information hidden in a solution with good information from another solution to produce new solutions with good indormation inherited from both parents, inevitably (hopefully) leading towrads optimality. </p><p>The ability of the algorithm to explore and exploit simultaneously, a growing amount of theoretical justification, and successful application to real-world problems strengthens the conclusion that GAs are a powerful, robust optimisation technique. <br> <br> <img SRC="article1.eye.gif"> </p><p><img SRC="article1.pinkball.gif"> An introduction to Genetic Algorithms. <i> mit press </i> <b> edited by Melanie Mitchell</b></p> <p><img SRC="article1.pinkball.gif"> Genetic algorithms in engineering and computer science / <b>edited by G. Winter</b> ... [et al.]. c1995 </p><p><img SRC="article1.pinkball.gif"> Foundations of genetic algorithms <b> edited by Gregory J.E. Rawlins. </b> c1991 </p></a><p><a name="summary"><img SRC="article1.pinkball.gif"> </a><a href="http://www.aic.nrl.navy.mil/galist/">The Genetic Algorithms Archive </a> <br> <br> </p>
   <hr> <br> <p>For details of <a href="http://www-students.doc.ic.ac.uk:80/~tcw2/Genetics/article1.html">applications</a> of genetics algorithms, please refer to my partner, <i>Chun</i>'s article. <br> <br> <a href="http://www-students.doc.ic.ac.uk:80/~hmw"> <img align="left" SRC="article1.home.gif"></a><a href="#top"><img SRC="article1.m_up.gif"></a>    </p></font>
 </body>
</html>