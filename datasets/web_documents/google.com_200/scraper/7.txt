<!doctype html>
<html>
 <head> 
  <meta charset="utf-8"> 
  <meta http-equiv="X-UA-Compatible" content="IE=edge"> 
  <title>Super simple web scraping with Node.js / JavaScript</title> 
  <meta name="description" content="How to create a web scraper in 20 lines of code to scrape websites like reddit, Hacker News, and BuzzFeed. Extract content and write it to a text file."> 
  <meta name="HandheldFriendly" content="True"> 
  <meta name="viewport" content="width=device-width, initial-scale=1.0"> 
  <link rel="shortcut icon" href="/favicon.ico"> 
  <link rel="stylesheet" type="text/css" href="/assets/css/screen.css?v=0f8a70dd43"> 
  <link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Merriweather:300,700,700italic,300italic|Open+Sans:700,400"> 
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-25699647-1', 'auto');
      ga('send', 'pageview');
    </script> 
  <link rel="canonical" href="http://www.netinstructions.com/simple-web-scraping-with-node-js-and-javascript/"> 
  <meta property="og:site_name" content="'Net Instructions"> 
  <meta property="og:type" content="article"> 
  <meta property="og:title" content="Super simple web scraping with Node.js / JavaScript"> 
  <meta property="og:description" content="How to create a web scraper in 20 lines of code to scrape websites like reddit, Hacker News, and BuzzFeed. Extract content and write it to a text file."> 
  <meta property="og:url" content="http://www.netinstructions.com/simple-web-scraping-with-node-js-and-javascript/"> 
  <meta property="article:published_time" content="2015-12-03T04:57:20.376Z"> 
  <meta property="article:modified_time" content="2017-03-10T22:06:48.386Z"> 
  <meta name="twitter:card" content="summary"> 
  <meta name="twitter:title" content="Super simple web scraping with Node.js / JavaScript"> 
  <meta name="twitter:description" content="How to create a web scraper in 20 lines of code to scrape websites like reddit, Hacker News, and BuzzFeed. Extract content and write it to a text file."> 
  <meta name="twitter:url" content="http://www.netinstructions.com/simple-web-scraping-with-node-js-and-javascript/"> 
  <script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "Article",
    "publisher": "'Net Instructions",
    "author": {
        "@type": "Person",
        "name": "Stephen",
        "url": "http://www.netinstructions.com/author/stephen",
        "sameAs": null,
        "description": null
    },
    "headline": "Super simple web scraping with Node.js / JavaScript",
    "url": "http://www.netinstructions.com/simple-web-scraping-with-node-js-and-javascript/",
    "datePublished": "2015-12-03T04:57:20.376Z",
    "dateModified": "2017-03-10T22:06:48.386Z",
    "description": "How to create a web scraper in 20 lines of code to scrape websites like reddit, Hacker News, and BuzzFeed. Extract content and write it to a text file."
}
    </script> 
  <meta name="generator" content="Ghost 0.6"> 
  <link rel="alternate" type="application/rss+xml" title="'Net Instructions" href="http://www.netinstructions.com/rss/"> 
  <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script> 
  <script>
  (adsbygoogle = window.adsbygoogle || []).push({
    google_ad_client: "ca-pub-3499795748662482",
    enable_page_level_ads: true
  });
</script> 
 </head> 
 <body class="post-template nav-closed"> 
  <div class="site-wrapper"> 
   <header class="main-header post-head no-cover"> 
    <nav class="main-nav  clearfix"> 
    </nav> 
   </header> 
   <main class="content" role="main"> 
    <article class="post"> 
     <header class="post-header"> 
      <h1 class="post-title">Simple web scraping with Node.js / JavaScript</h1> 
      <section class="post-meta"> 
       <time class="post-date" datetime="2015-12-03">03 December 2015</time> 
      </section> 
     </header> 
     <section class="post-content"> 
      <p>Following up on my popular tutorial on <a href="http://www.netinstructions.com/how-to-make-a-simple-web-crawler-in-javascript-and-node-js/">how to create an easy web crawler in Node.js</a> I decided to extend the idea a bit further by scraping a few popular websites. For now, I'll just append the results of web scraping to a .txt file, but in a future post I'll show you how to insert them into a database.</p> 
      <p>Each scraper takes about 20 lines of code and they're pretty easy to modify if you want to scrape other elements of the site or web page.</p> 
      <h2 id="webscrapingreddit">Web Scraping Reddit</h2> 
      <p>First I'll show you what it does and then explain it.</p> 
      <p><img src="/content/images/2015/12/scraping-reddit-tutorial-1.gif" alt=""></p> 
      <p>It firsts visits <a href="https://www.reddit.com/">reddit.com</a> and then collects all the post titles, the score, and the username of the user that submitted each post. It writes all of this to a .txt file named <code>reddit.txt</code> separating each entry on a new line. Alternatively it's easy to separate each entry with a comma or some other delimiter if you wanted to open the results in Excel or a spreadsheet. </p> 
      <p>Okay, so how did I do it?</p> 
      <p>Make sure you have Node.js and npm installed. If you're not familiar with them take a look at the <a href="http://www.netinstructions.com/how-to-make-a-simple-web-crawler-in-javascript-and-node-js/#prerequisites">paragraph here</a>.</p> 
      <p>Open up your command line. You'll need to install just two Node.js dependencies. You can do that by either running</p> 
      <pre><code>npm install --save cheerio
npm install --save request
</code></pre> 
      <p>as shown below:</p> 
      <p><img src="/content/images/2015/12/npm-install-web-scraper-dependencies.gif" alt=""></p> 
      <h4 id="alternateoptiontoinstalldependencies">Alternate option to install dependencies</h4> 
      <p>Another option is copying over the dependencies and adding them to a <code>package.json</code> file and then running <code>npm install</code>. My <code>package.json</code> includes these:</p> 
      <p><img src="/content/images/2015/12/my-package-json.png" alt=""></p> 
      <h3 id="theactualcodetoscrapereddit">The actual code to scrape reddit</h3> 
      <p>Now to take a look at how I scraped reddit in about 20 lines of code. Open up your favorite text editor (I use <a href="https://atom.io/">Atom</a>) and copy the following:</p> 
      <pre><code>var request = require('request');
var cheerio = require('cheerio');
var fs = require('fs');

request("https://www.reddit.com", function(error, response, body) {
  if(error) {
    console.log("Error: " + error);
  }
  console.log("Status code: " + response.statusCode);

  var $ = cheerio.load(body);

  $('div#siteTable &gt; div.link').each(function( index ) {
    var title = $(this).find('p.title &gt; a.title').text().trim();
    var score = $(this).find('div.score.unvoted').text().trim();
    var user = $(this).find('a.author').text().trim();
    console.log("Title: " + title);
    console.log("Score: " + score);
    console.log("User: " + user);
    fs.appendFileSync('reddit.txt', title + '\n' + score + '\n' + user + '\n');
  });

});
</code></pre> 
      <p>This is surprisingly simple. Save the file as <code>scrape-reddit.js</code> and then run it by typing <code>node scrape-reddit.js</code>. You should end up with a text file called <code>reddit.txt</code> that looks something like:</p> 
      <pre><code>UK Parliament Vote in Favor of Airstrikes in Syria
5515
CathGorm
Harrison Ford, everybody
4569
DudeWiggles
Nick Offerman Silently Drinking Whisky By A Fireplace For 45 Minutes
5112
smgulz
"A new blanket? For me? I love it!"
5605
natsdorf
Playing basketball (Fallout 4)
2535
theone1221
... continued
</code></pre> 
      <p>which is the post title, then the score, and finally the username.</p> 
      <h2 id="webscrapinghackernews">Web Scraping Hacker News</h2> 
      <p>Let's take a look at how the posts are structured:</p> 
      <p><img src="/content/images/2015/12/how-to-scrape-hacker-news-choosing-the-right-selectors.png" alt=""></p> 
      <p>As you can see, there are a bunch of <code>tr</code> HTML elements with a class of <code>athing</code>. So the first step will be to gather up all of the <code>tr.athing</code> elements. </p> 
      <p>We'll then want to grab the post titles by selecting the <code>td.title</code> child element and then the <code>a</code> element (the anchor tag of the hyperlink). </p> 
      <p>Note that we skip over any hiring posts by making sure we only gather up the <code>tr.athing</code> elements that have a <code>td.votelinks</code> child, as demonstrated in the following picture:</p> 
      <p><img src="/content/images/2015/12/scraping-hacker-news-selectors-for-finding-html.png" alt=""></p> 
      <p>Here's the code</p> 
      <pre><code>var request = require('request');
var cheerio = require('cheerio');
var fs = require('fs');

request("https://news.ycombinator.com/news", function(error, response, body) {
  if(error) {
    console.log("Error: " + error);
  }
  console.log("Status code: " + response.statusCode);

  var $ = cheerio.load(body);

  $('tr.athing:has(td.votelinks)').each(function( index ) {
    var title = $(this).find('td.title &gt; a').text().trim();
    var link = $(this).find('td.title &gt; a').attr('href');
    fs.appendFileSync('hackernews.txt', title + '\n' + link + '\n');
  });

});
</code></pre> 
      <p>Run that and you'll get a <code>hackernews.txt</code> file that looks something like:</p> 
      <p><img src="/content/images/2015/12/results-of-web-scraping-hacker-news.png" alt=""></p> 
      <p>First you have the title of the post on Hacker News and then the URL of that post on the next line. If you wanted both the title and URL on the same line, you can change the code:</p> 
      <pre><code>fs.appendFileSync('hackernews.txt', title + '\n' + link + '\n');
</code></pre> 
      <p>to something like:</p> 
      <pre><code>fs.appendFileSync('hackernews.txt', title + ',' + link + '\n');
</code></pre> 
      <p>This allows you to use a comma as a delimiter so you can open up the file in a spreadsheet like Excel or a different program. You may want to use a different delimiter, such as a semicolon, which is an easy change above.</p> 
      <h2 id="webscrapingbuzzfeed">Web Scraping BuzzFeed</h2> 
      <pre><code>var request = require('request');
var cheerio = require('cheerio');
var fs = require('fs');

request("http://www.buzzfeed.com", function(error, response, body) {
  if(error) {
    console.log("Error: " + error);
  }
  console.log("Status code: " + response.statusCode);

  var $ = cheerio.load(body);

  $('div.col1 &gt; ul &gt; li.grid-posts__item').each(function( index ) {
    var title = $(this).find('h2 &gt; a').text().trim();
    var author = $(this).find('div.small-meta &gt; div:nth-child(1) &gt; a').text().trim();
    var responses = $(this).find('div.small-meta &gt; div:nth-child(3) &gt; a').text();
    console.log(title);
    console.log(author);
    console.log(responses);
    fs.appendFileSync('buzzfeed.txt', title + '\n' + author + '\n' + responses + '\n');
  });

});
</code></pre> 
      <p>Run that and you'll get something like the following in a <code>buzzfeed.txt</code> file:</p> 
      <pre><code>These People Complaining About "The Wiz" Seem To Have Forgotten That "The Wizard Of Oz" Exists
Andy Neuenschwander
135 responses
It's Time We Realize Britney Spears Is Actually God
Matt Stopera
211 responses
29 Of The Best Awards Show Moments Of 2015
Chelsea Brown
60 responses
Try Stuffing Chicken Parmesan Meatballs With Mozzarella And See What Happens
Andrew Ilnyckyj
11 responses
Apparently In Texas You Get Pickles When You Go To The Movies
Anna Menta
123 responses
What's The Funniest Moment From "Elf"?
Kayla Yandoli
113 responses
This Video Of A Doctor Calming Babies Will Calm You The Eff Down
Alison Caporimo
189 responses
</code></pre> 
      <h3 id="wantmore">Want more?</h3> 
      <p>I'll eventually update this post to explain how the web scraper works. Specifically I'll talk about how I chose the selectors to pull the correct content from the right HTML element. There are great tools that make this process very easy, such as <a href="https://developers.google.com/web/tools/chrome-devtools/?hl=en">Chrome DevTools</a> that I use while I'm writing the web scraper for the first time.</p> 
      <p>I'll also show you how to iterate through the pages on each website to scrape even more content.</p> 
      <p>Finally, in a future post I'll detail how to insert these records into a database instead of a .txt file. <strong>Be sure to check back!</strong> </p> 
      <p>In the mean time, you may be interested in my tutorial on <a href="http://www.netinstructions.com/how-to-make-a-simple-web-crawler-in-javascript-and-node-js/">how to create a web crawler in Node.js / JavaScript</a>.</p> 
      <script async src="//pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script> 
      <!-- Net Instructions Footer --> 
      <ins class="adsbygoogle" style="display:block" data-ad-client="ca-pub-3499795748662482" data-ad-slot="1929117901" data-ad-format="auto"></ins> 
      <script>  
(adsbygoogle = window.adsbygoogle || []).push({});
</script> 
     </section> 
     <footer class="post-footer"> 
      <section class="author"> 
       <h4><a href="/author/stephen/">Stephen</a></h4> 
       <p>Read <a href="/author/stephen/">more posts</a> by this author.</p> 
       <div class="author-meta"> 
       </div> 
      </section> 
      <section class="share"> 
       <h4>Share this post</h4> 
       <a class="icon-twitter" href="https://twitter.com/share?text=Simple%20web%20scraping%20with%20Node.js%20%2F%20JavaScript&amp;url=http://www.netinstructions.com/simple-web-scraping-with-node-js-and-javascript/" onclick="window.open(this.href, 'twitter-share', 'width=550,height=235');return false;"> <span class="hidden">Twitter</span> </a> 
       <a class="icon-facebook" href="https://www.facebook.com/sharer/sharer.php?u=http://www.netinstructions.com/simple-web-scraping-with-node-js-and-javascript/" onclick="window.open(this.href, 'facebook-share','width=580,height=296');return false;"> <span class="hidden">Facebook</span> </a> 
       <a class="icon-google-plus" href="https://plus.google.com/share?url=http://www.netinstructions.com/simple-web-scraping-with-node-js-and-javascript/" onclick="window.open(this.href, 'google-plus-share', 'width=490,height=530');return false;"> <span class="hidden">Google+</span> </a> 
      </section> 
      <div class="disqusbox"> 
       <div> 
        <hr> 
       </div> 
       <p><strong>View or post Comments</strong></p> 
      </div> 
      <div id="disqus_thread"> 
       <form onsubmit="my.loadDisqus(); return false;" class="formBlock"> 
        <input class="disqusButton" type="submit" value="Load Comments"> 
       </form> 
      </div> 
      <script type="text/javascript">
                var disqus_shortname = 'netinstructions';
                var disqus_identifier = '';

                var my = my || {};
                my.loadDisqus = function() {
                    var dsq = document.createElement('script');
                    dsq.type = 'text/javascript';
                    dsq.async = true;
                    dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                };
            </script> 
      <noscript>
       Please enable JavaScript to view the 
       <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a>
      </noscript> 
     </footer> 
    </article> 
   </main> 
   <aside class="read-next"> 
    <a class="read-next-story no-cover" href="/how-to-install-and-run-tensorflow-on-a-windows-pc/"> 
     <section class="post"> 
      <h2>How to install and run TensorFlow on a Windows PC</h2> 
      <p>If you're involved with machine learning, you probably heard the news by now that Google open-sourced their machine learning…</p> 
     </section> </a> 
    <a class="read-next-story prev no-cover" href="/how-to-install-docker-on-windows-behind-a-proxy/"> 
     <section class="post"> 
      <h2>How to install Docker on Windows behind a proxy</h2> 
      <p>My journey into Docker started with TensorFlow, Google's machine learning library. TensorFlow provided no installation instructions for a Windows…</p> 
     </section> </a> 
   </aside> 
   <footer class="site-footer clearfix"> 
    <section class="copyright">
     <a href="http://www.netinstructions.com">'Net Instructions</a> © 2011-2017
    </section> 
    <section class="poweredby">
     Proudly published with 
     <a href="https://ghost.org">Ghost</a>
    </section> 
   </footer> 
  </div> 
  <script src="/public/jquery.min.js?v=0f8a70dd43"></script> 
  <script type="text/javascript" src="/assets/js/jquery.fitvids.js?v=0f8a70dd43"></script> 
  <script type="text/javascript" src="/assets/js/index.js?v=0f8a70dd43"></script>   
 </body>
</html>